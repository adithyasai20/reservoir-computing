{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the device on which the processing is going to take place.\n",
    "device = torch.device(\"cpu\")\n",
    "# Preprocessing takes most of the time. \n",
    "# No significant reduction in training time if we use GPU as the model is not very big.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeTransform:\n",
    "    \"\"\"\n",
    "    A class to binarize the input MNIST data.\n",
    "    \"\"\"\n",
    "    def __call__(self, img):\n",
    "        # Values are between 0 and 1 so I have binarized with threshold of 0.5\n",
    "        return (img>0.5).float()\n",
    "\n",
    "# Transform to be applied on to the data immediately after loading from location.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    BinarizeTransform()\n",
    "])\n",
    "\n",
    "# Load and transform MNIST data\n",
    "mnist_data_train = datasets.MNIST(root=\"data/MNIST\", train=True, download=True, transform=transform)\n",
    "mnist_data_test = datasets.MNIST(root=\"data/MNIST\", train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(mnist_data_train))       # Size of the train split\n",
    "val_size = len(mnist_data_train) - train_size       # Size of the validation split\n",
    "\n",
    "\n",
    "train_data, val_data = random_split(mnist_data_train, [train_size, val_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 6000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(mnist_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all the rows of each mask-set in every file \n",
    "json_data = {\n",
    "    \"365nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(10, 15),\n",
    "        \"I3\":range(18, 23),\n",
    "        \"I4\":range(25, 30)\n",
    "    },\n",
    "    \"455nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(7, 12),\n",
    "        \"I3\":range(14, 19),\n",
    "        \"I4\":range(21, 26)\n",
    "    },\n",
    "    \"White\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(9, 14),\n",
    "        \"I3\":range(16, 21),\n",
    "        \"I4\":range(24, 29)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"365nm\"  # Excel document name from which data has to be extracted.\n",
    "path = \"data/\"+filename+\".xlsx\" # Excel doc path\n",
    "\n",
    "df = pd.read_excel(path, usecols='B:Q') # Read the excel sheet\n",
    "# Break the sheet down into different `DataFrame`s for every Mask-set in the table\n",
    "tables = [df.iloc[json_data[filename][key]].copy().reset_index(drop=True) for key in list(json_data[filename].keys())]\n",
    "\n",
    "# Mask sets to be used\n",
    "mask_sets = [3]\n",
    "# Randomly initialize the device states (Uniform distribution over all the states)\n",
    "device_indices = torch.randint(0, 5, (len(mask_sets), 196))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    \"\"\"Dataset object to save the preprocessed mnist dataset\n",
    "\n",
    "    Parameters -\n",
    "    mnist_data : `torch.utils.data.dataset`\n",
    "                Contains images and corresponding labels of MNIST dataset               \n",
    "    tables : `list[pd.DataFrame]`\n",
    "                conductance tables for every mask-set.\n",
    "    device_indices : `torch.tensor`\n",
    "                Initial conductance states of every device. Shape of `((len(mask_sets), 196))`\n",
    "    mask_sets : `List[int]`\n",
    "                List of all the mask-sets to be used\n",
    "\n",
    "    Attributes - \n",
    "\n",
    "    mask_sets : `List[int]`\n",
    "                A list of all the mask-sets used for simulation.\n",
    "    processed_data : `torch.tensor`\n",
    "                MNIST images after preprocessing. Shape of ((N_samples, 1, 196 * len(mask_sets)))\n",
    "    labels : `torch.tensor`\n",
    "                label of each corresponding image. Shape of ((N_samples, num_classes))   (num_classes = 10)\n",
    "    device_indices : List[List]\n",
    "                Initial states of each device for every mask-set\n",
    "    \"\"\"\n",
    "    def __init__(self, mnist_data, tables, device_indices, mask_sets ):\n",
    "        self.mask_sets = mask_sets\n",
    "        self.processed_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.device_indices = device_indices.int().tolist()\n",
    "        \n",
    "        # Preprocessing step. Same as discussed in the paper given.\n",
    "        for idx in tqdm(range(len(mnist_data))):\n",
    "            image, label = mnist_data[idx]\n",
    "            image = image.reshape(1, 196, 4)\n",
    "            image_combined = (\n",
    "                image[:, :, 0] * 1000 + \n",
    "                image[:, :, 1] * 100 + \n",
    "                image[:, :, 2] * 10 + \n",
    "                image[:, :, 3]\n",
    "            )\n",
    "            # x = []\n",
    "            # for m_idx, mask in enumerate(self.mask_sets):\n",
    "            #     for i, device in enumerate(self.device_indices[m_idx]):                \n",
    "            #         x.append(tables[mask].loc[int(device), int(image_combined[0][i])]*1e9)\n",
    "            x = [\n",
    "                tables[mask].loc[int(device), int(image_combined[0][i])] * 1e9\n",
    "                for mask_idx, mask in enumerate(self.mask_sets)\n",
    "                for i, device in enumerate(self.device_indices[mask_idx])\n",
    "            ]*1e9\n",
    "            \n",
    "            self.processed_data.append(x)\n",
    "            self.labels.append(label)\n",
    "        \n",
    "        # Convert the lists to `torch.tensor`\n",
    "        self.processed_data = torch.tensor(self.processed_data)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Function to access length of the dataset object.\n",
    "\n",
    "        Returns: `int`\n",
    "                    Length of the dataset object\n",
    "        \"\"\"\n",
    "        return len(self.processed_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns element's image and label at a given index.\n",
    "        Parameters - \n",
    "        idx : int\n",
    "            index of the element to be accessed\n",
    "\n",
    "        Returns - torch.tensor, torch.tensor\n",
    "        \"\"\"\n",
    "        return self.processed_data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, combined_table:pd.DataFrame, device_masks, mask_set):\n",
    "        self.processed_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx in tqdm(range(len(data))):\n",
    "            image, label = data[idx]\n",
    "            image = image.reshape(196, 4)\n",
    "            optical_pulses = (\n",
    "                image[ :, 0] * 1000 + \n",
    "                image[ :, 1] * 100 + \n",
    "                image[ :, 2] * 10 + \n",
    "                image[ :, 3]\n",
    "            ).repeat(len(mask_set))\n",
    "            row_indices = torch.tensor([(device_masks[i]+mask_set[i]*5).tolist() for i in range(len(mask_set))]).flatten()\n",
    "            column_indices = combined_table.columns.get_indexer(optical_pulses.tolist())\n",
    "            \n",
    "            self.processed_data.append(   combined_table.values[row_indices, column_indices] *1e9 )\n",
    "            self.labels.append(label)\n",
    "        self.processed_data = torch.tensor(np.array(self.processed_data)).to(device=device)\n",
    "        self.labels = torch.tensor(self.labels).to(device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.processed_data.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.processed_data[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54000/54000 [03:03<00:00, 294.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training dataset\n",
    "train_dataset = CustomMNISTDataset(train_data, tables=tables, mask_sets=mask_sets, device_indices=device_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:19<00:00, 300.09it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = CustomMNISTDataset(val_data, tables=tables, mask_sets=mask_sets, device_indices=device_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:33<00:00, 294.44it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomMNISTDataset(mnist_data_test, tables=tables, mask_sets=mask_sets, device_indices=device_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadoutLayer(nn.Module):\n",
    "    \"\"\"Readout layer.\n",
    "    Parameters - \n",
    "\n",
    "    Attributes - \n",
    "    fc : `nn.Linear`\n",
    "            Fully connected layer to be trained for reservoir computing.\n",
    "    activation : `nn.functional.leaky_relu`\n",
    "            Activation layer to be applied\n",
    "    \n",
    "    softmax : `nn.Softmax`\n",
    "            Softmax activation function to get the one-hot encoded results.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        # super function to initialize the constructors of the parent classes.\n",
    "        super(ReadoutLayer, self).__init__()\n",
    "        # Class Attributes\n",
    "        self.fc = nn.Linear(input_size, 10) \n",
    "        self.activation = nn.functional.leaky_relu\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward method to be executed on function call.\n",
    "        Parameters - \n",
    "        x : torch.tensor\n",
    "            Shape( Batch_size, 196 * len(mask_sets) )\n",
    "        \n",
    "        Returns : torch.tensor\n",
    "            Shape( Batch_size, 10 )\n",
    "        \"\"\"\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(filename, mask_sets, device_indices):\n",
    "    # filename = \"365nm\"  # Excel document name from which data has to be extracted.\n",
    "    path = \"data/\"+filename+\".xlsx\" # Excel doc path\n",
    "\n",
    "    df = pd.read_excel(path, usecols='B:Q') # Read the excel sheet\n",
    "    # Break the sheet down into different `DataFrame`s for every Mask-set in the table\n",
    "    tables = [df.iloc[json_data[filename][key]].copy().reset_index(drop=True) for key in list(json_data[filename].keys())]\n",
    "    combined_table = pd.concat(tables, axis=0)\n",
    "\n",
    "    # train_dataset = CustomMNISTDataset(train_data, tables=tables, mask_sets=mask_sets, device_indices=device_indices)\n",
    "    # validation_dataset = CustomMNISTDataset(val_data, tables=tables, mask_sets=mask_sets, device_indices=device_indices)\n",
    "    # test_dataset = CustomMNISTDataset(mnist_data_test, tables=tables, mask_sets=mask_sets, device_indices=device_indices)\n",
    "    \n",
    "    train_dataset = CustomDataset(train_data, combined_table, device_indices, mask_sets)\n",
    "    validation_dataset = CustomDataset(val_data, combined_table, device_indices, mask_sets)\n",
    "    test_dataset = CustomDataset(mnist_data_test, combined_table, device_indices, mask_sets)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Model initialization\n",
    "    model = ReadoutLayer(len(mask_sets)*196)\n",
    "    # Loss function, Categorical crossentropy loss for multi-class classification problem\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Optimizer to update the gradients.\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    val_accuracy, val_precision, val_recall, val_fscore = [], [], [], []\n",
    "    # Evaluation metrics\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "    precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "    recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "    f1_score = F1Score(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "    # Class-wise Confusion matrix\n",
    "    confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to device\n",
    "            outputs = model(images.float())  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Loss calculation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images.float())\n",
    "                preds = outputs.argmax(dim=1)\n",
    "\n",
    "                # Update metrics\n",
    "                accuracy.update(preds, labels)\n",
    "                precision.update(preds, labels)\n",
    "                recall.update(preds, labels)\n",
    "                f1_score.update(preds, labels)\n",
    "\n",
    "            # Print validation metrics\n",
    "            print(f'Validation Accuracy: {accuracy.compute().item():.4f} Precision: {precision.compute().item():.4f} ', end=\"\")\n",
    "            print(f'Validation Recall: {recall.compute().item():.4f} F1 Score: {f1_score.compute().item():.4f}')\n",
    "\n",
    "            # Updating the list to save current metrics\n",
    "            val_accuracy.append(accuracy.compute().item())\n",
    "            val_precision.append(precision.compute().item())\n",
    "            val_recall.append(recall.compute().item())\n",
    "            val_fscore.append(f1_score.compute().item())\n",
    "\n",
    "            # Reset metrics for the next epoch\n",
    "            accuracy.reset()\n",
    "            precision.reset()\n",
    "            recall.reset()\n",
    "            f1_score.reset()\n",
    "            confusion_matrix.reset()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Move images and labels to GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(torch.tensor(images, dtype=torch.float32))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Append predictions and labels for metric calculations\n",
    "            all_preds.append(predicted)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "\n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds).to(device)\n",
    "    all_labels = torch.cat(all_labels).to(device)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_accuracy = accuracy(all_preds, all_labels)\n",
    "    test_precision = precision(all_preds, all_labels)\n",
    "    test_recall = recall(all_preds, all_labels)\n",
    "    test_f1 = f1_score(all_preds, all_labels)\n",
    "    test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "    print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(test_confusion_matrix)\n",
    "\n",
    "    save_path = \"data/mnist_results_debug/\" + filename + '_' + ''.join(map(str, mask_sets)) + '.npz'\n",
    "    np.savez(save_path,\n",
    "            predictions = all_preds,\n",
    "            labels = all_labels,\n",
    "            validation_accuracy = val_accuracy,\n",
    "            validation_precision = val_precision,\n",
    "            validation_recall = val_recall,\n",
    "            validation_fscore = val_fscore\n",
    "            \n",
    "    )\n",
    "    return test_accuracy, test_precision, test_recall, test_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54000/54000 [00:37<00:00, 1422.21it/s]\n",
      "100%|██████████| 6000/6000 [00:03<00:00, 1575.69it/s]\n",
      "100%|██████████| 10000/10000 [00:06<00:00, 1579.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7824\n",
      "Validation Accuracy: 0.6785 Precision: 0.4860 Validation Recall: 0.6548 F1 Score: 0.5548\n",
      "Epoch [2/100], Loss: 1.6760\n",
      "Validation Accuracy: 0.7547 Precision: 0.6199 Validation Recall: 0.7330 F1 Score: 0.6656\n",
      "Epoch [3/100], Loss: 1.6372\n",
      "Validation Accuracy: 0.8217 Precision: 0.7532 Validation Recall: 0.8107 F1 Score: 0.7764\n",
      "Epoch [4/100], Loss: 1.6530\n",
      "Validation Accuracy: 0.8277 Precision: 0.7530 Validation Recall: 0.8172 F1 Score: 0.7811\n",
      "Epoch [5/100], Loss: 1.6649\n",
      "Validation Accuracy: 0.8272 Precision: 0.7568 Validation Recall: 0.8163 F1 Score: 0.7812\n",
      "Epoch [6/100], Loss: 1.6050\n",
      "Validation Accuracy: 0.8325 Precision: 0.7621 Validation Recall: 0.8233 F1 Score: 0.7875\n",
      "Epoch [7/100], Loss: 1.5860\n",
      "Validation Accuracy: 0.8308 Precision: 0.7592 Validation Recall: 0.8209 F1 Score: 0.7852\n",
      "Epoch [8/100], Loss: 1.6300\n",
      "Validation Accuracy: 0.8342 Precision: 0.7657 Validation Recall: 0.8240 F1 Score: 0.7895\n",
      "Epoch [9/100], Loss: 1.6615\n",
      "Validation Accuracy: 0.8328 Precision: 0.7628 Validation Recall: 0.8229 F1 Score: 0.7875\n",
      "Epoch [10/100], Loss: 1.6198\n",
      "Validation Accuracy: 0.8337 Precision: 0.7610 Validation Recall: 0.8243 F1 Score: 0.7880\n",
      "Epoch [11/100], Loss: 1.6908\n",
      "Validation Accuracy: 0.8363 Precision: 0.7675 Validation Recall: 0.8265 F1 Score: 0.7916\n",
      "Epoch [12/100], Loss: 1.6288\n",
      "Validation Accuracy: 0.8385 Precision: 0.7657 Validation Recall: 0.8292 F1 Score: 0.7929\n",
      "Epoch [13/100], Loss: 1.6569\n",
      "Validation Accuracy: 0.8375 Precision: 0.7659 Validation Recall: 0.8279 F1 Score: 0.7921\n",
      "Epoch [14/100], Loss: 1.7059\n",
      "Validation Accuracy: 0.8352 Precision: 0.7626 Validation Recall: 0.8258 F1 Score: 0.7896\n",
      "Epoch [15/100], Loss: 1.6188\n",
      "Validation Accuracy: 0.8368 Precision: 0.7628 Validation Recall: 0.8276 F1 Score: 0.7910\n",
      "Epoch [16/100], Loss: 1.6061\n",
      "Validation Accuracy: 0.8380 Precision: 0.7656 Validation Recall: 0.8283 F1 Score: 0.7925\n",
      "Epoch [17/100], Loss: 1.7204\n",
      "Validation Accuracy: 0.8345 Precision: 0.7648 Validation Recall: 0.8251 F1 Score: 0.7898\n",
      "Epoch [18/100], Loss: 1.6663\n",
      "Validation Accuracy: 0.8392 Precision: 0.7681 Validation Recall: 0.8298 F1 Score: 0.7941\n",
      "Epoch [19/100], Loss: 1.6829\n",
      "Validation Accuracy: 0.8373 Precision: 0.7675 Validation Recall: 0.8276 F1 Score: 0.7924\n",
      "Epoch [20/100], Loss: 1.6573\n",
      "Validation Accuracy: 0.8392 Precision: 0.7668 Validation Recall: 0.8293 F1 Score: 0.7934\n",
      "Epoch [21/100], Loss: 1.5653\n",
      "Validation Accuracy: 0.8375 Precision: 0.7673 Validation Recall: 0.8285 F1 Score: 0.7927\n",
      "Epoch [22/100], Loss: 1.6307\n",
      "Validation Accuracy: 0.8377 Precision: 0.7675 Validation Recall: 0.8278 F1 Score: 0.7926\n",
      "Epoch [23/100], Loss: 1.6837\n",
      "Validation Accuracy: 0.8383 Precision: 0.7672 Validation Recall: 0.8286 F1 Score: 0.7930\n",
      "Epoch [24/100], Loss: 1.5799\n",
      "Validation Accuracy: 0.8387 Precision: 0.7667 Validation Recall: 0.8292 F1 Score: 0.7931\n",
      "Epoch [25/100], Loss: 1.5936\n",
      "Validation Accuracy: 0.8380 Precision: 0.7713 Validation Recall: 0.8283 F1 Score: 0.7940\n",
      "Epoch [26/100], Loss: 1.7306\n",
      "Validation Accuracy: 0.8395 Precision: 0.7657 Validation Recall: 0.8300 F1 Score: 0.7936\n",
      "Epoch [27/100], Loss: 1.5999\n",
      "Validation Accuracy: 0.8377 Precision: 0.7709 Validation Recall: 0.8277 F1 Score: 0.7933\n",
      "Epoch [28/100], Loss: 1.7346\n",
      "Validation Accuracy: 0.8390 Precision: 0.7679 Validation Recall: 0.8292 F1 Score: 0.7937\n",
      "Epoch [29/100], Loss: 1.6613\n",
      "Validation Accuracy: 0.8377 Precision: 0.7661 Validation Recall: 0.8278 F1 Score: 0.7922\n",
      "Epoch [30/100], Loss: 1.5837\n",
      "Validation Accuracy: 0.8348 Precision: 0.7675 Validation Recall: 0.8247 F1 Score: 0.7903\n",
      "Epoch [31/100], Loss: 1.6026\n",
      "Validation Accuracy: 0.8383 Precision: 0.7664 Validation Recall: 0.8288 F1 Score: 0.7929\n",
      "Epoch [32/100], Loss: 1.6437\n",
      "Validation Accuracy: 0.8387 Precision: 0.7660 Validation Recall: 0.8295 F1 Score: 0.7932\n",
      "Epoch [33/100], Loss: 1.7380\n",
      "Validation Accuracy: 0.8377 Precision: 0.7676 Validation Recall: 0.8285 F1 Score: 0.7928\n",
      "Epoch [34/100], Loss: 1.6276\n",
      "Validation Accuracy: 0.8390 Precision: 0.7665 Validation Recall: 0.8295 F1 Score: 0.7935\n",
      "Epoch [35/100], Loss: 1.6083\n",
      "Validation Accuracy: 0.8390 Precision: 0.7682 Validation Recall: 0.8301 F1 Score: 0.7941\n",
      "Epoch [36/100], Loss: 1.5849\n",
      "Validation Accuracy: 0.8400 Precision: 0.7655 Validation Recall: 0.8306 F1 Score: 0.7940\n",
      "Epoch [37/100], Loss: 1.6000\n",
      "Validation Accuracy: 0.8392 Precision: 0.7696 Validation Recall: 0.8293 F1 Score: 0.7942\n",
      "Epoch [38/100], Loss: 1.6760\n",
      "Validation Accuracy: 0.8403 Precision: 0.7698 Validation Recall: 0.8310 F1 Score: 0.7953\n",
      "Epoch [39/100], Loss: 1.6182\n",
      "Validation Accuracy: 0.8400 Precision: 0.7683 Validation Recall: 0.8306 F1 Score: 0.7947\n",
      "Epoch [40/100], Loss: 1.6573\n",
      "Validation Accuracy: 0.8392 Precision: 0.7655 Validation Recall: 0.8300 F1 Score: 0.7932\n",
      "Epoch [41/100], Loss: 1.5738\n",
      "Validation Accuracy: 0.8387 Precision: 0.7685 Validation Recall: 0.8293 F1 Score: 0.7937\n",
      "Epoch [42/100], Loss: 1.6549\n",
      "Validation Accuracy: 0.8395 Precision: 0.7704 Validation Recall: 0.8300 F1 Score: 0.7949\n",
      "Epoch [43/100], Loss: 1.5861\n",
      "Validation Accuracy: 0.8387 Precision: 0.7655 Validation Recall: 0.8290 F1 Score: 0.7929\n",
      "Epoch [44/100], Loss: 1.5838\n",
      "Validation Accuracy: 0.8363 Precision: 0.7681 Validation Recall: 0.8262 F1 Score: 0.7914\n",
      "Epoch [45/100], Loss: 1.6414\n",
      "Validation Accuracy: 0.8412 Precision: 0.7694 Validation Recall: 0.8322 F1 Score: 0.7959\n",
      "Epoch [46/100], Loss: 1.5977\n",
      "Validation Accuracy: 0.8385 Precision: 0.7656 Validation Recall: 0.8291 F1 Score: 0.7929\n",
      "Epoch [47/100], Loss: 1.7067\n",
      "Validation Accuracy: 0.8390 Precision: 0.7672 Validation Recall: 0.8295 F1 Score: 0.7937\n",
      "Epoch [48/100], Loss: 1.5304\n",
      "Validation Accuracy: 0.8400 Precision: 0.7711 Validation Recall: 0.8309 F1 Score: 0.7956\n",
      "Epoch [49/100], Loss: 1.6037\n",
      "Validation Accuracy: 0.8405 Precision: 0.7701 Validation Recall: 0.8308 F1 Score: 0.7954\n",
      "Epoch [50/100], Loss: 1.6179\n",
      "Validation Accuracy: 0.8398 Precision: 0.7707 Validation Recall: 0.8303 F1 Score: 0.7952\n",
      "Epoch [51/100], Loss: 1.6105\n",
      "Validation Accuracy: 0.8392 Precision: 0.7652 Validation Recall: 0.8296 F1 Score: 0.7933\n",
      "Epoch [52/100], Loss: 1.6328\n",
      "Validation Accuracy: 0.8397 Precision: 0.7688 Validation Recall: 0.8305 F1 Score: 0.7946\n",
      "Epoch [53/100], Loss: 1.6677\n",
      "Validation Accuracy: 0.8392 Precision: 0.7655 Validation Recall: 0.8303 F1 Score: 0.7932\n",
      "Epoch [54/100], Loss: 1.5679\n",
      "Validation Accuracy: 0.8412 Precision: 0.7700 Validation Recall: 0.8316 F1 Score: 0.7959\n",
      "Epoch [55/100], Loss: 1.6102\n",
      "Validation Accuracy: 0.8392 Precision: 0.7677 Validation Recall: 0.8301 F1 Score: 0.7939\n",
      "Epoch [56/100], Loss: 1.6452\n",
      "Validation Accuracy: 0.8412 Precision: 0.7700 Validation Recall: 0.8317 F1 Score: 0.7960\n",
      "Epoch [57/100], Loss: 1.6301\n",
      "Validation Accuracy: 0.8408 Precision: 0.7673 Validation Recall: 0.8312 F1 Score: 0.7949\n",
      "Epoch [58/100], Loss: 1.6504\n",
      "Validation Accuracy: 0.8377 Precision: 0.7696 Validation Recall: 0.8283 F1 Score: 0.7931\n",
      "Epoch [59/100], Loss: 1.7129\n",
      "Validation Accuracy: 0.8403 Precision: 0.7668 Validation Recall: 0.8311 F1 Score: 0.7946\n",
      "Epoch [60/100], Loss: 1.6496\n",
      "Validation Accuracy: 0.8392 Precision: 0.7669 Validation Recall: 0.8298 F1 Score: 0.7937\n",
      "Epoch [61/100], Loss: 1.6231\n",
      "Validation Accuracy: 0.8398 Precision: 0.7669 Validation Recall: 0.8303 F1 Score: 0.7941\n",
      "Epoch [62/100], Loss: 1.6943\n",
      "Validation Accuracy: 0.8398 Precision: 0.7699 Validation Recall: 0.8300 F1 Score: 0.7948\n",
      "Epoch [63/100], Loss: 1.6826\n",
      "Validation Accuracy: 0.8413 Precision: 0.7718 Validation Recall: 0.8322 F1 Score: 0.7967\n",
      "Epoch [64/100], Loss: 1.6285\n",
      "Validation Accuracy: 0.8402 Precision: 0.7716 Validation Recall: 0.8309 F1 Score: 0.7958\n",
      "Epoch [65/100], Loss: 1.6428\n",
      "Validation Accuracy: 0.8405 Precision: 0.7647 Validation Recall: 0.8314 F1 Score: 0.7941\n",
      "Epoch [66/100], Loss: 1.6190\n",
      "Validation Accuracy: 0.8407 Precision: 0.7674 Validation Recall: 0.8312 F1 Score: 0.7949\n",
      "Epoch [67/100], Loss: 1.7670\n",
      "Validation Accuracy: 0.8407 Precision: 0.7734 Validation Recall: 0.8311 F1 Score: 0.7967\n",
      "Epoch [68/100], Loss: 1.6287\n",
      "Validation Accuracy: 0.8405 Precision: 0.7714 Validation Recall: 0.8311 F1 Score: 0.7959\n",
      "Epoch [69/100], Loss: 1.5277\n",
      "Validation Accuracy: 0.8415 Precision: 0.7714 Validation Recall: 0.8319 F1 Score: 0.7966\n",
      "Epoch [70/100], Loss: 1.5743\n",
      "Validation Accuracy: 0.8392 Precision: 0.7678 Validation Recall: 0.8302 F1 Score: 0.7940\n",
      "Epoch [71/100], Loss: 1.6935\n",
      "Validation Accuracy: 0.8413 Precision: 0.7693 Validation Recall: 0.8317 F1 Score: 0.7959\n",
      "Epoch [72/100], Loss: 1.5797\n",
      "Validation Accuracy: 0.8407 Precision: 0.7671 Validation Recall: 0.8309 F1 Score: 0.7948\n",
      "Epoch [73/100], Loss: 1.6588\n",
      "Validation Accuracy: 0.8423 Precision: 0.7717 Validation Recall: 0.8328 F1 Score: 0.7973\n",
      "Epoch [74/100], Loss: 1.6091\n",
      "Validation Accuracy: 0.8412 Precision: 0.7681 Validation Recall: 0.8321 F1 Score: 0.7955\n",
      "Epoch [75/100], Loss: 1.5929\n",
      "Validation Accuracy: 0.8403 Precision: 0.7704 Validation Recall: 0.8312 F1 Score: 0.7954\n",
      "Epoch [76/100], Loss: 1.6531\n",
      "Validation Accuracy: 0.8398 Precision: 0.7672 Validation Recall: 0.8306 F1 Score: 0.7943\n",
      "Epoch [77/100], Loss: 1.6918\n",
      "Validation Accuracy: 0.8393 Precision: 0.7676 Validation Recall: 0.8303 F1 Score: 0.7941\n",
      "Epoch [78/100], Loss: 1.6779\n",
      "Validation Accuracy: 0.8397 Precision: 0.7693 Validation Recall: 0.8308 F1 Score: 0.7948\n",
      "Epoch [79/100], Loss: 1.5982\n",
      "Validation Accuracy: 0.8422 Precision: 0.7691 Validation Recall: 0.8329 F1 Score: 0.7966\n",
      "Epoch [80/100], Loss: 1.5765\n",
      "Validation Accuracy: 0.8423 Precision: 0.7700 Validation Recall: 0.8335 F1 Score: 0.7970\n",
      "Epoch [81/100], Loss: 1.5404\n",
      "Validation Accuracy: 0.8410 Precision: 0.7686 Validation Recall: 0.8315 F1 Score: 0.7955\n",
      "Epoch [82/100], Loss: 1.5558\n",
      "Validation Accuracy: 0.8413 Precision: 0.7724 Validation Recall: 0.8320 F1 Score: 0.7968\n",
      "Epoch [83/100], Loss: 1.6676\n",
      "Validation Accuracy: 0.8420 Precision: 0.7731 Validation Recall: 0.8324 F1 Score: 0.7975\n",
      "Epoch [84/100], Loss: 1.5979\n",
      "Validation Accuracy: 0.8423 Precision: 0.7721 Validation Recall: 0.8330 F1 Score: 0.7974\n",
      "Epoch [85/100], Loss: 1.6127\n",
      "Validation Accuracy: 0.8420 Precision: 0.7713 Validation Recall: 0.8330 F1 Score: 0.7971\n",
      "Epoch [86/100], Loss: 1.6983\n",
      "Validation Accuracy: 0.8415 Precision: 0.7707 Validation Recall: 0.8326 F1 Score: 0.7964\n",
      "Epoch [87/100], Loss: 1.7275\n",
      "Validation Accuracy: 0.8428 Precision: 0.7737 Validation Recall: 0.8339 F1 Score: 0.7985\n",
      "Epoch [88/100], Loss: 1.5745\n",
      "Validation Accuracy: 0.8422 Precision: 0.7711 Validation Recall: 0.8324 F1 Score: 0.7969\n",
      "Epoch [89/100], Loss: 1.6724\n",
      "Validation Accuracy: 0.8425 Precision: 0.7680 Validation Recall: 0.8337 F1 Score: 0.7966\n",
      "Epoch [90/100], Loss: 1.5368\n",
      "Validation Accuracy: 0.8418 Precision: 0.7719 Validation Recall: 0.8322 F1 Score: 0.7969\n",
      "Epoch [91/100], Loss: 1.5923\n",
      "Validation Accuracy: 0.8433 Precision: 0.7719 Validation Recall: 0.8342 F1 Score: 0.7982\n",
      "Epoch [92/100], Loss: 1.6502\n",
      "Validation Accuracy: 0.8430 Precision: 0.7735 Validation Recall: 0.8337 F1 Score: 0.7984\n",
      "Epoch [93/100], Loss: 1.5752\n",
      "Validation Accuracy: 0.8412 Precision: 0.7677 Validation Recall: 0.8323 F1 Score: 0.7954\n",
      "Epoch [94/100], Loss: 1.6162\n",
      "Validation Accuracy: 0.8417 Precision: 0.7693 Validation Recall: 0.8323 F1 Score: 0.7962\n",
      "Epoch [95/100], Loss: 1.6726\n",
      "Validation Accuracy: 0.8427 Precision: 0.7718 Validation Recall: 0.8335 F1 Score: 0.7977\n",
      "Epoch [96/100], Loss: 1.5718\n",
      "Validation Accuracy: 0.8415 Precision: 0.7722 Validation Recall: 0.8318 F1 Score: 0.7968\n",
      "Epoch [97/100], Loss: 1.7841\n",
      "Validation Accuracy: 0.8400 Precision: 0.7686 Validation Recall: 0.8309 F1 Score: 0.7947\n",
      "Epoch [98/100], Loss: 1.5274\n",
      "Validation Accuracy: 0.8415 Precision: 0.7710 Validation Recall: 0.8320 F1 Score: 0.7965\n",
      "Epoch [99/100], Loss: 1.6118\n",
      "Validation Accuracy: 0.8430 Precision: 0.7730 Validation Recall: 0.8336 F1 Score: 0.7983\n",
      "Epoch [100/100], Loss: 1.6277\n",
      "Validation Accuracy: 0.8423 Precision: 0.7728 Validation Recall: 0.8327 F1 Score: 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_26748\\2658863303.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.95%\n",
      "Test Precision: 77.3635%\n",
      "Test Recall: 83.9154%\n",
      "Test F1 Score: 0.8000\n",
      "Confusion Matrix:\n",
      "tensor([[ 962,    0,    0,    5,    0,    3,    4,    2,    4,    0],\n",
      "        [   0, 1112,    4,    2,    0,    3,    4,    1,    9,    0],\n",
      "        [  15,    4,  916,   15,   17,    3,   15,   13,   34,    0],\n",
      "        [   3,    1,   15,  922,    3,   21,    1,   15,   29,    0],\n",
      "        [   2,    2,    2,    2,  949,    1,   11,    9,    4,    0],\n",
      "        [  10,    5,    3,   41,   15,  763,   13,    4,   38,    0],\n",
      "        [  14,    4,    8,    1,    8,   15,  903,    2,    3,    0],\n",
      "        [   2,   10,   21,    5,   15,    0,    1,  974,    0,    0],\n",
      "        [   2,    6,    3,   20,   17,   14,    9,    9,  894,    0],\n",
      "        [   8,    5,    0,   12,  568,   25,    1,  325,   65,    0]])\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, fscore = get_metrics(filename=\"365nm\", mask_sets=[0, 1, 2, 3], device_indices=torch.randint(0, 5, (4, 196)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_combinations(lis):\n",
    "    all_combinations = []\n",
    "    for r in range(1, len(lis)+1):\n",
    "        combs = list(itertools.combinations(lis, r))\n",
    "        all_combinations.extend(combs)\n",
    "    return [list(ele) for ele in all_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54000/54000 [03:25<00:00, 262.69it/s]\n",
      "100%|██████████| 6000/6000 [00:22<00:00, 266.12it/s]\n",
      "100%|██████████| 10000/10000 [00:38<00:00, 263.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.0585\n",
      "Validation Accuracy: 0.5460 Precision: 0.3341 Validation Recall: 0.5283 F1 Score: 0.4063\n",
      "Epoch [2/100], Loss: 2.0079\n",
      "Validation Accuracy: 0.5568 Precision: 0.3421 Validation Recall: 0.5395 F1 Score: 0.4155\n",
      "Epoch [3/100], Loss: 1.8727\n",
      "Validation Accuracy: 0.5615 Precision: 0.3422 Validation Recall: 0.5438 F1 Score: 0.4179\n",
      "Epoch [4/100], Loss: 1.8594\n",
      "Validation Accuracy: 0.6467 Precision: 0.4642 Validation Recall: 0.6328 F1 Score: 0.5318\n",
      "Epoch [5/100], Loss: 1.7686\n",
      "Validation Accuracy: 0.6928 Precision: 0.5736 Validation Recall: 0.6793 F1 Score: 0.6083\n",
      "Epoch [6/100], Loss: 1.7550\n",
      "Validation Accuracy: 0.7215 Precision: 0.5876 Validation Recall: 0.7080 F1 Score: 0.6387\n",
      "Epoch [7/100], Loss: 1.7963\n",
      "Validation Accuracy: 0.7245 Precision: 0.5893 Validation Recall: 0.7111 F1 Score: 0.6409\n",
      "Epoch [8/100], Loss: 1.8111\n",
      "Validation Accuracy: 0.7262 Precision: 0.5918 Validation Recall: 0.7128 F1 Score: 0.6428\n",
      "Epoch [9/100], Loss: 1.7984\n",
      "Validation Accuracy: 0.7248 Precision: 0.5937 Validation Recall: 0.7119 F1 Score: 0.6419\n",
      "Epoch [10/100], Loss: 1.7363\n",
      "Validation Accuracy: 0.7287 Precision: 0.5958 Validation Recall: 0.7156 F1 Score: 0.6458\n",
      "Epoch [11/100], Loss: 1.6899\n",
      "Validation Accuracy: 0.7305 Precision: 0.5937 Validation Recall: 0.7172 F1 Score: 0.6463\n",
      "Epoch [12/100], Loss: 1.8125\n",
      "Validation Accuracy: 0.7288 Precision: 0.5935 Validation Recall: 0.7155 F1 Score: 0.6453\n",
      "Epoch [13/100], Loss: 1.8192\n",
      "Validation Accuracy: 0.7295 Precision: 0.5951 Validation Recall: 0.7164 F1 Score: 0.6462\n",
      "Epoch [14/100], Loss: 1.7434\n",
      "Validation Accuracy: 0.7315 Precision: 0.5951 Validation Recall: 0.7183 F1 Score: 0.6473\n",
      "Epoch [15/100], Loss: 1.6959\n",
      "Validation Accuracy: 0.7348 Precision: 0.5986 Validation Recall: 0.7216 F1 Score: 0.6508\n",
      "Epoch [16/100], Loss: 1.7463\n",
      "Validation Accuracy: 0.7332 Precision: 0.5983 Validation Recall: 0.7199 F1 Score: 0.6495\n",
      "Epoch [17/100], Loss: 1.7636\n",
      "Validation Accuracy: 0.7337 Precision: 0.5976 Validation Recall: 0.7204 F1 Score: 0.6498\n",
      "Epoch [18/100], Loss: 1.7593\n",
      "Validation Accuracy: 0.7335 Precision: 0.6005 Validation Recall: 0.7203 F1 Score: 0.6505\n",
      "Epoch [19/100], Loss: 1.6978\n",
      "Validation Accuracy: 0.7333 Precision: 0.5984 Validation Recall: 0.7202 F1 Score: 0.6495\n",
      "Epoch [20/100], Loss: 1.8079\n",
      "Validation Accuracy: 0.7352 Precision: 0.5995 Validation Recall: 0.7220 F1 Score: 0.6513\n",
      "Epoch [21/100], Loss: 1.7236\n",
      "Validation Accuracy: 0.7578 Precision: 0.6920 Validation Recall: 0.7461 F1 Score: 0.7020\n",
      "Epoch [22/100], Loss: 1.7552\n",
      "Validation Accuracy: 0.7672 Precision: 0.6986 Validation Recall: 0.7561 F1 Score: 0.7163\n",
      "Epoch [23/100], Loss: 1.7066\n",
      "Validation Accuracy: 0.7755 Precision: 0.7076 Validation Recall: 0.7648 F1 Score: 0.7263\n",
      "Epoch [24/100], Loss: 1.7674\n",
      "Validation Accuracy: 0.7830 Precision: 0.7128 Validation Recall: 0.7726 F1 Score: 0.7366\n",
      "Epoch [25/100], Loss: 1.6869\n",
      "Validation Accuracy: 0.7865 Precision: 0.7168 Validation Recall: 0.7765 F1 Score: 0.7410\n",
      "Epoch [26/100], Loss: 1.6483\n",
      "Validation Accuracy: 0.7893 Precision: 0.7202 Validation Recall: 0.7793 F1 Score: 0.7436\n",
      "Epoch [27/100], Loss: 1.6642\n",
      "Validation Accuracy: 0.7897 Precision: 0.7205 Validation Recall: 0.7798 F1 Score: 0.7441\n",
      "Epoch [28/100], Loss: 1.7297\n",
      "Validation Accuracy: 0.7918 Precision: 0.7222 Validation Recall: 0.7824 F1 Score: 0.7468\n",
      "Epoch [29/100], Loss: 1.6341\n",
      "Validation Accuracy: 0.7940 Precision: 0.7248 Validation Recall: 0.7845 F1 Score: 0.7494\n",
      "Epoch [30/100], Loss: 1.7935\n",
      "Validation Accuracy: 0.7933 Precision: 0.7237 Validation Recall: 0.7838 F1 Score: 0.7485\n",
      "Epoch [31/100], Loss: 1.7214\n",
      "Validation Accuracy: 0.7945 Precision: 0.7251 Validation Recall: 0.7852 F1 Score: 0.7499\n",
      "Epoch [32/100], Loss: 1.7512\n",
      "Validation Accuracy: 0.7977 Precision: 0.7290 Validation Recall: 0.7884 F1 Score: 0.7532\n",
      "Epoch [33/100], Loss: 1.7887\n",
      "Validation Accuracy: 0.7958 Precision: 0.7280 Validation Recall: 0.7864 F1 Score: 0.7513\n",
      "Epoch [34/100], Loss: 1.7607\n",
      "Validation Accuracy: 0.7955 Precision: 0.7282 Validation Recall: 0.7860 F1 Score: 0.7513\n",
      "Epoch [35/100], Loss: 1.6356\n",
      "Validation Accuracy: 0.7955 Precision: 0.7266 Validation Recall: 0.7863 F1 Score: 0.7509\n",
      "Epoch [36/100], Loss: 1.7267\n",
      "Validation Accuracy: 0.7960 Precision: 0.7267 Validation Recall: 0.7867 F1 Score: 0.7510\n",
      "Epoch [37/100], Loss: 1.5836\n",
      "Validation Accuracy: 0.7967 Precision: 0.7276 Validation Recall: 0.7873 F1 Score: 0.7518\n",
      "Epoch [38/100], Loss: 1.7924\n",
      "Validation Accuracy: 0.7978 Precision: 0.7291 Validation Recall: 0.7886 F1 Score: 0.7537\n",
      "Epoch [39/100], Loss: 1.6122\n",
      "Validation Accuracy: 0.7997 Precision: 0.7324 Validation Recall: 0.7903 F1 Score: 0.7556\n",
      "Epoch [40/100], Loss: 1.5917\n",
      "Validation Accuracy: 0.7990 Precision: 0.7305 Validation Recall: 0.7898 F1 Score: 0.7547\n",
      "Epoch [41/100], Loss: 1.6636\n",
      "Validation Accuracy: 0.8003 Precision: 0.7306 Validation Recall: 0.7910 F1 Score: 0.7559\n",
      "Epoch [42/100], Loss: 1.7452\n",
      "Validation Accuracy: 0.7992 Precision: 0.7308 Validation Recall: 0.7899 F1 Score: 0.7552\n",
      "Epoch [43/100], Loss: 1.6455\n",
      "Validation Accuracy: 0.7995 Precision: 0.7298 Validation Recall: 0.7901 F1 Score: 0.7548\n",
      "Epoch [44/100], Loss: 1.6808\n",
      "Validation Accuracy: 0.7995 Precision: 0.7310 Validation Recall: 0.7900 F1 Score: 0.7551\n",
      "Epoch [45/100], Loss: 1.7685\n",
      "Validation Accuracy: 0.8002 Precision: 0.7306 Validation Recall: 0.7909 F1 Score: 0.7557\n",
      "Epoch [46/100], Loss: 1.6568\n",
      "Validation Accuracy: 0.7997 Precision: 0.7314 Validation Recall: 0.7904 F1 Score: 0.7556\n",
      "Epoch [47/100], Loss: 1.6567\n",
      "Validation Accuracy: 0.8005 Precision: 0.7320 Validation Recall: 0.7912 F1 Score: 0.7560\n",
      "Epoch [48/100], Loss: 1.6580\n",
      "Validation Accuracy: 0.8002 Precision: 0.7308 Validation Recall: 0.7910 F1 Score: 0.7556\n",
      "Epoch [49/100], Loss: 1.6281\n",
      "Validation Accuracy: 0.8005 Precision: 0.7319 Validation Recall: 0.7911 F1 Score: 0.7564\n",
      "Epoch [50/100], Loss: 1.5660\n",
      "Validation Accuracy: 0.8017 Precision: 0.7328 Validation Recall: 0.7926 F1 Score: 0.7576\n",
      "Epoch [51/100], Loss: 1.6434\n",
      "Validation Accuracy: 0.8015 Precision: 0.7327 Validation Recall: 0.7925 F1 Score: 0.7573\n",
      "Epoch [52/100], Loss: 1.6911\n",
      "Validation Accuracy: 0.8047 Precision: 0.7343 Validation Recall: 0.7954 F1 Score: 0.7603\n",
      "Epoch [53/100], Loss: 1.6384\n",
      "Validation Accuracy: 0.8008 Precision: 0.7333 Validation Recall: 0.7917 F1 Score: 0.7570\n",
      "Epoch [54/100], Loss: 1.5885\n",
      "Validation Accuracy: 0.8028 Precision: 0.7353 Validation Recall: 0.7936 F1 Score: 0.7590\n",
      "Epoch [55/100], Loss: 1.6771\n",
      "Validation Accuracy: 0.8002 Precision: 0.7324 Validation Recall: 0.7907 F1 Score: 0.7560\n",
      "Epoch [56/100], Loss: 1.6778\n",
      "Validation Accuracy: 0.8017 Precision: 0.7327 Validation Recall: 0.7926 F1 Score: 0.7575\n",
      "Epoch [57/100], Loss: 1.5894\n",
      "Validation Accuracy: 0.8037 Precision: 0.7367 Validation Recall: 0.7944 F1 Score: 0.7598\n",
      "Epoch [58/100], Loss: 1.6990\n",
      "Validation Accuracy: 0.8030 Precision: 0.7346 Validation Recall: 0.7937 F1 Score: 0.7590\n",
      "Epoch [59/100], Loss: 1.6509\n",
      "Validation Accuracy: 0.8022 Precision: 0.7346 Validation Recall: 0.7930 F1 Score: 0.7582\n",
      "Epoch [60/100], Loss: 1.6462\n",
      "Validation Accuracy: 0.8042 Precision: 0.7357 Validation Recall: 0.7950 F1 Score: 0.7601\n",
      "Epoch [61/100], Loss: 1.6432\n",
      "Validation Accuracy: 0.8048 Precision: 0.7332 Validation Recall: 0.7957 F1 Score: 0.7600\n",
      "Epoch [62/100], Loss: 1.6866\n",
      "Validation Accuracy: 0.8043 Precision: 0.7372 Validation Recall: 0.7952 F1 Score: 0.7606\n",
      "Epoch [63/100], Loss: 1.7220\n",
      "Validation Accuracy: 0.8048 Precision: 0.7361 Validation Recall: 0.7957 F1 Score: 0.7607\n",
      "Epoch [64/100], Loss: 1.6319\n",
      "Validation Accuracy: 0.8030 Precision: 0.7350 Validation Recall: 0.7938 F1 Score: 0.7591\n",
      "Epoch [65/100], Loss: 1.7092\n",
      "Validation Accuracy: 0.8042 Precision: 0.7366 Validation Recall: 0.7952 F1 Score: 0.7603\n",
      "Epoch [66/100], Loss: 1.6707\n",
      "Validation Accuracy: 0.8045 Precision: 0.7345 Validation Recall: 0.7952 F1 Score: 0.7601\n",
      "Epoch [67/100], Loss: 1.7457\n",
      "Validation Accuracy: 0.8055 Precision: 0.7375 Validation Recall: 0.7965 F1 Score: 0.7616\n",
      "Epoch [68/100], Loss: 1.6244\n",
      "Validation Accuracy: 0.8038 Precision: 0.7346 Validation Recall: 0.7947 F1 Score: 0.7595\n",
      "Epoch [69/100], Loss: 1.7035\n",
      "Validation Accuracy: 0.8045 Precision: 0.7351 Validation Recall: 0.7954 F1 Score: 0.7604\n",
      "Epoch [70/100], Loss: 1.6758\n",
      "Validation Accuracy: 0.8033 Precision: 0.7352 Validation Recall: 0.7941 F1 Score: 0.7594\n",
      "Epoch [71/100], Loss: 1.7313\n",
      "Validation Accuracy: 0.8045 Precision: 0.7344 Validation Recall: 0.7954 F1 Score: 0.7601\n",
      "Epoch [72/100], Loss: 1.6016\n",
      "Validation Accuracy: 0.8037 Precision: 0.7352 Validation Recall: 0.7945 F1 Score: 0.7597\n",
      "Epoch [73/100], Loss: 1.6356\n",
      "Validation Accuracy: 0.8033 Precision: 0.7343 Validation Recall: 0.7943 F1 Score: 0.7591\n",
      "Epoch [74/100], Loss: 1.6727\n",
      "Validation Accuracy: 0.8038 Precision: 0.7357 Validation Recall: 0.7949 F1 Score: 0.7601\n",
      "Epoch [75/100], Loss: 1.6128\n",
      "Validation Accuracy: 0.8055 Precision: 0.7375 Validation Recall: 0.7964 F1 Score: 0.7615\n",
      "Epoch [76/100], Loss: 1.6005\n",
      "Validation Accuracy: 0.8053 Precision: 0.7371 Validation Recall: 0.7961 F1 Score: 0.7613\n",
      "Epoch [77/100], Loss: 1.5984\n",
      "Validation Accuracy: 0.8053 Precision: 0.7357 Validation Recall: 0.7964 F1 Score: 0.7610\n",
      "Epoch [78/100], Loss: 1.6496\n",
      "Validation Accuracy: 0.8052 Precision: 0.7358 Validation Recall: 0.7962 F1 Score: 0.7610\n",
      "Epoch [79/100], Loss: 1.6338\n",
      "Validation Accuracy: 0.8040 Precision: 0.7353 Validation Recall: 0.7948 F1 Score: 0.7599\n",
      "Epoch [80/100], Loss: 1.6327\n",
      "Validation Accuracy: 0.8047 Precision: 0.7366 Validation Recall: 0.7956 F1 Score: 0.7608\n",
      "Epoch [81/100], Loss: 1.6990\n",
      "Validation Accuracy: 0.8062 Precision: 0.7359 Validation Recall: 0.7971 F1 Score: 0.7616\n",
      "Epoch [82/100], Loss: 1.6697\n",
      "Validation Accuracy: 0.8052 Precision: 0.7353 Validation Recall: 0.7960 F1 Score: 0.7608\n",
      "Epoch [83/100], Loss: 1.6693\n",
      "Validation Accuracy: 0.8042 Precision: 0.7351 Validation Recall: 0.7950 F1 Score: 0.7600\n",
      "Epoch [84/100], Loss: 1.6534\n",
      "Validation Accuracy: 0.8055 Precision: 0.7363 Validation Recall: 0.7965 F1 Score: 0.7615\n",
      "Epoch [85/100], Loss: 1.6818\n",
      "Validation Accuracy: 0.8053 Precision: 0.7385 Validation Recall: 0.7964 F1 Score: 0.7619\n",
      "Epoch [86/100], Loss: 1.6474\n",
      "Validation Accuracy: 0.8057 Precision: 0.7360 Validation Recall: 0.7964 F1 Score: 0.7612\n",
      "Epoch [87/100], Loss: 1.5846\n",
      "Validation Accuracy: 0.8063 Precision: 0.7372 Validation Recall: 0.7973 F1 Score: 0.7622\n",
      "Epoch [88/100], Loss: 1.7066\n",
      "Validation Accuracy: 0.8038 Precision: 0.7358 Validation Recall: 0.7949 F1 Score: 0.7600\n",
      "Epoch [89/100], Loss: 1.6413\n",
      "Validation Accuracy: 0.8065 Precision: 0.7387 Validation Recall: 0.7975 F1 Score: 0.7626\n",
      "Epoch [90/100], Loss: 1.6484\n",
      "Validation Accuracy: 0.8063 Precision: 0.7380 Validation Recall: 0.7974 F1 Score: 0.7625\n",
      "Epoch [91/100], Loss: 1.7628\n",
      "Validation Accuracy: 0.8050 Precision: 0.7361 Validation Recall: 0.7959 F1 Score: 0.7608\n",
      "Epoch [92/100], Loss: 1.5890\n",
      "Validation Accuracy: 0.8067 Precision: 0.7381 Validation Recall: 0.7975 F1 Score: 0.7627\n",
      "Epoch [93/100], Loss: 1.6474\n",
      "Validation Accuracy: 0.8068 Precision: 0.7375 Validation Recall: 0.7978 F1 Score: 0.7629\n",
      "Epoch [94/100], Loss: 1.6630\n",
      "Validation Accuracy: 0.8057 Precision: 0.7372 Validation Recall: 0.7966 F1 Score: 0.7618\n",
      "Epoch [95/100], Loss: 1.6850\n",
      "Validation Accuracy: 0.8067 Precision: 0.7373 Validation Recall: 0.7976 F1 Score: 0.7625\n",
      "Epoch [96/100], Loss: 1.6112\n",
      "Validation Accuracy: 0.8065 Precision: 0.7370 Validation Recall: 0.7974 F1 Score: 0.7625\n",
      "Epoch [97/100], Loss: 1.6751\n",
      "Validation Accuracy: 0.8068 Precision: 0.7387 Validation Recall: 0.7978 F1 Score: 0.7627\n",
      "Epoch [98/100], Loss: 1.6375\n",
      "Validation Accuracy: 0.8063 Precision: 0.7382 Validation Recall: 0.7974 F1 Score: 0.7625\n",
      "Epoch [99/100], Loss: 1.7081\n",
      "Validation Accuracy: 0.8058 Precision: 0.7384 Validation Recall: 0.7969 F1 Score: 0.7622\n",
      "Epoch [100/100], Loss: 1.6065\n",
      "Validation Accuracy: 0.8065 Precision: 0.7382 Validation Recall: 0.7975 F1 Score: 0.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_27520\\3621217840.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 80.95%\n",
      "Test Precision: 74.4073%\n",
      "Test Recall: 80.8918%\n",
      "Test F1 Score: 0.7703\n",
      "Confusion Matrix:\n",
      "tensor([[ 943,    0,    4,    6,    2,   11,    7,    1,    6,    0],\n",
      "        [   0, 1076,    6,    8,    2,    3,    4,    1,   35,    0],\n",
      "        [  16,    9,  878,   26,   16,    3,   23,   14,   47,    0],\n",
      "        [   9,    4,   29,  874,    1,   31,    6,   18,   38,    0],\n",
      "        [   5,    2,    2,    0,  942,    4,   14,    6,    7,    0],\n",
      "        [  12,    6,    8,   51,   21,  711,   19,   17,   47,    0],\n",
      "        [  11,    7,    8,    3,   12,   17,  897,    0,    3,    0],\n",
      "        [   2,   15,   26,   10,   17,    5,    1,  950,    2,    0],\n",
      "        [   9,   11,   12,   26,   20,   42,   14,   16,  824,    0],\n",
      "        [  14,    8,    4,    8,  577,   28,    3,  305,   62,    0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54000/54000 [02:54<00:00, 308.67it/s]\n",
      "100%|██████████| 6000/6000 [00:19<00:00, 314.71it/s]\n",
      "100%|██████████| 10000/10000 [00:32<00:00, 310.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.8341\n",
      "Validation Accuracy: 0.6545 Precision: 0.5313 Validation Recall: 0.6477 F1 Score: 0.5809\n",
      "Epoch [2/100], Loss: 1.7685\n",
      "Validation Accuracy: 0.6753 Precision: 0.5465 Validation Recall: 0.6674 F1 Score: 0.5986\n",
      "Epoch [3/100], Loss: 1.8306\n",
      "Validation Accuracy: 0.6842 Precision: 0.5575 Validation Recall: 0.6764 F1 Score: 0.6081\n",
      "Epoch [4/100], Loss: 1.7645\n",
      "Validation Accuracy: 0.6882 Precision: 0.5593 Validation Recall: 0.6814 F1 Score: 0.6114\n",
      "Epoch [5/100], Loss: 1.9042\n",
      "Validation Accuracy: 0.6923 Precision: 0.5679 Validation Recall: 0.6857 F1 Score: 0.6170\n",
      "Epoch [6/100], Loss: 1.6923\n",
      "Validation Accuracy: 0.7732 Precision: 0.7035 Validation Recall: 0.7656 F1 Score: 0.7313\n",
      "Epoch [7/100], Loss: 1.6448\n",
      "Validation Accuracy: 0.7762 Precision: 0.7057 Validation Recall: 0.7687 F1 Score: 0.7338\n",
      "Epoch [8/100], Loss: 1.7582\n",
      "Validation Accuracy: 0.7807 Precision: 0.7128 Validation Recall: 0.7735 F1 Score: 0.7392\n",
      "Epoch [9/100], Loss: 1.7323\n",
      "Validation Accuracy: 0.7830 Precision: 0.7141 Validation Recall: 0.7758 F1 Score: 0.7411\n",
      "Epoch [10/100], Loss: 1.6381\n",
      "Validation Accuracy: 0.7815 Precision: 0.7130 Validation Recall: 0.7743 F1 Score: 0.7400\n",
      "Epoch [11/100], Loss: 1.7356\n",
      "Validation Accuracy: 0.7818 Precision: 0.7130 Validation Recall: 0.7742 F1 Score: 0.7401\n",
      "Epoch [12/100], Loss: 1.6980\n",
      "Validation Accuracy: 0.7835 Precision: 0.7128 Validation Recall: 0.7765 F1 Score: 0.7412\n",
      "Epoch [13/100], Loss: 1.6265\n",
      "Validation Accuracy: 0.7850 Precision: 0.7142 Validation Recall: 0.7776 F1 Score: 0.7426\n",
      "Epoch [14/100], Loss: 1.6786\n",
      "Validation Accuracy: 0.7850 Precision: 0.7128 Validation Recall: 0.7772 F1 Score: 0.7420\n",
      "Epoch [15/100], Loss: 1.6632\n",
      "Validation Accuracy: 0.7868 Precision: 0.7184 Validation Recall: 0.7795 F1 Score: 0.7452\n",
      "Epoch [16/100], Loss: 1.6753\n",
      "Validation Accuracy: 0.7863 Precision: 0.7172 Validation Recall: 0.7791 F1 Score: 0.7445\n",
      "Epoch [17/100], Loss: 1.6457\n",
      "Validation Accuracy: 0.7862 Precision: 0.7182 Validation Recall: 0.7792 F1 Score: 0.7447\n",
      "Epoch [18/100], Loss: 1.6421\n",
      "Validation Accuracy: 0.7872 Precision: 0.7180 Validation Recall: 0.7800 F1 Score: 0.7454\n",
      "Epoch [19/100], Loss: 1.6778\n",
      "Validation Accuracy: 0.7868 Precision: 0.7174 Validation Recall: 0.7796 F1 Score: 0.7449\n",
      "Epoch [20/100], Loss: 1.7058\n",
      "Validation Accuracy: 0.7867 Precision: 0.7189 Validation Recall: 0.7792 F1 Score: 0.7452\n",
      "Epoch [21/100], Loss: 1.6884\n",
      "Validation Accuracy: 0.7878 Precision: 0.7208 Validation Recall: 0.7808 F1 Score: 0.7466\n",
      "Epoch [22/100], Loss: 1.6966\n",
      "Validation Accuracy: 0.7888 Precision: 0.7179 Validation Recall: 0.7816 F1 Score: 0.7463\n",
      "Epoch [23/100], Loss: 1.6963\n",
      "Validation Accuracy: 0.7878 Precision: 0.7202 Validation Recall: 0.7808 F1 Score: 0.7464\n",
      "Epoch [24/100], Loss: 1.6893\n",
      "Validation Accuracy: 0.7882 Precision: 0.7188 Validation Recall: 0.7810 F1 Score: 0.7462\n",
      "Epoch [25/100], Loss: 1.7118\n",
      "Validation Accuracy: 0.7895 Precision: 0.7223 Validation Recall: 0.7824 F1 Score: 0.7483\n",
      "Epoch [26/100], Loss: 1.7403\n",
      "Validation Accuracy: 0.7897 Precision: 0.7207 Validation Recall: 0.7825 F1 Score: 0.7479\n",
      "Epoch [27/100], Loss: 1.6262\n",
      "Validation Accuracy: 0.7912 Precision: 0.7205 Validation Recall: 0.7838 F1 Score: 0.7488\n",
      "Epoch [28/100], Loss: 1.7288\n",
      "Validation Accuracy: 0.7902 Precision: 0.7206 Validation Recall: 0.7830 F1 Score: 0.7482\n",
      "Epoch [29/100], Loss: 1.7161\n",
      "Validation Accuracy: 0.7903 Precision: 0.7214 Validation Recall: 0.7831 F1 Score: 0.7485\n",
      "Epoch [30/100], Loss: 1.5548\n",
      "Validation Accuracy: 0.7903 Precision: 0.7228 Validation Recall: 0.7831 F1 Score: 0.7488\n",
      "Epoch [31/100], Loss: 1.6751\n",
      "Validation Accuracy: 0.7878 Precision: 0.7204 Validation Recall: 0.7807 F1 Score: 0.7466\n",
      "Epoch [32/100], Loss: 1.7868\n",
      "Validation Accuracy: 0.7900 Precision: 0.7191 Validation Recall: 0.7827 F1 Score: 0.7476\n",
      "Epoch [33/100], Loss: 1.6391\n",
      "Validation Accuracy: 0.7898 Precision: 0.7224 Validation Recall: 0.7825 F1 Score: 0.7484\n",
      "Epoch [34/100], Loss: 1.6474\n",
      "Validation Accuracy: 0.7895 Precision: 0.7207 Validation Recall: 0.7823 F1 Score: 0.7477\n",
      "Epoch [35/100], Loss: 1.6315\n",
      "Validation Accuracy: 0.7902 Precision: 0.7208 Validation Recall: 0.7830 F1 Score: 0.7482\n",
      "Epoch [36/100], Loss: 1.7101\n",
      "Validation Accuracy: 0.7895 Precision: 0.7221 Validation Recall: 0.7827 F1 Score: 0.7480\n",
      "Epoch [37/100], Loss: 1.6463\n",
      "Validation Accuracy: 0.7900 Precision: 0.7197 Validation Recall: 0.7824 F1 Score: 0.7476\n",
      "Epoch [38/100], Loss: 1.6200\n",
      "Validation Accuracy: 0.7903 Precision: 0.7221 Validation Recall: 0.7832 F1 Score: 0.7486\n",
      "Epoch [39/100], Loss: 1.7181\n",
      "Validation Accuracy: 0.7892 Precision: 0.7211 Validation Recall: 0.7819 F1 Score: 0.7477\n",
      "Epoch [40/100], Loss: 1.6349\n",
      "Validation Accuracy: 0.7898 Precision: 0.7214 Validation Recall: 0.7828 F1 Score: 0.7482\n",
      "Epoch [41/100], Loss: 1.7483\n",
      "Validation Accuracy: 0.7920 Precision: 0.7231 Validation Recall: 0.7850 F1 Score: 0.7502\n",
      "Epoch [42/100], Loss: 1.6657\n",
      "Validation Accuracy: 0.7923 Precision: 0.7218 Validation Recall: 0.7850 F1 Score: 0.7499\n",
      "Epoch [43/100], Loss: 1.7683\n",
      "Validation Accuracy: 0.7910 Precision: 0.7233 Validation Recall: 0.7836 F1 Score: 0.7494\n",
      "Epoch [44/100], Loss: 1.5636\n",
      "Validation Accuracy: 0.7908 Precision: 0.7215 Validation Recall: 0.7836 F1 Score: 0.7488\n",
      "Epoch [45/100], Loss: 1.6281\n",
      "Validation Accuracy: 0.7898 Precision: 0.7221 Validation Recall: 0.7823 F1 Score: 0.7482\n",
      "Epoch [46/100], Loss: 1.7728\n",
      "Validation Accuracy: 0.7895 Precision: 0.7184 Validation Recall: 0.7820 F1 Score: 0.7469\n",
      "Epoch [47/100], Loss: 1.6107\n",
      "Validation Accuracy: 0.7908 Precision: 0.7210 Validation Recall: 0.7838 F1 Score: 0.7487\n",
      "Epoch [48/100], Loss: 1.6703\n",
      "Validation Accuracy: 0.7922 Precision: 0.7207 Validation Recall: 0.7849 F1 Score: 0.7495\n",
      "Epoch [49/100], Loss: 1.7751\n",
      "Validation Accuracy: 0.7912 Precision: 0.7218 Validation Recall: 0.7839 F1 Score: 0.7491\n",
      "Epoch [50/100], Loss: 1.7398\n",
      "Validation Accuracy: 0.7897 Precision: 0.7206 Validation Recall: 0.7825 F1 Score: 0.7479\n",
      "Epoch [51/100], Loss: 1.7409\n",
      "Validation Accuracy: 0.7902 Precision: 0.7198 Validation Recall: 0.7828 F1 Score: 0.7478\n",
      "Epoch [52/100], Loss: 1.5570\n",
      "Validation Accuracy: 0.7918 Precision: 0.7241 Validation Recall: 0.7847 F1 Score: 0.7502\n",
      "Epoch [53/100], Loss: 1.7354\n",
      "Validation Accuracy: 0.7915 Precision: 0.7214 Validation Recall: 0.7841 F1 Score: 0.7492\n",
      "Epoch [54/100], Loss: 1.6563\n",
      "Validation Accuracy: 0.7923 Precision: 0.7233 Validation Recall: 0.7854 F1 Score: 0.7505\n",
      "Epoch [55/100], Loss: 1.5826\n",
      "Validation Accuracy: 0.7902 Precision: 0.7203 Validation Recall: 0.7828 F1 Score: 0.7481\n",
      "Epoch [56/100], Loss: 1.7215\n",
      "Validation Accuracy: 0.7912 Precision: 0.7205 Validation Recall: 0.7839 F1 Score: 0.7488\n",
      "Epoch [57/100], Loss: 1.6160\n",
      "Validation Accuracy: 0.7897 Precision: 0.7203 Validation Recall: 0.7825 F1 Score: 0.7477\n",
      "Epoch [58/100], Loss: 1.6319\n",
      "Validation Accuracy: 0.7920 Precision: 0.7226 Validation Recall: 0.7849 F1 Score: 0.7499\n",
      "Epoch [59/100], Loss: 1.6433\n",
      "Validation Accuracy: 0.7925 Precision: 0.7227 Validation Recall: 0.7855 F1 Score: 0.7504\n",
      "Epoch [60/100], Loss: 1.6047\n",
      "Validation Accuracy: 0.7900 Precision: 0.7208 Validation Recall: 0.7827 F1 Score: 0.7481\n",
      "Epoch [61/100], Loss: 1.6192\n",
      "Validation Accuracy: 0.7927 Precision: 0.7219 Validation Recall: 0.7856 F1 Score: 0.7502\n",
      "Epoch [62/100], Loss: 1.7014\n",
      "Validation Accuracy: 0.7915 Precision: 0.7223 Validation Recall: 0.7843 F1 Score: 0.7496\n",
      "Epoch [63/100], Loss: 1.5777\n",
      "Validation Accuracy: 0.7900 Precision: 0.7209 Validation Recall: 0.7826 F1 Score: 0.7480\n",
      "Epoch [64/100], Loss: 1.6388\n",
      "Validation Accuracy: 0.7923 Precision: 0.7234 Validation Recall: 0.7854 F1 Score: 0.7504\n",
      "Epoch [65/100], Loss: 1.6570\n",
      "Validation Accuracy: 0.7910 Precision: 0.7229 Validation Recall: 0.7838 F1 Score: 0.7494\n",
      "Epoch [66/100], Loss: 1.7303\n",
      "Validation Accuracy: 0.7917 Precision: 0.7212 Validation Recall: 0.7846 F1 Score: 0.7494\n",
      "Epoch [67/100], Loss: 1.5946\n",
      "Validation Accuracy: 0.7922 Precision: 0.7229 Validation Recall: 0.7852 F1 Score: 0.7502\n",
      "Epoch [68/100], Loss: 1.6557\n",
      "Validation Accuracy: 0.7918 Precision: 0.7210 Validation Recall: 0.7847 F1 Score: 0.7494\n",
      "Epoch [69/100], Loss: 1.7625\n",
      "Validation Accuracy: 0.7917 Precision: 0.7227 Validation Recall: 0.7843 F1 Score: 0.7497\n",
      "Epoch [70/100], Loss: 1.6351\n",
      "Validation Accuracy: 0.7917 Precision: 0.7233 Validation Recall: 0.7846 F1 Score: 0.7500\n",
      "Epoch [71/100], Loss: 1.6256\n",
      "Validation Accuracy: 0.8378 Precision: 0.8429 Validation Recall: 0.8337 F1 Score: 0.8313\n",
      "Epoch [72/100], Loss: 1.6684\n",
      "Validation Accuracy: 0.8437 Precision: 0.8417 Validation Recall: 0.8406 F1 Score: 0.8405\n",
      "Epoch [73/100], Loss: 1.7258\n",
      "Validation Accuracy: 0.8445 Precision: 0.8424 Validation Recall: 0.8414 F1 Score: 0.8409\n",
      "Epoch [74/100], Loss: 1.5159\n",
      "Validation Accuracy: 0.8432 Precision: 0.8415 Validation Recall: 0.8402 F1 Score: 0.8400\n",
      "Epoch [75/100], Loss: 1.5822\n",
      "Validation Accuracy: 0.8440 Precision: 0.8416 Validation Recall: 0.8406 F1 Score: 0.8404\n",
      "Epoch [76/100], Loss: 1.6281\n",
      "Validation Accuracy: 0.8440 Precision: 0.8425 Validation Recall: 0.8411 F1 Score: 0.8408\n",
      "Epoch [77/100], Loss: 1.5315\n",
      "Validation Accuracy: 0.8465 Precision: 0.8439 Validation Recall: 0.8433 F1 Score: 0.8430\n",
      "Epoch [78/100], Loss: 1.5728\n",
      "Validation Accuracy: 0.8472 Precision: 0.8447 Validation Recall: 0.8441 F1 Score: 0.8438\n",
      "Epoch [79/100], Loss: 1.6363\n",
      "Validation Accuracy: 0.8455 Precision: 0.8432 Validation Recall: 0.8422 F1 Score: 0.8420\n",
      "Epoch [80/100], Loss: 1.6329\n",
      "Validation Accuracy: 0.8470 Precision: 0.8449 Validation Recall: 0.8440 F1 Score: 0.8438\n",
      "Epoch [81/100], Loss: 1.6262\n",
      "Validation Accuracy: 0.8462 Precision: 0.8444 Validation Recall: 0.8431 F1 Score: 0.8431\n",
      "Epoch [82/100], Loss: 1.5442\n",
      "Validation Accuracy: 0.8475 Precision: 0.8451 Validation Recall: 0.8444 F1 Score: 0.8442\n",
      "Epoch [83/100], Loss: 1.5605\n",
      "Validation Accuracy: 0.8472 Precision: 0.8452 Validation Recall: 0.8441 F1 Score: 0.8441\n",
      "Epoch [84/100], Loss: 1.6967\n",
      "Validation Accuracy: 0.8465 Precision: 0.8441 Validation Recall: 0.8433 F1 Score: 0.8432\n",
      "Epoch [85/100], Loss: 1.6477\n",
      "Validation Accuracy: 0.8477 Precision: 0.8449 Validation Recall: 0.8447 F1 Score: 0.8444\n",
      "Epoch [86/100], Loss: 1.6152\n",
      "Validation Accuracy: 0.8487 Precision: 0.8458 Validation Recall: 0.8454 F1 Score: 0.8452\n",
      "Epoch [87/100], Loss: 1.5809\n",
      "Validation Accuracy: 0.8470 Precision: 0.8440 Validation Recall: 0.8438 F1 Score: 0.8436\n",
      "Epoch [88/100], Loss: 1.6304\n",
      "Validation Accuracy: 0.8495 Precision: 0.8475 Validation Recall: 0.8465 F1 Score: 0.8464\n",
      "Epoch [89/100], Loss: 1.6783\n",
      "Validation Accuracy: 0.8480 Precision: 0.8456 Validation Recall: 0.8450 F1 Score: 0.8448\n",
      "Epoch [90/100], Loss: 1.6188\n",
      "Validation Accuracy: 0.8495 Precision: 0.8477 Validation Recall: 0.8468 F1 Score: 0.8467\n",
      "Epoch [91/100], Loss: 1.6248\n",
      "Validation Accuracy: 0.8497 Precision: 0.8478 Validation Recall: 0.8466 F1 Score: 0.8466\n",
      "Epoch [92/100], Loss: 1.6756\n",
      "Validation Accuracy: 0.8490 Precision: 0.8465 Validation Recall: 0.8458 F1 Score: 0.8458\n",
      "Epoch [93/100], Loss: 1.7076\n",
      "Validation Accuracy: 0.8515 Precision: 0.8495 Validation Recall: 0.8489 F1 Score: 0.8486\n",
      "Epoch [94/100], Loss: 1.6132\n",
      "Validation Accuracy: 0.8508 Precision: 0.8499 Validation Recall: 0.8482 F1 Score: 0.8482\n",
      "Epoch [95/100], Loss: 1.5997\n",
      "Validation Accuracy: 0.8510 Precision: 0.8492 Validation Recall: 0.8483 F1 Score: 0.8481\n",
      "Epoch [96/100], Loss: 1.5945\n",
      "Validation Accuracy: 0.8515 Precision: 0.8493 Validation Recall: 0.8485 F1 Score: 0.8484\n",
      "Epoch [97/100], Loss: 1.6063\n",
      "Validation Accuracy: 0.8503 Precision: 0.8480 Validation Recall: 0.8474 F1 Score: 0.8473\n",
      "Epoch [98/100], Loss: 1.6332\n",
      "Validation Accuracy: 0.8520 Precision: 0.8504 Validation Recall: 0.8492 F1 Score: 0.8492\n",
      "Epoch [99/100], Loss: 1.6218\n",
      "Validation Accuracy: 0.8507 Precision: 0.8484 Validation Recall: 0.8477 F1 Score: 0.8476\n",
      "Epoch [100/100], Loss: 1.5683\n",
      "Validation Accuracy: 0.8517 Precision: 0.8498 Validation Recall: 0.8487 F1 Score: 0.8487\n",
      "Test Accuracy: 86.37%\n",
      "Test Precision: 86.1921%\n",
      "Test Recall: 86.1740%\n",
      "Test F1 Score: 0.8613\n",
      "Confusion Matrix:\n",
      "tensor([[ 932,    0,    4,    3,    3,    8,   14,    2,   14,    0],\n",
      "        [   0, 1092,    6,    3,    0,    4,    7,    2,   21,    0],\n",
      "        [  17,    7,  854,   27,   18,    5,   23,   19,   55,    7],\n",
      "        [  10,    3,   43,  794,    3,   73,    7,   18,   49,   10],\n",
      "        [   4,    2,    6,    0,  865,    8,   20,    7,   16,   54],\n",
      "        [  16,    6,    9,   68,   23,  691,   17,    3,   48,   11],\n",
      "        [  31,    4,   21,    0,   16,   17,  851,    1,   16,    1],\n",
      "        [   1,   13,   22,    3,   13,    4,    1,  932,   10,   29],\n",
      "        [  14,    6,   13,   28,    8,   62,   16,   13,  805,    9],\n",
      "        [  11,    7,    7,    7,   61,   16,    3,   46,   30,  821]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_27520\\3621217840.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "metrics_json = {\n",
    "    \"White\":{},\n",
    "    \"365nm\":{},\n",
    "    \"455nm\":{}\n",
    "}\n",
    "mask_sets = [0]\n",
    "combinations = get_all_combinations(mask_sets)\n",
    "for filename in [\"White\", \"455nm\"]:\n",
    "    for ms in combinations:\n",
    "\n",
    "        dev_ind = torch.randint(0, 5, (len(ms), 196))\n",
    "\n",
    "        accuracy, precision, recall, fscore = get_metrics(filename=filename, mask_sets=ms, device_indices=dev_ind)\n",
    "        metrics_json[filename][''.join(map(str, ms)) ] = {\n",
    "            \"Accuracy\":accuracy.item(),\n",
    "            \"Precision\":precision.item(),\n",
    "            \"Recall\":recall.item(),\n",
    "            \"F-score\":fscore.item()\n",
    "            \n",
    "        }\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data/metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name\n",
    "filename = 'data/metrics.xlsx'\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine\n",
    "with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:\n",
    "    for wavelength, results in metrics_json.items():\n",
    "        # Flatten the data for each wavelength\n",
    "        flattened_data = []\n",
    "        for index, metrics in results.items():\n",
    "            if metrics:  # Check if the metrics are not empty\n",
    "                flattened_data.append({\n",
    "                    'Index': index,\n",
    "                    'Accuracy': metrics['Accuracy'],  # Convert tensor to float\n",
    "                    'Precision': metrics['Precision'],\n",
    "                    'Recall': metrics['Recall'],\n",
    "                    'F-score': metrics['F-score']\n",
    "                })\n",
    "        \n",
    "        # Create a DataFrame for the current wavelength\n",
    "        if flattened_data:  # Check if there's data to save\n",
    "            df = pd.DataFrame(flattened_data)\n",
    "            # Write the DataFrame to a specific sheet named after the wavelength\n",
    "            df.to_excel(writer, sheet_name=wavelength, index=False)\n",
    "\n",
    "print(\"Data saved to\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7956\n",
      "Validation Accuracy: 0.7177 Precision: 0.5817 Validation Recall: 0.7140 F1 Score: 0.6382\n",
      "Epoch [2/100], Loss: 1.7219\n",
      "Validation Accuracy: 0.7248 Precision: 0.5893 Validation Recall: 0.7213 F1 Score: 0.6454\n",
      "Epoch [3/100], Loss: 1.6405\n",
      "Validation Accuracy: 0.8622 Precision: 0.8630 Validation Recall: 0.8614 F1 Score: 0.8613\n",
      "Epoch [4/100], Loss: 1.6338\n",
      "Validation Accuracy: 0.8715 Precision: 0.8713 Validation Recall: 0.8708 F1 Score: 0.8704\n",
      "Epoch [5/100], Loss: 1.5685\n",
      "Validation Accuracy: 0.8763 Precision: 0.8761 Validation Recall: 0.8752 F1 Score: 0.8756\n",
      "Epoch [6/100], Loss: 1.5794\n",
      "Validation Accuracy: 0.8778 Precision: 0.8777 Validation Recall: 0.8768 F1 Score: 0.8770\n",
      "Epoch [7/100], Loss: 1.5311\n",
      "Validation Accuracy: 0.8733 Precision: 0.8728 Validation Recall: 0.8724 F1 Score: 0.8724\n",
      "Epoch [8/100], Loss: 1.6506\n",
      "Validation Accuracy: 0.8775 Precision: 0.8770 Validation Recall: 0.8766 F1 Score: 0.8766\n",
      "Epoch [9/100], Loss: 1.5100\n",
      "Validation Accuracy: 0.8765 Precision: 0.8759 Validation Recall: 0.8758 F1 Score: 0.8753\n",
      "Epoch [10/100], Loss: 1.5781\n",
      "Validation Accuracy: 0.8760 Precision: 0.8757 Validation Recall: 0.8753 F1 Score: 0.8751\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Move to device\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:211\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "model = ReadoutLayer(len(mask_sets)*196)\n",
    "# Loss function, Categorical crossentropy loss for multi-class classification problem\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer to update the gradients.\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "val_accuracy, val_precision, val_recall, val_fscore = [], [], [], []\n",
    "# Evaluation metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "\n",
    "# Class-wise Confusion matrix\n",
    "confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to device\n",
    "        outputs = model(images.float())  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Loss calculation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images.float())\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            accuracy.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            f1_score.update(preds, labels)\n",
    "\n",
    "        # Print validation metrics\n",
    "        print(f'Validation Accuracy: {accuracy.compute().item():.4f} Precision: {precision.compute().item():.4f} ', end=\"\")\n",
    "        print(f'Validation Recall: {recall.compute().item():.4f} F1 Score: {f1_score.compute().item():.4f}')\n",
    "\n",
    "        # Updating the list to save current metrics\n",
    "        val_accuracy.append(accuracy.compute().item())\n",
    "        val_precision.append(precision.compute().item())\n",
    "        val_recall.append(recall.compute().item())\n",
    "        val_fscore.append(f1_score.compute().item())\n",
    "\n",
    "        # Reset metrics for the next epoch\n",
    "        accuracy.reset()\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        f1_score.reset()\n",
    "        confusion_matrix.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_29648\\247194469.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.93%\n",
      "Test Precision: 86.6844%\n",
      "Test Recall: 86.7090%\n",
      "Test F1 Score: 0.8669\n",
      "Confusion Matrix:\n",
      "tensor([[ 938,    1,    4,    4,    1,   13,   14,    2,    3,    0],\n",
      "        [   0, 1099,    8,    3,    1,    4,    7,    3,   10,    0],\n",
      "        [  13,    3,  884,   30,   14,   15,   18,   16,   37,    2],\n",
      "        [   4,    6,   43,  837,    2,   48,    7,   16,   40,    7],\n",
      "        [   5,    2,   13,    0,  828,    8,   11,    8,    8,   99],\n",
      "        [  10,    3,   17,   61,   20,  693,   25,   12,   35,   16],\n",
      "        [  15,    3,   14,    1,   13,   21,  876,    7,    7,    1],\n",
      "        [   4,    8,   22,    6,   13,    3,    3,  924,    7,   38],\n",
      "        [   6,   17,   16,   50,   13,   62,    7,   19,  765,   19],\n",
      "        [   7,    5,    1,    8,   54,   16,    1,   44,   24,  849]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(torch.tensor(images, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and labels for metric calculations\n",
    "        all_preds.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "all_preds = torch.cat(all_preds).to(device)\n",
    "all_labels = torch.cat(all_labels).to(device)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy(all_preds, all_labels)\n",
    "test_precision = precision(all_preds, all_labels)\n",
    "test_recall = recall(all_preds, all_labels)\n",
    "test_f1 = f1_score(all_preds, all_labels)\n",
    "test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_confusion_matrix)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/mnist_results/\" + filename + '_' + ''.join(map(str, mask_sets)) + '.npz'\n",
    "np.savez(save_path,\n",
    "         predictions = all_preds,\n",
    "         labels = all_labels,\n",
    "         validation_accuracy = val_accuracy,\n",
    "         validation_precision = val_precision,\n",
    "         validation_recall = val_recall,\n",
    "         validation_fscore = val_fscore\n",
    "         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# # Hyperparameters\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "# epochs = 5\n",
    "\n",
    "# # MNIST dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# train_dataset = datasets.MNIST(root='./data/MNIST', train=True, transform=transform, download=False)\n",
    "# test_dataset = datasets.MNIST(root='./data/MNIST', train=False, transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Define the single-layer MLP model\n",
    "# class SingleLayerMLP(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SingleLayerMLP, self).__init__()\n",
    "#         self.fc = nn.Linear(784, 10)  # Input layer (784) to output layer (10 classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 28*28)  # Flatten the input\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# # Initialize model, loss function, and optimizer\n",
    "# model = SingleLayerMLP()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Initialize metrics\n",
    "# accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "# precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "# recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "# f1_score = F1Score(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "# confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     for images, labels in train_loader:\n",
    "#         # Move images and labels to GPU\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         # Move images and labels to GPU\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#         # Append predictions and labels for metric calculations\n",
    "#         all_preds.append(predicted)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "# # Concatenate all predictions and labels\n",
    "# all_preds = torch.cat(all_preds)\n",
    "# all_labels = torch.cat(all_labels)\n",
    "\n",
    "# # Calculate metrics\n",
    "# test_accuracy = accuracy(all_preds, all_labels)\n",
    "# test_precision = precision(all_preds, all_labels)\n",
    "# test_recall = recall(all_preds, all_labels)\n",
    "# test_f1 = f1_score(all_preds, all_labels)\n",
    "# test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "# print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "# print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "# print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "# print(f'Test F1 Score: {test_f1:.4f}')\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
