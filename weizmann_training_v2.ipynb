{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data\\weizmann_dataset\\classification_masks.mat\"\n",
    "data = loadmat(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_trailing_digits(s:str):\n",
    "    if s in [\"wave1\" or \"wave\" or \"wave2\"]:\n",
    "        return s\n",
    "    while s and s[-1].isdigit():\n",
    "        s = s[:-1]\n",
    "    return s\n",
    "\n",
    "labels = [name.split('_')[-1] for name, _ in data['aligned_masks'].dtype.descr]\n",
    "labels = [remove_trailing_digits(s) for s in labels]\n",
    "\n",
    "class_names = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [data['aligned_masks'][0][0][idx] for idx in range(93)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, class_labels = [], []\n",
    "\n",
    "for idx, video in enumerate(train_data):\n",
    "    video_frames = np.array([cv2.resize(frame, (30, 70)) for frame in video])\n",
    "\n",
    "    # Parameters\n",
    "    group_size = 4\n",
    "    stride = 3\n",
    "\n",
    "    # Calculate the number of groups\n",
    "    num_groups = (video_frames.shape[0] - 1) // stride + 1\n",
    "\n",
    "    # Initialize an array to store the groups\n",
    "    groups = np.empty((num_groups, group_size, 70, 30), dtype=video_frames.dtype)\n",
    "\n",
    "    # Create the groups with the specified stride\n",
    "    for i in range(num_groups):\n",
    "        start_index = i * stride\n",
    "        end_index = start_index + group_size\n",
    "\n",
    "        if end_index <= video_frames.shape[0]:\n",
    "            # If enough frames are available, take the group directly\n",
    "            groups[i] = video_frames[start_index:end_index]\n",
    "        else:\n",
    "            # If not enough frames are left, pad with zeros\n",
    "            frames_left = video_frames[start_index:]\n",
    "            padding = np.zeros((group_size - frames_left.shape[0], 70, 30), dtype=video_frames.dtype)\n",
    "            groups[i] = np.vstack((frames_left, padding))\n",
    "\n",
    "    dataset.append(groups)\n",
    "    class_labels.extend([np.where(class_names == labels[idx])[0][0]]*num_groups)\n",
    "\n",
    "dataset = np.concatenate(dataset, axis=0)\n",
    "class_labels = np.array(class_labels)\n",
    "\n",
    "mask = np.mean(dataset, axis=(1, 2, 3)) > 0.12\n",
    "dataset = dataset[mask]\n",
    "class_labels = class_labels[mask]\n",
    "\n",
    "dataset = (\n",
    "    dataset[:, 3, :, :]*1000+\n",
    "    dataset[:, 2, :, :]*100+\n",
    "    dataset[:, 1, :, :]*10+\n",
    "    dataset[:, 0, :, :]\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1100, 70, 30)\n",
      "Validation data shape: (440, 70, 30)\n",
      "Test data shape: (661, 70, 30)\n",
      "Train labels shape: (1100,)\n",
      "Validation labels shape: (440,)\n",
      "Test labels shape: (661,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the split ratios\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.3\n",
    "\n",
    "# Ensure the split ratios add up to 1\n",
    "assert train_ratio + val_ratio + test_ratio == 1\n",
    "\n",
    "# Shuffle the dataset and labels with the same permutation\n",
    "num_samples = dataset.shape[0]\n",
    "indices = np.random.permutation(num_samples)\n",
    "shuffled_dataset = dataset[indices]\n",
    "shuffled_labels = class_labels[indices]\n",
    "\n",
    "# Calculate split indices\n",
    "train_end = int(train_ratio * num_samples)\n",
    "val_end = train_end + int(val_ratio * num_samples)\n",
    "\n",
    "# Split the data and labels\n",
    "train_data, val_data, test_data = (\n",
    "    shuffled_dataset[:train_end],\n",
    "    shuffled_dataset[train_end:val_end],\n",
    "    shuffled_dataset[val_end:],\n",
    ")\n",
    "train_labels, val_labels, test_labels = (\n",
    "    shuffled_labels[:train_end],\n",
    "    shuffled_labels[train_end:val_end],\n",
    "    shuffled_labels[val_end:],\n",
    ")\n",
    "\n",
    "# Print the shapes of the splits\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all the rows of each mask-set in every file \n",
    "json_data = {\n",
    "    \"365nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(10, 15),\n",
    "        \"I3\":range(18, 23),\n",
    "        \"I4\":range(25, 30)\n",
    "    },\n",
    "    \"455nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(7, 12),\n",
    "        \"I3\":range(14, 19),\n",
    "        \"I4\":range(21, 26)\n",
    "    },\n",
    "    \"White\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(9, 14),\n",
    "        \"I3\":range(16, 21),\n",
    "        \"I4\":range(24, 29)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tables = []\n",
    "for filename in [\"White\", \"365nm\", \"455nm\"]:\n",
    "    path = \"data/\"+filename+\".xlsx\" \n",
    "    df = pd.read_excel(path, usecols='B:Q') # Read the excel sheet\n",
    "    tables = [df.iloc[json_data[filename][key]].copy().reset_index(drop=True) for key in list(json_data[filename].keys())]\n",
    "    combined_table = pd.concat(tables, axis=0)\n",
    "    combined_tables.append(combined_table)\n",
    "    del(df, tables, combined_table)\n",
    "\n",
    "combined_tables[1] = combined_tables[1].reindex(columns=combined_tables[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MASKS = 8\n",
    "optical_range = np.array([0, 1, 2])  # Optical masks: 0, 1, 2\n",
    "electrical_range = np.array([0, 1, 2, 3])  # Electrical masks: 0, 1, 2, 3\n",
    "\n",
    "# Generate a meshgrid of all combinations, so that we don't sample same pair twice\n",
    "optical_masks, electrical_masks = np.meshgrid(optical_range, electrical_range, indexing='ij')\n",
    "all_pairs = np.column_stack((optical_masks.ravel(), electrical_masks.ravel()))\n",
    "\n",
    "unique_indices = np.random.choice(all_pairs.shape[0], size=NUMBER_OF_MASKS, replace=False)\n",
    "\n",
    "selected_pairs = all_pairs[unique_indices]\n",
    "optical_masks = selected_pairs[:, 0]\n",
    "electrical_masks = selected_pairs[:, 1]\n",
    "\n",
    "\n",
    "# Use this to override previous values,  if you want a specific set of masks\n",
    "# optical_masks = np.array([0, 1, 2])\n",
    "# electrical_masks = np.array([0, 1, 2])\n",
    "\n",
    "# Device masks\n",
    "\n",
    "number_of_devices = np.multiply(*dataset.shape[-2:])\n",
    "\n",
    "# device_mask = np.random.randint(0, 5, (NUMBER_OF_MASKS, number_of_devices))\n",
    "\n",
    "device_mask = np.ones((NUMBER_OF_MASKS, number_of_devices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 1 0] [2 0 2 1 2 3 0 1] (8, 2100)\n"
     ]
    }
   ],
   "source": [
    "print(optical_masks, electrical_masks, device_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset:np.array, \n",
    "                 labels:np.array, \n",
    "                 combined_tables:np.array, \n",
    "                 optical_masks:np.array, \n",
    "                 electrical_masks:np.array, \n",
    "                 device_mask:np.array):\n",
    "        self.processed_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx in tqdm(range(len(dataset))):\n",
    "            image, label = dataset[idx], labels[idx]\n",
    "            # image = (\n",
    "            #     images[0]*1000+\n",
    "            #     images[1]*100+\n",
    "            #     images[2]*10+\n",
    "            #     images[3]\n",
    "            # )\n",
    "            image = image.flatten()\n",
    "            \n",
    "            column_indices = combined_tables[0].columns.get_indexer(image.tolist())\n",
    "            x = []\n",
    "            for j, (optical_mask, electrical_mask) in enumerate(zip(optical_masks, electrical_masks)):\n",
    "                required_table = combined_tables[optical_mask].iloc[electrical_mask*5:(electrical_mask+1)*5].iloc[device_mask[j]]\n",
    "                \n",
    "                x.append(required_table.values[np.arange(device_mask.shape[-1]), column_indices]*1e9)\n",
    "            \n",
    "            x = np.concatenate(x, axis=0)\n",
    "\n",
    "            # print(y)\n",
    "            \n",
    "            self.processed_data.append(x)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.processed_data = torch.tensor(self.processed_data).to(device=device)\n",
    "        self.labels = torch.tensor(self.labels).to(device=device)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.processed_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx], self.labels[idx]\n",
    "    \n",
    "# train_dataset = CustomDataset(dataset, class_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 256\n",
    "class ReadoutLayer(nn.Module):\n",
    "    def __init__(self, input_size:int):\n",
    "        super(ReadoutLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 10)\n",
    "        # self.fc2 = nn.Linear(50, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.activation = nn.functional.leaky_relu\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.activation(self.fc(x))\n",
    "        # x = self.softmax(x)\n",
    "        # x = x.reshape(BATCH_SIZE, 1, NUMBER_OF_MASKS*144, 180)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [00:02<00:00, 482.12it/s]\n",
      "100%|██████████| 440/440 [00:00<00:00, 471.67it/s]\n",
      "100%|██████████| 661/661 [00:01<00:00, 513.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_data, train_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "validation_dataset = CustomDataset(val_data, val_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "test_dataset = CustomDataset(test_data, test_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ReadoutLayer(number_of_devices*NUMBER_OF_MASKS).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "val_accuracy, val_precision, val_recall, val_fscore = [], [], [], []\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 1.1524 Validation - Accuracy: 0.4705 Precision: 0.5282  Recall: 0.4804 F1 Score: 0.4766\n",
      "Epoch [20/1000], Loss: 0.5827 Validation - Accuracy: 0.5364 Precision: 0.5859  Recall: 0.5528 F1 Score: 0.5410\n",
      "Epoch [30/1000], Loss: 0.6317 Validation - Accuracy: 0.5591 Precision: 0.6097  Recall: 0.5757 F1 Score: 0.5607\n",
      "Epoch [40/1000], Loss: 0.4200 Validation - Accuracy: 0.5636 Precision: 0.5805  Recall: 0.5698 F1 Score: 0.5670\n",
      "Epoch [50/1000], Loss: 0.2605 Validation - Accuracy: 0.5591 Precision: 0.5855  Recall: 0.5679 F1 Score: 0.5597\n",
      "Epoch [60/1000], Loss: 0.2697 Validation - Accuracy: 0.5591 Precision: 0.5901  Recall: 0.5591 F1 Score: 0.5635\n",
      "Epoch [70/1000], Loss: 0.4258 Validation - Accuracy: 0.5545 Precision: 0.5874  Recall: 0.5575 F1 Score: 0.5529\n",
      "Epoch [80/1000], Loss: 0.3173 Validation - Accuracy: 0.5432 Precision: 0.5744  Recall: 0.5500 F1 Score: 0.5447\n",
      "Epoch [90/1000], Loss: 0.2897 Validation - Accuracy: 0.5523 Precision: 0.5923  Recall: 0.5677 F1 Score: 0.5586\n",
      "Epoch [100/1000], Loss: 0.1048 Validation - Accuracy: 0.5591 Precision: 0.5771  Recall: 0.5653 F1 Score: 0.5630\n",
      "Epoch [110/1000], Loss: 0.2884 Validation - Accuracy: 0.5614 Precision: 0.5956  Recall: 0.5773 F1 Score: 0.5634\n",
      "Epoch [120/1000], Loss: 0.2254 Validation - Accuracy: 0.5614 Precision: 0.5785  Recall: 0.5621 F1 Score: 0.5627\n",
      "Epoch [130/1000], Loss: 0.0810 Validation - Accuracy: 0.5614 Precision: 0.5707  Recall: 0.5613 F1 Score: 0.5623\n",
      "Epoch [140/1000], Loss: 0.1058 Validation - Accuracy: 0.5682 Precision: 0.5785  Recall: 0.5700 F1 Score: 0.5700\n",
      "Epoch [150/1000], Loss: 0.0521 Validation - Accuracy: 0.5477 Precision: 0.5833  Recall: 0.5547 F1 Score: 0.5532\n",
      "Epoch [160/1000], Loss: 0.2482 Validation - Accuracy: 0.5455 Precision: 0.5735  Recall: 0.5544 F1 Score: 0.5514\n",
      "Epoch [170/1000], Loss: 0.1146 Validation - Accuracy: 0.5545 Precision: 0.5759  Recall: 0.5553 F1 Score: 0.5566\n",
      "Epoch [180/1000], Loss: 0.0550 Validation - Accuracy: 0.5523 Precision: 0.5713  Recall: 0.5501 F1 Score: 0.5521\n",
      "Epoch [190/1000], Loss: 0.0923 Validation - Accuracy: 0.5409 Precision: 0.5668  Recall: 0.5543 F1 Score: 0.5469\n",
      "Epoch [200/1000], Loss: 0.0940 Validation - Accuracy: 0.5455 Precision: 0.5626  Recall: 0.5372 F1 Score: 0.5410\n",
      "Epoch [210/1000], Loss: 0.0375 Validation - Accuracy: 0.5523 Precision: 0.5711  Recall: 0.5486 F1 Score: 0.5508\n",
      "Epoch [220/1000], Loss: 0.0550 Validation - Accuracy: 0.5455 Precision: 0.5816  Recall: 0.5585 F1 Score: 0.5527\n",
      "Epoch [230/1000], Loss: 0.1402 Validation - Accuracy: 0.5455 Precision: 0.5751  Recall: 0.5343 F1 Score: 0.5409\n",
      "Epoch [240/1000], Loss: 0.0799 Validation - Accuracy: 0.5455 Precision: 0.5668  Recall: 0.5516 F1 Score: 0.5489\n",
      "Epoch [250/1000], Loss: 0.0607 Validation - Accuracy: 0.5432 Precision: 0.5643  Recall: 0.5498 F1 Score: 0.5477\n",
      "Epoch [260/1000], Loss: 0.0543 Validation - Accuracy: 0.5523 Precision: 0.5814  Recall: 0.5583 F1 Score: 0.5565\n",
      "Epoch [270/1000], Loss: 0.0908 Validation - Accuracy: 0.5523 Precision: 0.5764  Recall: 0.5614 F1 Score: 0.5562\n",
      "Epoch [280/1000], Loss: 0.1092 Validation - Accuracy: 0.5500 Precision: 0.5660  Recall: 0.5529 F1 Score: 0.5518\n",
      "Epoch [290/1000], Loss: 0.0642 Validation - Accuracy: 0.5477 Precision: 0.5663  Recall: 0.5407 F1 Score: 0.5442\n",
      "Epoch [300/1000], Loss: 0.0536 Validation - Accuracy: 0.5409 Precision: 0.5668  Recall: 0.5234 F1 Score: 0.5233\n",
      "Epoch [310/1000], Loss: 0.0739 Validation - Accuracy: 0.5409 Precision: 0.5789  Recall: 0.5410 F1 Score: 0.5436\n",
      "Epoch [320/1000], Loss: 0.0558 Validation - Accuracy: 0.5523 Precision: 0.5973  Recall: 0.5683 F1 Score: 0.5562\n",
      "Epoch [330/1000], Loss: 0.1214 Validation - Accuracy: 0.5523 Precision: 0.5802  Recall: 0.5573 F1 Score: 0.5562\n",
      "Epoch [340/1000], Loss: 0.0569 Validation - Accuracy: 0.5500 Precision: 0.5715  Recall: 0.5534 F1 Score: 0.5532\n",
      "Epoch [350/1000], Loss: 0.0570 Validation - Accuracy: 0.5545 Precision: 0.5754  Recall: 0.5621 F1 Score: 0.5573\n",
      "Epoch [360/1000], Loss: 0.0471 Validation - Accuracy: 0.5432 Precision: 0.5699  Recall: 0.5553 F1 Score: 0.5488\n",
      "Epoch [370/1000], Loss: 0.1447 Validation - Accuracy: 0.5386 Precision: 0.5733  Recall: 0.5514 F1 Score: 0.5452\n",
      "Epoch [380/1000], Loss: 0.0913 Validation - Accuracy: 0.5455 Precision: 0.5597  Recall: 0.5466 F1 Score: 0.5474\n",
      "Epoch [390/1000], Loss: 0.0776 Validation - Accuracy: 0.5386 Precision: 0.5827  Recall: 0.5559 F1 Score: 0.5443\n",
      "Epoch [400/1000], Loss: 0.0089 Validation - Accuracy: 0.5386 Precision: 0.5700  Recall: 0.5499 F1 Score: 0.5435\n",
      "Epoch [410/1000], Loss: 0.0193 Validation - Accuracy: 0.5455 Precision: 0.5733  Recall: 0.5528 F1 Score: 0.5497\n",
      "Epoch [420/1000], Loss: 0.0688 Validation - Accuracy: 0.5341 Precision: 0.5777  Recall: 0.5485 F1 Score: 0.5414\n",
      "Epoch [430/1000], Loss: 0.0332 Validation - Accuracy: 0.5523 Precision: 0.5839  Recall: 0.5638 F1 Score: 0.5569\n",
      "Epoch [440/1000], Loss: 0.0688 Validation - Accuracy: 0.5318 Precision: 0.5603  Recall: 0.5448 F1 Score: 0.5375\n",
      "Epoch [450/1000], Loss: 0.0559 Validation - Accuracy: 0.5455 Precision: 0.5730  Recall: 0.5478 F1 Score: 0.5478\n",
      "Epoch [460/1000], Loss: 0.0725 Validation - Accuracy: 0.5432 Precision: 0.5714  Recall: 0.5554 F1 Score: 0.5472\n",
      "Epoch [470/1000], Loss: 0.0639 Validation - Accuracy: 0.5386 Precision: 0.5598  Recall: 0.5441 F1 Score: 0.5422\n",
      "Epoch [480/1000], Loss: 0.0356 Validation - Accuracy: 0.5432 Precision: 0.5753  Recall: 0.5460 F1 Score: 0.5471\n",
      "Epoch [490/1000], Loss: 0.0078 Validation - Accuracy: 0.5341 Precision: 0.5674  Recall: 0.5465 F1 Score: 0.5399\n",
      "Epoch [500/1000], Loss: 0.0701 Validation - Accuracy: 0.5523 Precision: 0.5789  Recall: 0.5551 F1 Score: 0.5548\n",
      "Epoch [510/1000], Loss: 0.0246 Validation - Accuracy: 0.5455 Precision: 0.5683  Recall: 0.5533 F1 Score: 0.5497\n",
      "Epoch [520/1000], Loss: 0.0465 Validation - Accuracy: 0.5364 Precision: 0.5811  Recall: 0.5521 F1 Score: 0.5405\n",
      "Epoch [530/1000], Loss: 0.0419 Validation - Accuracy: 0.5432 Precision: 0.5665  Recall: 0.5527 F1 Score: 0.5465\n",
      "Epoch [540/1000], Loss: 0.0501 Validation - Accuracy: 0.5500 Precision: 0.5733  Recall: 0.5523 F1 Score: 0.5515\n",
      "Epoch [550/1000], Loss: 0.0213 Validation - Accuracy: 0.5295 Precision: 0.5713  Recall: 0.5426 F1 Score: 0.5374\n",
      "Epoch [560/1000], Loss: 0.0746 Validation - Accuracy: 0.5364 Precision: 0.5668  Recall: 0.5405 F1 Score: 0.5412\n",
      "Epoch [570/1000], Loss: 0.0060 Validation - Accuracy: 0.5364 Precision: 0.5734  Recall: 0.5269 F1 Score: 0.5344\n",
      "Epoch [580/1000], Loss: 0.0163 Validation - Accuracy: 0.5273 Precision: 0.5707  Recall: 0.5422 F1 Score: 0.5345\n",
      "Epoch [590/1000], Loss: 0.0514 Validation - Accuracy: 0.5591 Precision: 0.5732  Recall: 0.5634 F1 Score: 0.5578\n",
      "Epoch [600/1000], Loss: 0.0121 Validation - Accuracy: 0.5636 Precision: 0.5971  Recall: 0.5499 F1 Score: 0.5536\n",
      "Epoch [610/1000], Loss: 0.0397 Validation - Accuracy: 0.5386 Precision: 0.5636  Recall: 0.5418 F1 Score: 0.5421\n",
      "Epoch [620/1000], Loss: 0.0298 Validation - Accuracy: 0.5250 Precision: 0.5878  Recall: 0.5406 F1 Score: 0.5362\n",
      "Epoch [630/1000], Loss: 0.0074 Validation - Accuracy: 0.5432 Precision: 0.5577  Recall: 0.5484 F1 Score: 0.5446\n",
      "Epoch [640/1000], Loss: 0.0186 Validation - Accuracy: 0.5545 Precision: 0.5729  Recall: 0.5586 F1 Score: 0.5560\n",
      "Epoch [650/1000], Loss: 0.0039 Validation - Accuracy: 0.5409 Precision: 0.5665  Recall: 0.5471 F1 Score: 0.5430\n",
      "Epoch [660/1000], Loss: 0.0282 Validation - Accuracy: 0.5432 Precision: 0.5667  Recall: 0.5373 F1 Score: 0.5414\n",
      "Epoch [670/1000], Loss: 0.0196 Validation - Accuracy: 0.5318 Precision: 0.5692  Recall: 0.5201 F1 Score: 0.5291\n",
      "Epoch [680/1000], Loss: 0.0250 Validation - Accuracy: 0.5227 Precision: 0.5614  Recall: 0.5372 F1 Score: 0.5296\n",
      "Epoch [690/1000], Loss: 0.0202 Validation - Accuracy: 0.5500 Precision: 0.5671  Recall: 0.5533 F1 Score: 0.5507\n",
      "Epoch [700/1000], Loss: 0.0175 Validation - Accuracy: 0.5386 Precision: 0.5683  Recall: 0.5525 F1 Score: 0.5433\n",
      "Epoch [710/1000], Loss: 0.0430 Validation - Accuracy: 0.5023 Precision: 0.5762  Recall: 0.4879 F1 Score: 0.5015\n",
      "Epoch [720/1000], Loss: 3.0240 Validation - Accuracy: 0.4136 Precision: 0.5091  Recall: 0.4142 F1 Score: 0.3706\n",
      "Epoch [730/1000], Loss: 0.0503 Validation - Accuracy: 0.5273 Precision: 0.5873  Recall: 0.5386 F1 Score: 0.5318\n",
      "Epoch [740/1000], Loss: 0.0570 Validation - Accuracy: 0.5682 Precision: 0.5897  Recall: 0.5783 F1 Score: 0.5721\n",
      "Epoch [750/1000], Loss: 0.0074 Validation - Accuracy: 0.5568 Precision: 0.6047  Recall: 0.5694 F1 Score: 0.5646\n",
      "Epoch [760/1000], Loss: 0.0395 Validation - Accuracy: 0.5591 Precision: 0.6012  Recall: 0.5710 F1 Score: 0.5649\n",
      "Epoch [770/1000], Loss: 0.0043 Validation - Accuracy: 0.5545 Precision: 0.6271  Recall: 0.5711 F1 Score: 0.5684\n",
      "Epoch [780/1000], Loss: 0.0274 Validation - Accuracy: 0.5636 Precision: 0.5977  Recall: 0.5747 F1 Score: 0.5699\n",
      "Epoch [790/1000], Loss: 0.0280 Validation - Accuracy: 0.5568 Precision: 0.5969  Recall: 0.5689 F1 Score: 0.5629\n",
      "Epoch [800/1000], Loss: 0.0490 Validation - Accuracy: 0.5545 Precision: 0.6115  Recall: 0.5671 F1 Score: 0.5649\n",
      "Epoch [810/1000], Loss: 0.0588 Validation - Accuracy: 0.5364 Precision: 0.5764  Recall: 0.5354 F1 Score: 0.5404\n",
      "Epoch [820/1000], Loss: 0.0226 Validation - Accuracy: 0.5568 Precision: 0.5947  Recall: 0.5689 F1 Score: 0.5622\n",
      "Epoch [830/1000], Loss: 0.0541 Validation - Accuracy: 0.5591 Precision: 0.5933  Recall: 0.5723 F1 Score: 0.5633\n",
      "Epoch [840/1000], Loss: 0.0040 Validation - Accuracy: 0.5659 Precision: 0.6062  Recall: 0.5809 F1 Score: 0.5716\n",
      "Epoch [850/1000], Loss: 0.0184 Validation - Accuracy: 0.5545 Precision: 0.5852  Recall: 0.5601 F1 Score: 0.5574\n",
      "Epoch [860/1000], Loss: 0.0022 Validation - Accuracy: 0.5364 Precision: 0.5798  Recall: 0.5347 F1 Score: 0.5406\n",
      "Epoch [870/1000], Loss: 0.0377 Validation - Accuracy: 0.5545 Precision: 0.6125  Recall: 0.5717 F1 Score: 0.5623\n",
      "Epoch [880/1000], Loss: 0.0012 Validation - Accuracy: 0.5545 Precision: 0.5912  Recall: 0.5594 F1 Score: 0.5589\n",
      "Epoch [890/1000], Loss: 0.0503 Validation - Accuracy: 0.5455 Precision: 0.5771  Recall: 0.5468 F1 Score: 0.5488\n",
      "Epoch [900/1000], Loss: 0.0378 Validation - Accuracy: 0.5409 Precision: 0.5755  Recall: 0.5435 F1 Score: 0.5437\n",
      "Epoch [910/1000], Loss: 0.0288 Validation - Accuracy: 0.5500 Precision: 0.5810  Recall: 0.5500 F1 Score: 0.5535\n",
      "Epoch [920/1000], Loss: 0.1147 Validation - Accuracy: 0.5568 Precision: 0.5895  Recall: 0.5657 F1 Score: 0.5582\n",
      "Epoch [930/1000], Loss: 0.0398 Validation - Accuracy: 0.5364 Precision: 0.5749  Recall: 0.5392 F1 Score: 0.5373\n",
      "Epoch [940/1000], Loss: 0.0173 Validation - Accuracy: 0.5636 Precision: 0.5884  Recall: 0.5649 F1 Score: 0.5648\n",
      "Epoch [950/1000], Loss: 0.0182 Validation - Accuracy: 0.5591 Precision: 0.5909  Recall: 0.5710 F1 Score: 0.5629\n",
      "Epoch [960/1000], Loss: 0.0482 Validation - Accuracy: 0.4591 Precision: 0.5849  Recall: 0.4877 F1 Score: 0.4726\n",
      "Epoch [970/1000], Loss: 0.0192 Validation - Accuracy: 0.5477 Precision: 0.5803  Recall: 0.5535 F1 Score: 0.5520\n",
      "Epoch [980/1000], Loss: 0.0328 Validation - Accuracy: 0.5568 Precision: 0.5815  Recall: 0.5612 F1 Score: 0.5589\n",
      "Epoch [990/1000], Loss: 0.0327 Validation - Accuracy: 0.5614 Precision: 0.5994  Recall: 0.5746 F1 Score: 0.5660\n",
      "Epoch [1000/1000], Loss: 0.0435 Validation - Accuracy: 0.5500 Precision: 0.6004  Recall: 0.5509 F1 Score: 0.5537\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to device\n",
    "        outputs = model(images.float())  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Loss calculation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "    \n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images, labels\n",
    "            outputs = model(images.float())\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            accuracy.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            f1_score.update(preds, labels)\n",
    "\n",
    "        # Print validation metrics\n",
    "\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}', end=\" \")\n",
    "            print(f'Validation - Accuracy: {accuracy.compute().item():.4f} Precision: {precision.compute().item():.4f} ', end=\" \")\n",
    "            print(f'Recall: {recall.compute().item():.4f} F1 Score: {f1_score.compute().item():.4f}')\n",
    "\n",
    "        # Updating the list to save current metrics\n",
    "        val_accuracy.append(accuracy.compute().item())\n",
    "        val_precision.append(precision.compute().item())\n",
    "        val_recall.append(recall.compute().item())\n",
    "        val_fscore.append(f1_score.compute().item())\n",
    "\n",
    "        # Reset metrics for the next epoch\n",
    "        accuracy.reset()\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        f1_score.reset()\n",
    "        confusion_matrix.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.45%\n",
      "Test Precision: 99.3672%\n",
      "Test Recall: 99.4520%\n",
      "Test F1 Score: 0.9940\n",
      "Confusion Matrix:\n",
      "tensor([[100,   0,   0,   0,   0,   0,   0,   0,   0,   1],\n",
      "        [  0, 104,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0, 122,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0, 105,   0,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0, 121,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 109,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 132,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0, 111,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0, 103,   4],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  87]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_16856\\3474578151.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(torch.tensor(images, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and labels for metric calculations\n",
    "        all_preds.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "all_preds = torch.cat(all_preds).to(device)\n",
    "all_labels = torch.cat(all_labels).to(device)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy(all_preds, all_labels)\n",
    "test_precision = precision(all_preds, all_labels)\n",
    "test_recall = recall(all_preds, all_labels)\n",
    "test_f1 = f1_score(all_preds, all_labels)\n",
    "test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_confusion_matrix)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
