{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the device on which the processing is going to take place.\n",
    "device = torch.device(\"cpu\")\n",
    "# Preprocessing takes most of the time. \n",
    "# No significant reduction in training time if we use GPU as the model is not very big.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizeTransform:\n",
    "    \"\"\"\n",
    "    A class to binarize the input MNIST data.\n",
    "    \"\"\"\n",
    "    def __call__(self, img):\n",
    "        # Values are between 0 and 1 so I have binarized with threshold of 0.5\n",
    "        return (img>0.5).float()\n",
    "\n",
    "# Transform to be applied on to the data immediately after loading from location.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    BinarizeTransform()\n",
    "])\n",
    "\n",
    "# Load and transform MNIST data\n",
    "mnist_data_train = datasets.MNIST(root=\"data/MNIST\", train=True, download=True, transform=transform)\n",
    "mnist_data_test = datasets.MNIST(root=\"data/MNIST\", train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(mnist_data_train))       # Size of the train split\n",
    "val_size = len(mnist_data_train) - train_size       # Size of the validation split\n",
    "\n",
    "\n",
    "train_data, val_data = random_split(mnist_data_train, [train_size, val_size])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 6000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data), len(mnist_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all the rows of each mask-set in every file \n",
    "json_data = {\n",
    "    \"365nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(10, 15),\n",
    "        \"I3\":range(18, 23),\n",
    "        \"I4\":range(25, 30)\n",
    "    },\n",
    "    \"455nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(7, 12),\n",
    "        \"I3\":range(14, 19),\n",
    "        \"I4\":range(21, 26)\n",
    "    },\n",
    "    \"White\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(9, 14),\n",
    "        \"I3\":range(16, 21),\n",
    "        \"I4\":range(24, 29)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"365nm\"  # Excel document name from which data has to be extracted.\n",
    "path = \"data/\"+filename+\".xlsx\" # Excel doc path\n",
    "\n",
    "df = pd.read_excel(path, usecols='B:Q') # Read the excel sheet\n",
    "# Break the sheet down into different `DataFrame`s for every Mask-set in the table\n",
    "tables = [df.iloc[json_data[filename][key]].copy().reset_index(drop=True) for key in list(json_data[filename].keys())]\n",
    "\n",
    "NUMBER_OF_MASK_SETS = 1\n",
    "mask_sets = np.random.randint(0, 20, (NUMBER_OF_MASK_SETS,))\n",
    "mask_sets = np.array([(n//5, n%5) for n in mask_sets])  # [ (current_mask, optical_mask) ]\n",
    "\n",
    "# Model hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mnist_data, tables, mask_sets):\n",
    "\n",
    "        self.processed_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx in range(len(mnist_data)):\n",
    "            image, label = mnist_data[idx]\n",
    "            image = image.reshape(1, 196, 4)\n",
    "            image_combined = (\n",
    "                image[:, :, 0] * 1000 + \n",
    "                image[:, :, 1] * 100 + \n",
    "                image[:, :, 2] * 10 + \n",
    "                image[:, :, 3]\n",
    "            )\n",
    "            x = [ tables[current_mask].loc[optical_mask][image_combined[0].tolist()].tolist()\n",
    "                 for current_mask, optical_mask in mask_sets\n",
    "                 ]\n",
    "            x = torch.tensor(x).reshape((1, 196 * len(mask_sets)))\n",
    "            self.processed_data.append(x)\n",
    "            self.labels.append(label)\n",
    "\n",
    "            if (idx+1)%1000 == 0:\n",
    "                print(f\"{(idx+1)}/{len(mnist_data)} done\")\n",
    "\n",
    "        \n",
    "        self.processed_data = torch.cat(self.processed_data, axis = 0)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.processed_data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.processed_data[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/54000 done\n",
      "2000/54000 done\n",
      "3000/54000 done\n",
      "4000/54000 done\n",
      "5000/54000 done\n",
      "6000/54000 done\n",
      "7000/54000 done\n",
      "8000/54000 done\n",
      "9000/54000 done\n",
      "10000/54000 done\n",
      "11000/54000 done\n",
      "12000/54000 done\n",
      "13000/54000 done\n",
      "14000/54000 done\n",
      "15000/54000 done\n",
      "16000/54000 done\n",
      "17000/54000 done\n",
      "18000/54000 done\n",
      "19000/54000 done\n",
      "20000/54000 done\n",
      "21000/54000 done\n",
      "22000/54000 done\n",
      "23000/54000 done\n",
      "24000/54000 done\n",
      "25000/54000 done\n",
      "26000/54000 done\n",
      "27000/54000 done\n",
      "28000/54000 done\n",
      "29000/54000 done\n",
      "30000/54000 done\n",
      "31000/54000 done\n",
      "32000/54000 done\n",
      "33000/54000 done\n",
      "34000/54000 done\n",
      "35000/54000 done\n",
      "36000/54000 done\n",
      "37000/54000 done\n",
      "38000/54000 done\n",
      "39000/54000 done\n",
      "40000/54000 done\n",
      "41000/54000 done\n",
      "42000/54000 done\n",
      "43000/54000 done\n",
      "44000/54000 done\n",
      "45000/54000 done\n",
      "46000/54000 done\n",
      "47000/54000 done\n",
      "48000/54000 done\n",
      "49000/54000 done\n",
      "50000/54000 done\n",
      "51000/54000 done\n",
      "52000/54000 done\n",
      "53000/54000 done\n",
      "54000/54000 done\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training dataset\n",
    "train_dataset = CustomDataset(train_data, tables=tables, mask_sets=mask_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/6000 done\n",
      "2000/6000 done\n",
      "3000/6000 done\n",
      "4000/6000 done\n",
      "5000/6000 done\n",
      "6000/6000 done\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = CustomDataset(val_data, tables=tables, mask_sets=mask_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/10000 done\n",
      "2000/10000 done\n",
      "3000/10000 done\n",
      "4000/10000 done\n",
      "5000/10000 done\n",
      "6000/10000 done\n",
      "7000/10000 done\n",
      "8000/10000 done\n",
      "9000/10000 done\n",
      "10000/10000 done\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(mnist_data_test, tables=tables, mask_sets=mask_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadoutLayer(nn.Module):\n",
    "    \"\"\"Readout layer.\n",
    "    Parameters - \n",
    "\n",
    "    Attributes - \n",
    "    fc : `nn.Linear`\n",
    "            Fully connected layer to be trained for reservoir computing.\n",
    "    activation : `nn.functional.leaky_relu`\n",
    "            Activation layer to be applied\n",
    "    \n",
    "    softmax : `nn.Softmax`\n",
    "            Softmax activation function to get the one-hot encoded results.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # super function to initialize the constructors of the parent classes.\n",
    "        super(ReadoutLayer, self).__init__()\n",
    "        # Class Attributes\n",
    "        self.fc = nn.Linear(len(mask_sets)*196, 10) \n",
    "        self.activation = nn.functional.leaky_relu\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward method to be executed on function call.\n",
    "        Parameters - \n",
    "        x : torch.tensor\n",
    "            Shape( Batch_size, 196 * len(mask_sets) )\n",
    "        \n",
    "        Returns : torch.tensor\n",
    "            Shape( Batch_size, 10 )\n",
    "        \"\"\"\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.3007\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [2/100], Loss: 2.3028\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [3/100], Loss: 2.3024\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [4/100], Loss: 2.3062\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [5/100], Loss: 2.3026\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [6/100], Loss: 2.2995\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [7/100], Loss: 2.3018\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [8/100], Loss: 2.2864\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [9/100], Loss: 2.3045\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [10/100], Loss: 2.3001\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [11/100], Loss: 2.2985\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [12/100], Loss: 2.3094\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [13/100], Loss: 2.2997\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [14/100], Loss: 2.2967\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [15/100], Loss: 2.2991\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [16/100], Loss: 2.3092\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [17/100], Loss: 2.2996\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [18/100], Loss: 2.3012\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [19/100], Loss: 2.2906\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [20/100], Loss: 2.3038\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [21/100], Loss: 2.3072\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [22/100], Loss: 2.2901\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [23/100], Loss: 2.3026\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [24/100], Loss: 2.2985\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [25/100], Loss: 2.2988\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [26/100], Loss: 2.3030\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [27/100], Loss: 2.3036\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [28/100], Loss: 2.3039\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [29/100], Loss: 2.3068\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [30/100], Loss: 2.3002\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [31/100], Loss: 2.3022\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [32/100], Loss: 2.2957\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [33/100], Loss: 2.3028\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [34/100], Loss: 2.3051\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [35/100], Loss: 2.2984\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [36/100], Loss: 2.2976\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [37/100], Loss: 2.3109\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [38/100], Loss: 2.3034\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [39/100], Loss: 2.3051\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [40/100], Loss: 2.2977\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [41/100], Loss: 2.3044\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [42/100], Loss: 2.2911\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [43/100], Loss: 2.2985\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [44/100], Loss: 2.2937\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [45/100], Loss: 2.3087\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [46/100], Loss: 2.3062\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [47/100], Loss: 2.3088\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [48/100], Loss: 2.3108\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [49/100], Loss: 2.3052\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [50/100], Loss: 2.3009\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [51/100], Loss: 2.3073\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [52/100], Loss: 2.3009\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [53/100], Loss: 2.3043\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [54/100], Loss: 2.3000\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [55/100], Loss: 2.3096\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [56/100], Loss: 2.2983\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [57/100], Loss: 2.3026\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [58/100], Loss: 2.2942\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [59/100], Loss: 2.2988\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [60/100], Loss: 2.2954\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [61/100], Loss: 2.3095\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [62/100], Loss: 2.2985\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [63/100], Loss: 2.3057\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [64/100], Loss: 2.3069\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n",
      "Epoch [65/100], Loss: 2.2945\n",
      "Validation Accuracy: 0.1125 Precision: 0.0112 Validation Recall: 0.1000 F1 Score: 0.0202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \u001b[38;5;66;03m# Loss calculation\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:340\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    331\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    332\u001b[0m     (inputs,)\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[0;32m    337\u001b[0m )\n\u001b[0;32m    339\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 340\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32md:\\Reservoir-computing\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:220\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m    219\u001b[0m         new_grads\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 220\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         )\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "model = ReadoutLayer()\n",
    "# Loss function, Categorical crossentropy loss for multi-class classification problem\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimizer to update the gradients.\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "val_accuracy, val_precision, val_recall, val_fscore = [], [], [], []\n",
    "# Evaluation metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "\n",
    "# Class-wise Confusion matrix\n",
    "confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to device\n",
    "        outputs = model(images.float())  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Loss calculation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images.float())\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            accuracy.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            f1_score.update(preds, labels)\n",
    "\n",
    "        # Print validation metrics\n",
    "        print(f'Validation Accuracy: {accuracy.compute().item():.4f} Precision: {precision.compute().item():.4f} ', end=\"\")\n",
    "        print(f'Validation Recall: {recall.compute().item():.4f} F1 Score: {f1_score.compute().item():.4f}')\n",
    "\n",
    "        # Updating the list to save current metrics\n",
    "        val_accuracy.append(accuracy.compute().item())\n",
    "        val_precision.append(precision.compute().item())\n",
    "        val_recall.append(recall.compute().item())\n",
    "        val_fscore.append(f1_score.compute().item())\n",
    "\n",
    "        # Reset metrics for the next epoch\n",
    "        accuracy.reset()\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        f1_score.reset()\n",
    "        confusion_matrix.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54000, 196])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.48%\n",
      "Test Precision: 87.4476%\n",
      "Test Recall: 87.2869%\n",
      "Test F1 Score: 0.8729\n",
      "Confusion Matrix:\n",
      "tensor([[ 927,    0,   12,    4,    1,    6,   12,    6,   10,    2],\n",
      "        [   0, 1093,    2,   10,    2,    3,    7,    2,   16,    0],\n",
      "        [  10,    8,  872,   21,   26,    7,   14,   12,   55,    7],\n",
      "        [   2,    4,   32,  877,    3,   30,    3,   16,   32,   11],\n",
      "        [   0,    8,    5,    1,  874,    1,   19,   11,   10,   53],\n",
      "        [  13,   10,    5,   61,   24,  691,   16,   16,   48,    8],\n",
      "        [  18,    4,   12,    0,   17,   15,  878,    4,    7,    3],\n",
      "        [   2,   15,   15,    9,   13,    1,    0,  925,   16,   32],\n",
      "        [  15,   14,   26,   27,   16,   23,   14,   18,  811,   10],\n",
      "        [   7,   10,    3,   21,   88,   14,    0,   44,   22,  800]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_30172\\247194469.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(torch.tensor(images, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and labels for metric calculations\n",
    "        all_preds.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "all_preds = torch.cat(all_preds).to(device)\n",
    "all_labels = torch.cat(all_labels).to(device)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy(all_preds, all_labels)\n",
    "test_precision = precision(all_preds, all_labels)\n",
    "test_recall = recall(all_preds, all_labels)\n",
    "test_f1 = f1_score(all_preds, all_labels)\n",
    "test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_confusion_matrix)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/mnist_results/\" + filename + '_' + ''.join(map(str, mask_sets)) + '.npz'\n",
    "np.savez(save_path,\n",
    "         predictions = all_preds,\n",
    "         labels = all_labels,\n",
    "         validation_accuracy = val_accuracy,\n",
    "         validation_precision = val_precision,\n",
    "         validation_recall = val_recall,\n",
    "         validation_fscore = val_fscore\n",
    "         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# # Hyperparameters\n",
    "# batch_size = 64\n",
    "# learning_rate = 0.001\n",
    "# epochs = 5\n",
    "\n",
    "# # MNIST dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# train_dataset = datasets.MNIST(root='./data/MNIST', train=True, transform=transform, download=False)\n",
    "# test_dataset = datasets.MNIST(root='./data/MNIST', train=False, transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # Define the single-layer MLP model\n",
    "# class SingleLayerMLP(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SingleLayerMLP, self).__init__()\n",
    "#         self.fc = nn.Linear(784, 10)  # Input layer (784) to output layer (10 classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 28*28)  # Flatten the input\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "# # Initialize model, loss function, and optimizer\n",
    "# model = SingleLayerMLP()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Initialize metrics\n",
    "# accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "# precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "# recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "# f1_score = F1Score(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "# confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=10).to(device)\n",
    "\n",
    "# # Training loop\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     for images, labels in train_loader:\n",
    "#         # Move images and labels to GPU\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Testing loop\n",
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         # Move images and labels to GPU\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#         # Append predictions and labels for metric calculations\n",
    "#         all_preds.append(predicted)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "# # Concatenate all predictions and labels\n",
    "# all_preds = torch.cat(all_preds)\n",
    "# all_labels = torch.cat(all_labels)\n",
    "\n",
    "# # Calculate metrics\n",
    "# test_accuracy = accuracy(all_preds, all_labels)\n",
    "# test_precision = precision(all_preds, all_labels)\n",
    "# test_recall = recall(all_preds, all_labels)\n",
    "# test_f1 = f1_score(all_preds, all_labels)\n",
    "# test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "# print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "# print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "# print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "# print(f'Test F1 Score: {test_f1:.4f}')\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
