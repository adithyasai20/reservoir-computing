{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item for item in os.listdir(\"data/kth_dataset\") if os.path.isdir(os.path.join(\"data/kth_dataset\", item))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (75854, 30, 40)\n",
      "Combined labels shape: (75854, 6)\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(\"data\\kth_dataset\\processed_data.npz\")\n",
    "combined_data = []\n",
    "combined_labels = []\n",
    "\n",
    "# Loop through the dictionary to combine data and labels\n",
    "for label, data_array in data_dict.items():\n",
    "    # Append the data array entries to all_data\n",
    "    combined_data.append(data_array)  # Keeps the (num_entries, 4, width, height) shape\n",
    "    \n",
    "    # Create a list of labels for each entry in this data_array and extend all_labels\n",
    "    combined_labels.extend([label] * data_array.shape[0])\n",
    "\n",
    "del(data_array)\n",
    "# Concatenate all data along the first axis to create a single numpy array\n",
    "combined_data = np.concatenate(combined_data, axis=0)  # Shape: (total_entries, 4, width, height)\n",
    "combined_labels = np.array(combined_labels)             # Shape: (total_entries,)\n",
    "\n",
    "\n",
    "# Convert each label in combined_labels to its corresponding index\n",
    "label_indices = [labels.index(label) for label in combined_labels]\n",
    "\n",
    "# Create a one-hot encoded array using np.eye\n",
    "num_classes = len(labels)\n",
    "one_hot_labels = np.eye(num_classes)[label_indices]  # Shape: (total_entries, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indices = np.random.permutation(combined_data.shape[0])\n",
    "shuffled_data = combined_data[indices]\n",
    "shuffled_labels = one_hot_labels[indices]\n",
    "del(combined_data, combined_labels, one_hot_labels, data_dict, label_indices, indices)\n",
    "\n",
    "print(\"Combined data shape:\", shuffled_data.shape)\n",
    "print(\"Combined labels shape:\", shuffled_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e+00, 1.000e+01, 1.100e+01, 1.000e+02, 1.010e+02,\n",
       "       1.100e+02, 1.110e+02, 1.000e+03, 1.001e+03, 1.010e+03, 1.011e+03,\n",
       "       1.100e+03, 1.101e+03, 1.110e+03, 1.111e+03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(shuffled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16e1efc5c10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = shuffled_data[900]\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (56890, 30, 40)\n",
      "Train labels shape: (56890, 6)\n",
      "Validation data shape: (7585, 30, 40)\n",
      "Validation labels shape: (7585, 6)\n",
      "Test data shape: (11379, 30, 40)\n",
      "Test labels shape: (11379, 6)\n"
     ]
    }
   ],
   "source": [
    "# Define the split ratios\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Total number of entries\n",
    "total_entries = shuffled_data.shape[0]\n",
    "\n",
    "# Calculate split indices\n",
    "train_end = int(total_entries * train_ratio)\n",
    "val_end = train_end + int(total_entries * val_ratio)\n",
    "\n",
    "# Split the data and labels\n",
    "train_data = shuffled_data[:train_end]\n",
    "train_labels = shuffled_labels[:train_end]\n",
    "\n",
    "val_data = shuffled_data[train_end:val_end]\n",
    "val_labels = shuffled_labels[train_end:val_end]\n",
    "\n",
    "test_data = shuffled_data[val_end:]\n",
    "test_labels = shuffled_labels[val_end:]\n",
    "\n",
    "del(shuffled_data, shuffled_labels)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all the rows of each mask-set in every file \n",
    "json_data = {\n",
    "    \"365nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(10, 15),\n",
    "        \"I3\":range(18, 23),\n",
    "        \"I4\":range(25, 30)\n",
    "    },\n",
    "    \"455nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(7, 12),\n",
    "        \"I3\":range(14, 19),\n",
    "        \"I4\":range(21, 26)\n",
    "    },\n",
    "    \"White\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(9, 14),\n",
    "        \"I3\":range(16, 21),\n",
    "        \"I4\":range(24, 29)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tables = []\n",
    "for filename in [\"White\", \"365nm\", \"455nm\"]:\n",
    "    path = \"data/\"+filename+\".xlsx\" \n",
    "    df = pd.read_excel(path, usecols='B:Q') # Read the excel sheet\n",
    "    tables = [df.iloc[json_data[filename][key]].copy().reset_index(drop=True) for key in list(json_data[filename].keys())]\n",
    "    combined_table = pd.concat(tables, axis=0)\n",
    "    combined_tables.append(combined_table)\n",
    "    del(df, tables, combined_table)\n",
    "\n",
    "combined_tables[1] = combined_tables[1].reindex(columns=combined_tables[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MASKS = 2\n",
    "optical_range = np.array([0, 1, 2])  # Optical masks: 0, 1, 2\n",
    "electrical_range = np.array([0, 1, 2, 3])  # Electrical masks: 0, 1, 2, 3\n",
    "\n",
    "# Generate a meshgrid of all combinations, so that we don't sample same pair twice\n",
    "optical_masks, electrical_masks = np.meshgrid(optical_range, electrical_range, indexing='ij')\n",
    "all_pairs = np.column_stack((optical_masks.ravel(), electrical_masks.ravel()))\n",
    "\n",
    "unique_indices = np.random.choice(all_pairs.shape[0], size=NUMBER_OF_MASKS, replace=False)\n",
    "\n",
    "selected_pairs = all_pairs[unique_indices]\n",
    "optical_masks = selected_pairs[:, 0]\n",
    "electrical_masks = selected_pairs[:, 1]\n",
    "\n",
    "\n",
    "# Use this to override previous values,  if you want a specific set of masks\n",
    "# optical_masks = np.array([0, 1, 2])\n",
    "# electrical_masks = np.array([0, 1, 2])\n",
    "\n",
    "# Device masks\n",
    "\n",
    "number_of_devices = np.multiply(*train_data.shape[-2:])\n",
    "\n",
    "# device_mask = np.random.randint(0, 5, (NUMBER_OF_MASKS, number_of_devices))\n",
    "\n",
    "device_mask = np.ones((NUMBER_OF_MASKS, number_of_devices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0] [3 3] (2, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(optical_masks, electrical_masks, device_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset:np.array, \n",
    "                 labels:np.array, \n",
    "                 combined_tables:np.array, \n",
    "                 optical_masks:np.array, \n",
    "                 electrical_masks:np.array, \n",
    "                 device_mask:np.array):\n",
    "        self.processed_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx in tqdm(range(len(dataset))):\n",
    "            image, label = dataset[idx], labels[idx]\n",
    "            # image = (\n",
    "            #     images[0]*1000+\n",
    "            #     images[1]*100+\n",
    "            #     images[2]*10+\n",
    "            #     images[3]\n",
    "            # )\n",
    "            image = image.flatten()\n",
    "            \n",
    "            column_indices = combined_tables[0].columns.get_indexer(image.tolist())\n",
    "            x = []\n",
    "            for j, (optical_mask, electrical_mask) in enumerate(zip(optical_masks, electrical_masks)):\n",
    "                required_table = combined_tables[optical_mask].iloc[electrical_mask*5:(electrical_mask+1)*5].iloc[device_mask[j]]\n",
    "                # print(required_table.shape)\n",
    "\n",
    "                # to_add = required_table.values[np.arange(device_mask.shape[-1]), column_indices]*1e9\n",
    "\n",
    "                # plt.imshow(to_add.reshape(43, 54))\n",
    "\n",
    "                # print(y)\n",
    "\n",
    "                x.append(required_table.values[np.arange(device_mask.shape[-1]), column_indices]*1e9)\n",
    "            \n",
    "            x = np.concatenate(x, axis=0)\n",
    "\n",
    "            # print(y)\n",
    "            \n",
    "            self.processed_data.append(x)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.processed_data = torch.tensor(self.processed_data).to(device=device)\n",
    "        self.labels = torch.tensor(self.labels).to(device=device)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.processed_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx], self.labels[idx]\n",
    "    \n",
    "# train_dataset = CustomDataset(train_data, train_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1000,  100,   10,    1, 1100,  110, 1010, 1001,  101,   11, 1110, 1101,\n",
       "       1011,  111, 1111,    0],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tables[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 2048\n",
    "class ReadoutLayer(nn.Module):\n",
    "    def __init__(self, input_size:int):\n",
    "        super(ReadoutLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, len(labels))\n",
    "        self.activation = nn.functional.relu\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc(x))\n",
    "        x = self.softmax(x)\n",
    "        # x = x.reshape(BATCH_SIZE, 1, NUMBER_OF_MASKS*144, 180)\n",
    "        \n",
    "        # x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "# class ReadoutLayer(nn.Module):\n",
    "#     def __init__(self, input_channels:int):\n",
    "#         super(ReadoutLayer, self).__init__()\n",
    "        \n",
    "#         # Define convolutional layers for feature extraction\n",
    "#         self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)  # First convolutional layer\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Second convolutional layer\n",
    "        \n",
    "#         # Fully connected layer for classification (after flattening the output from conv layers)\n",
    "#         self.fc = nn.Linear(64 * 36 * 45, 10)  # Adjust this depending on the dimensions after convolution\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Reshape the input to (BATCH_SIZE, input_channels, height, width)\n",
    "#         x = x.reshape(BATCH_SIZE, 1, NUMBER_OF_MASKS * 144, 180)\n",
    "        \n",
    "#         # Apply the first convolutional layer with ReLU activation\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.max_pool2d(x, 2)  # Apply max pooling to downsample\n",
    "        \n",
    "#         # Apply the second convolutional layer with ReLU activation\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2)  # Apply max pooling to downsample\n",
    "        \n",
    "#         # Flatten the output to feed into the fully connected layer\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "#         # Pass through the fully connected layer for classification\n",
    "#         x = self.fc(x)\n",
    "        \n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56890/56890 [00:29<00:00, 1953.22it/s]\n",
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_46404\\2448274079.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  self.processed_data = torch.tensor(self.processed_data).to(device=device)\n",
      "100%|██████████| 7585/7585 [00:04<00:00, 1755.61it/s]\n",
      "100%|██████████| 11379/11379 [00:05<00:00, 1946.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_data, train_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "validation_dataset = CustomDataset(val_data, val_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "test_dataset = CustomDataset(test_data, test_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2400])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x16e1f43c1d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGKCAYAAACYZ+KgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqzklEQVR4nO3df3RU9Z3/8deAZADJDEZMJjGBRrEBhIQWAQdaGiQlxC4HKseDtKcESvHoJh4h29KNR8UfPWda0YJ1U7DHlay7RhS/gqeshWIw4bAEdonNInTNkSw1sWTillMmEE3AzP3+gUy9koQ7uZPMDPN8nPM5x7lzP3M/l9td3rzfn8/nOgzDMAQAAPC5IdEeAAAAiC0EBwAAwITgAAAAmBAcAAAAE4IDAABgQnAAAABMCA4AAIAJwQEAADAhOAAAACYEBwAAwITgAACAGLR582bl5ubK5XLJ5XLJ6/Xqd7/7XZ99tm/frgkTJmj48OGaMmWK3nrrrX5dm+AAAIAYlJmZqZ///Oeqr6/XkSNHdMcdd2jRokU6fvx4j+cfPHhQy5Yt06pVq/SHP/xBixcv1uLFi3Xs2LGwr+3gxUsAAPSts7NT58+ft/07SUlJGj58eL/7p6SkaMOGDVq1atVl3y1dulQdHR3atWtX6Njtt9+uqVOnasuWLWFd55p+jxAAgATQ2dmp7HGj5P+42/ZveTwe/fd//7cpQHA6nXI6nX326+7u1vbt29XR0SGv19vjOXV1dSorKzMdKyws1M6dO8MeJ8EBAAB9OH/+vPwfd+vD+q/Ildz/anz72aDGTfuT0tLSTMfXr1+vxx57rMc+7733nrxerzo7OzVq1Cjt2LFDkyZN6vFcv99/2W+npaXJ7/eHPVaCAwAALBiV7NCoZEe/+wd1sW9LS4tcLlfoeF9Zg5ycHDU0NCgQCOj1119XcXGxamtrew0QIoXgAAAAC7qNoLptzNLrNoKSFFp9YEVSUpLGjx8vSZo2bZr+67/+S88++6yef/75y871eDxqa2szHWtra5PH4wl7rKxWAAAgTgSDQXV1dfX4ndfrVXV1tenY3r17e52j0BcyBwAAWBCUoaD6nzoIt295ebmKioo0duxYnT17VlVVVaqpqdGePXskScuXL9eNN94on88nSXrwwQf1rW99S88884y+853vaNu2bTpy5Ih+85vfhD1WggMAACwIKqigzf7h+Pjjj7V8+XK1trbK7XYrNzdXe/bs0be//W1JUnNzs4YM+VsBYNasWaqqqtLDDz+shx56SLfccot27typyZMnhz1W9jkAAKAP7e3tcrvdOtWYaXu1QkbORwoEApbnHEQLmQMAACzoNgx12/j3tJ2+g43gAAAACwZ7zkE0sVoBAACYkDkAAMCCoAx1J0jmgOAAAAALEqmsQHAAAIAFiTQhkTkHAADAhMwBAAAWBD9vdvrHC4IDAAAs6LY5IdFO38FGWQEAAJiQOQAAwIJuQzZf2Ry5sQw0ggMAACxIpDkHlBUAAIAJmQMAACwIyqFuOWz1jxcEBwAAWBA0LjY7/eMFZQUAAGBC5gAAAAu6bZYV7PQdbAQHAABYQHAAAABMgoZDQcPGhEQbfQcbcw4AAIAJmQMAACygrAAAAEy6NUTdNhLu3REcy0CjrAAAAEzIHAAAYIFhc0KiEUcTEgkOAACwIJHmHFBWAAAAJmQOAACwoNsYom7DxoTEOHq3QswFB8FgUKdOnVJycrIcjvhJwQAABp9hGDp79qwyMjI0ZMjAJsODcihoI+EeVPxEBzEXHJw6dUpZWVnRHgYAII60tLQoMzNzQK+RSHMOYi44SE5OliR9Q3fqGg2L8mgAALHsM13QAb0V+rsDkTFgwUFFRYU2bNggv9+vvLw8Pffcc5oxY8YV+10qJVyjYbrGQXAAAOjD55n6wShD259zED9lhQEp0Lz66qsqKyvT+vXr9e677yovL0+FhYX6+OOPB+JyAAAMuItzDuy1eDEgwcEvf/lLrV69WitXrtSkSZO0ZcsWjRw5Ui+++OJl53Z1dam9vd3UAABA9EQ8ODh//rzq6+tVUFDwt4sMGaKCggLV1dVddr7P55Pb7Q41JiMCAGJR8PN3K/S32VnpMNgiPtK//OUv6u7uVlpamul4Wlqa/H7/ZeeXl5crEAiEWktLS6SHBACAbZfmHNhp8SLqqxWcTqecTme0hwEAAD4X8eBgzJgxGjp0qNra2kzH29ra5PF4In05AAAGRdBmaSCeNkGKeI4jKSlJ06ZNU3V1dehYMBhUdXW1vF5vpC8HAMCg6DYctlu8GJCyQllZmYqLi3XbbbdpxowZ2rRpkzo6OrRy5cqBuBwAAIigAQkOli5dqv/7v//To48+Kr/fr6lTp2r37t2XTVIEACBeXFp10P/+8VNWGLAJiaWlpSotLR2onwcAYFAFjSEK2lhxEIyjHRKjvloBAIB4kEiZg/hZdAkAAAYFmQMAACwISrZWHAQjN5QBR3AAAIAF9vc5iJ9kffyMFAAADAoyBwAAWGD3/Qi8WwEAgKtMUA4FZWfOQYLvkAjgov/30SFL5y3JvH2ARwIA1hEcAABgAWUFAABgYn8TpPgJDuJnpAAAYFCQOQAAwIKg4VDQziZIif7KZgAArjZBm2WFeNoEieAAAAAL7L+VMX6Cg/gZKQAAGBRkDgAAsKBbDnXb2MjITt/BRnAAAIAFiVRWIDgA+sHqzoejhgy3dN6eUw02RtM/nwTPWzovaPFFs+zyCESWz+fTG2+8offff18jRozQrFmz9Itf/EI5OTm99qmsrNTKlStNx5xOpzo7O8O6dvyEMQAARFG3/lZa6F8LT21trUpKSnTo0CHt3btXFy5c0Pz589XR0dFnP5fLpdbW1lD78MMPw75XMgcAAFgQqbJCe3u76bjT6ZTT6bzs/N27d5s+V1ZWKjU1VfX19ZozZ06v13E4HPJ4PP0ep0TmAACAQZWVlSW32x1qPp/PUr9AICBJSklJ6fO8c+fOady4ccrKytKiRYt0/PjxsMdI5gAAAAsi9eKllpYWuVyu0PGesgZfFgwGtWbNGs2ePVuTJ0/u9bycnBy9+OKLys3NVSAQ0NNPP61Zs2bp+PHjyszMtDxWggMAACww5FDQxnJE4/O+LpfLFBxYUVJSomPHjunAgQN9nuf1euX1ekOfZ82apYkTJ+r555/Xk08+afl6BAcAAMSw0tJS7dq1S/v37w/rX/+SNGzYMH3ta1/TiRMnwurHnAMAACy4VFaw08JhGIZKS0u1Y8cO7du3T9nZ2eGPubtb7733ntLT08PqR+YAAAALBvutjCUlJaqqqtKbb76p5ORk+f1+SZLb7daIESMkScuXL9eNN94YmtT4xBNP6Pbbb9f48eN15swZbdiwQR9++KF+9KMfhXVtggMAACzotvlWxnD7bt68WZKUn59vOr5161atWLFCktTc3KwhQ/72u3/961+1evVq+f1+XXfddZo2bZoOHjyoSZMmhXVtggOgH4ZcBRW5kUOSLJ1ndSdFq7tGspMiYI1hGFc8p6amxvR548aN2rhxo+1rExwAAGDBYJcVoongAAAAC4IaoqCNrKGdvoMtfkYKAAAGBZkDAAAs6DYc6rZRGrDTd7ARHAAAYEEizTmgrAAAAEzIHAAAYIFh85XNho2+g43gAAAAC7rlULeNFy/Z6TvY4ieMAQAAg4LMAfAFVnf5Gzlk+ACPJHZY3UnxXLBzgEcCRFfQsDepMHjlDQ9jRsQzB4899pgcDoepTZgwIdKXAQBgUAU/n3Ngp8WLAckc3HrrrXr77bf/dpFrSFAAAOJbUA4FbcwbsNN3sA3I39rXXHONPB7PQPw0AAAYYAOS4/jggw+UkZGhm266Sd///vfV3Nzc67ldXV1qb283NQAAYs2lHRLttHgR8eBg5syZqqys1O7du7V582adPHlS3/zmN3X27Nkez/f5fHK73aGWlZUV6SEBAGBbIs05iPhIi4qKdPfddys3N1eFhYV66623dObMGb322ms9nl9eXq5AIBBqLS0tkR4SAAAIw4DPFBw9erS++tWv6sSJEz1+73Q65XQ6B3oYAADYEpTNdyvE0YTEAc9xnDt3Tk1NTUpPTx/oSwEAMGCMz1cr9LcZiRwc/PjHP1Ztba3+9Kc/6eDBg/rud7+roUOHatmyZZG+FAAAGAARLyt89NFHWrZsmU6fPq0bbrhB3/jGN3To0CHdcMMNkb4UEHFD2FG83/izw9UukV7ZHPHgYNu2bZH+SQAAos7uioOEXq0AAADiG/saAwBgAWUFAABgwrsVAACASSJlDphzAAAATMgcAABgQSJlDggOAACwIJGCA8oKAADAhMwB8AXfzZxh6bw9pxoGdiBxyOqfHRCvEilzQHAAAIAFhuwtRzQiN5QBR1kBAACYkDkAAMACygoAAMAkkYIDygoAAMCEzAEAABYkUuaA4AAAAAsIDgAAgIlhOGTY+AveTt/BRnAA9ENhxlRL510NmyVZvVcAVw+CAwAALAjKYWsTJDt9BxvBAQAAFiTSnAOWMgIAABMyBwAAWMCERAAAYEJZAQAAJCwyBwAAWEBZAQAAmBg2ywrxFBxQVgAAACZkDgAAsMCQZBj2+scLggMAACwIyiEHOyQCAIBLEmlCInMOAACACZkDAAAsCBoOORJkEySCAwAALDAMmxMS42hGImUFAABgQuYAAAALEmlCIsEBAAAWJFJwQFkBAIAY5PP5NH36dCUnJys1NVWLFy9WY2PjFftt375dEyZM0PDhwzVlyhS99dZbYV+bzAEwgAozplo6b8+phgEdBwD7Bnu1Qm1trUpKSjR9+nR99tlneuihhzR//nz98Y9/1LXXXttjn4MHD2rZsmXy+Xz6u7/7O1VVVWnx4sV69913NXnyZMvXJjgAAMCCwV6tsHv3btPnyspKpaamqr6+XnPmzOmxz7PPPqsFCxboJz/5iSTpySef1N69e/VP//RP2rJli+Vrh11W2L9/vxYuXKiMjAw5HA7t3LnT9L1hGHr00UeVnp6uESNGqKCgQB988EG4lwEA4KrU3t5ual1dXZb6BQIBSVJKSkqv59TV1amgoMB0rLCwUHV1dWGNMezgoKOjQ3l5eaqoqOjx+6eeekq/+tWvtGXLFh0+fFjXXnutCgsL1dnZGe6lAACIGRczBw4b7eLvZGVlye12h5rP57vitYPBoNasWaPZs2f3WR7w+/1KS0szHUtLS5Pf7w/rXsMuKxQVFamoqKjH7wzD0KZNm/Twww9r0aJFkqSXXnpJaWlp2rlzp+65555wLwcAQEyI1GqFlpYWuVyu0HGn03nFviUlJTp27JgOHDjQ7+uHI6KrFU6ePCm/329Kabjdbs2cObPXlEZXV9dlKRYAAGKNEYEmSS6Xy9SuFByUlpZq165deuedd5SZmdnnuR6PR21tbaZjbW1t8ng84dxqZIODS2mLcFIaPp/PlF7JysqK5JAAAIhLhmGotLRUO3bs0L59+5SdnX3FPl6vV9XV1aZje/fuldfrDevaUd/noLy8XIFAINRaWlqiPSQAAC5jb75B+CWJkpIS/du//ZuqqqqUnJwsv98vv9+vTz/9NHTO8uXLVV5eHvr84IMPavfu3XrmmWf0/vvv67HHHtORI0dUWloa1rUjGhxcSluEk9JwOp2XpVgAAIg5kaorWLR582YFAgHl5+crPT091F599dXQOc3NzWptbQ19njVrlqqqqvSb3/xGeXl5ev3117Vz586w9jiQIrzPQXZ2tjwej6qrqzV16lRJF5dsHD58WPfff38kLwUAwFXNsLAxQk1NzWXH7r77bt199922rh12cHDu3DmdOHEi9PnkyZNqaGhQSkqKxo4dqzVr1uhnP/uZbrnlFmVnZ+uRRx5RRkaGFi9ebGugAABElc3VCoqjdyuEHRwcOXJEc+fODX0uKyuTJBUXF6uyslLr1q1TR0eH7r33Xp05c0bf+MY3tHv3bg0fPjxyowYAYJAN9g6J0RR2cJCfn99nqsPhcOiJJ57QE088YWtgAAAgOni3AgAAFiTSK5sJDgAAsMJw2Js3EEfBQdT3OQAAALGFzAEAABYwIREAAJj1YyOjy/rHCYIDAAAsSKQJicw5AAAAJmQOgATVbQSjPQQg/sRRacAOggMAACygrAAAABIWmQMAAKxgtQIAADBzfN7s9I8PlBUAAIAJmQMAAKygrAAAAEwSKDigrAAAAEzIHAAAYEUCvbKZ4ABIUHfe+PVoDwGIK7yVEQAAmDHnAAAAJCoyBwAAWMGcAwAA8EUO42Kz0z9eUFYAAAAmZA4AALAigSYkEhwAAGBFAs05oKwAAABMyBwAAGAFZQUAAGCSQMEBZQUAAGBC5gAAACsSKHNAcAAAgBUJtFqB4AAAAAvYIREAACQsMgcAAFiRQHMOyBwAAAATggMAAGBCWQEAAAscsjkhMWIjGXgEBwAAWJFASxnDLivs379fCxcuVEZGhhwOh3bu3Gn6fsWKFXI4HKa2YMGCSI0XAAAMsLCDg46ODuXl5amioqLXcxYsWKDW1tZQe+WVV2wNEgCAqDMi0OJE2GWFoqIiFRUV9XmO0+mUx+Pp96AAAIg5LGW0p6amRqmpqcrJydH999+v06dP93puV1eX2tvbTQ0AAERPxIODBQsW6KWXXlJ1dbV+8YtfqLa2VkVFReru7u7xfJ/PJ7fbHWpZWVmRHhIAALZd2j7ZTosXEV+tcM8994T+e8qUKcrNzdXNN9+smpoazZs377Lzy8vLVVZWFvrc3t5OgAAAiD2UFSLnpptu0pgxY3TixIkev3c6nXK5XKYGAEDMSaAJiQMeHHz00Uc6ffq00tPTB/pSAAAgAsIuK5w7d86UBTh58qQaGhqUkpKilJQUPf7441qyZIk8Ho+ampq0bt06jR8/XoWFhREdOAAAgymRXtkcdnBw5MgRzZ07N/T50nyB4uJibd68WUePHtW//Mu/6MyZM8rIyND8+fP15JNPyul0Rm7UAAAMtgTaITHs4CA/P1+G0Xv4s2fPHlsDAgAA0cW7FQAAsCKBVisQHAAAYEEizTkY8NUKAAAgvpA5AADACsoKAADAxO4WyHEUHFBWAAAAJgQHAABYEYXtk/fv36+FCxcqIyNDDodDO3fu7PP8mpoaORyOy5rf7w/rugQHAABYEYXgoKOjQ3l5eaqoqAirX2Njo1pbW0MtNTU1rP7MOQAAwIJILWVsb283HXc6nb3uIlxUVKSioqKwr5WamqrRo0eH3e8SMgcAAAyirKwsud3uUPP5fBG/xtSpU5Wenq5vf/vb+o//+I+w+5M5AABgELW0tMjlcoU+R/LdQ+np6dqyZYtuu+02dXV16YUXXlB+fr4OHz6sr3/965Z/h+AAAAArIrTPgcvlMgUHkZSTk6OcnJzQ51mzZqmpqUkbN27Uv/7rv1r+HcoKAABcxWbMmKETJ06E1YfMAQAAFsTruxUaGhqUnp4eVh+CAwAArBrkv+DPnTtn+lf/yZMn1dDQoJSUFI0dO1bl5eX685//rJdeekmStGnTJmVnZ+vWW29VZ2enXnjhBe3bt0+///3vw7ouwQEAADHqyJEjmjt3buhzWVmZJKm4uFiVlZVqbW1Vc3Nz6Pvz58/rH/7hH/TnP/9ZI0eOVG5urt5++23Tb1hBcAAAgBVRePFSfn6+DKP3jpWVlabP69at07p168K/0JcQHAAAYEG8zjnoD1YrAAAAEzIHAABYEYWyQrQQHAAAYEEilRUIDgAAsCKBMgfMOQAAACZkDgAAsCKBMgcEBwAAWJBIcw4oKwAAABMyBwAAWEFZAQAAmBAcABhMhRlTr3jOnlMNAz4OAJAIDgAAsCSRJiQSHAAAYEUClRVYrQAAAEzIHAAAYAFlBQAAYJZAZQWCAwAArEig4IA5BwAAwITMAQAAFjg+b3b6xwuCAwAArKCsAAAAElVYwYHP59P06dOVnJys1NRULV68WI2NjaZzOjs7VVJSouuvv16jRo3SkiVL1NbWFtFBAwAw2C4tZbTT4kVYwUFtba1KSkp06NAh7d27VxcuXND8+fPV0dEROmft2rX67W9/q+3bt6u2tlanTp3SXXfdFfGBAwAwqIwItDgR1pyD3bt3mz5XVlYqNTVV9fX1mjNnjgKBgP75n/9ZVVVVuuOOOyRJW7du1cSJE3Xo0CHdfvvtkRs5AAAYELbmHAQCAUlSSkqKJKm+vl4XLlxQQUFB6JwJEyZo7Nixqqur6/E3urq61N7ebmoAAMSkBMgaSDaCg2AwqDVr1mj27NmaPHmyJMnv9yspKUmjR482nZuWlia/39/j7/h8Prnd7lDLysrq75AAABgwzDmwoKSkRMeOHdO2bdtsDaC8vFyBQCDUWlpabP0eAACwp1/7HJSWlmrXrl3av3+/MjMzQ8c9Ho/Onz+vM2fOmLIHbW1t8ng8Pf6W0+mU0+nszzAAABg87HPQM8MwVFpaqh07dmjfvn3Kzs42fT9t2jQNGzZM1dXVoWONjY1qbm6W1+uNzIgBAIiCRCorhJU5KCkpUVVVld58800lJyeH5hG43W6NGDFCbrdbq1atUllZmVJSUuRyufTAAw/I6/WyUgEAEN8SKHMQVnCwefNmSVJ+fr7p+NatW7VixQpJ0saNGzVkyBAtWbJEXV1dKiws1K9//euIDBZIZIUZU6M9BAAJIqzgwDCuHPYMHz5cFRUVqqio6PegAACINXZLA1dtWQEAgISVQGUFXrwEAABMyBwAAGBFAmUOCA4AALAgkeYcUFYAAAAmZA4AALCCsgIAAPgih2HIYWFJf1/94wVlBQAAYELmAAAAKygrAACAL0qk1QoEBwAAWJFAmQPmHAAAABMyBwAAWEBZAQAAmFFWAAAAiYrMAQAAFlBWAAAAZpQVAABAoiJzAACARfFUGrCD4AAAACsM42Kz0z9OEBwAAGBBIk1IZM4BAAAwIXMAAIAVCbRageAAAAALHMGLzU7/eEFZAQCAGLV//34tXLhQGRkZcjgc2rlz5xX71NTU6Otf/7qcTqfGjx+vysrKsK9LcAAAgBVGBFqYOjo6lJeXp4qKCkvnnzx5Ut/5znc0d+5cNTQ0aM2aNfrRj36kPXv2hHVdygoAAFgQjdUKRUVFKioqsnz+li1blJ2drWeeeUaSNHHiRB04cEAbN25UYWGh5d8hcwAAwCBqb283ta6uroj9dl1dnQoKCkzHCgsLVVdXF9bvEBwAAGDFpU2Q7DRJWVlZcrvdoebz+SI2RL/fr7S0NNOxtLQ0tbe369NPP7X8O5QVAACwIFJlhZaWFrlcrtBxp9Npc2SRR3AAAMAgcrlcpuAgkjwej9ra2kzH2tra5HK5NGLECMu/Q1kBAAArorBaIVxer1fV1dWmY3v37pXX6w3rdwgOAACw4FJZwU4L17lz59TQ0KCGhgZJF5cqNjQ0qLm5WZJUXl6u5cuXh86/77779L//+79at26d3n//ff3617/Wa6+9prVr14Z1XcoKAABYEYW3Mh45ckRz584NfS4rK5MkFRcXq7KyUq2traFAQZKys7P17//+71q7dq2effZZZWZm6oUXXghrGaNEcAAAQMzKz8+X0UdQ0dPuh/n5+frDH/5g67oEBwAAWJBIr2wmOAAAwIoEeisjExIBAIAJmQMAACxIpLJCWJkDn8+n6dOnKzk5WampqVq8eLEaGxtN5+Tn58vhcJjafffdF9FBAwAw6IKG/RYnwgoOamtrVVJSokOHDmnv3r26cOGC5s+fr46ODtN5q1evVmtra6g99dRTER00AAAYOGGVFXbv3m36XFlZqdTUVNXX12vOnDmh4yNHjpTH47H0m11dXaY3UrW3t4czJAAABgcTEq0JBAKSpJSUFNPxl19+WWPGjNHkyZNVXl6uTz75pNff8Pl8prdTZWVl2RkSAAADwiGbOyRG+wbC0O8JicFgUGvWrNHs2bM1efLk0PHvfe97GjdunDIyMnT06FH99Kc/VWNjo954440ef6e8vDy045N0MXNAgAAAQPT0OzgoKSnRsWPHdODAAdPxe++9N/TfU6ZMUXp6uubNm6empibdfPPNl/2O0+mMyddVAgBgEoXtk6OlX2WF0tJS7dq1S++8844yMzP7PHfmzJmSpBMnTvTnUgAAxIRovHgpWsLKHBiGoQceeEA7duxQTU2NsrOzr9jn0puk0tPT+zVAAABiQgJNSAwrOCgpKVFVVZXefPNNJScny+/3S5LcbrdGjBihpqYmVVVV6c4779T111+vo0ePau3atZozZ45yc3MH5AYAAEBkhRUcbN68WdLFjY6+aOvWrVqxYoWSkpL09ttva9OmTero6FBWVpaWLFmihx9+OGIDBgAgGhyGIYeNeQN2+g62sMsKfcnKylJtba2tAQEAEJOCnzc7/eMEL14CAAAmvHgJAAALKCsAAACzBFqtQFkBAACYkDkAAMCKBNohkeAAAAAL7O5yGE87JFJWAAAAJmQOAACwgrICAAD4IkfwYrPTP14QHAAAYEUCZQ6YcwAAAEzIHAAAYEUCbYJEcAAAgAWJtH0yZQUAAGBC5gAAACsSaEIiwQEAAFYYkuwsR4yf2ICyAgAAMCNzAACABYk0IZHgAAAAKwzZnHMQsZEMOMoKAADAhMwBAABWsFoBAACYBCU5bPaPEwQHAABYkEgTEplzAAAATMgcAABgBXMOAACASQIFB5QVAACACZkDAACsSKDMAcEBAABWJNBSRsoKAADAhMwBAAAWJNI+BwQHAABYkUBzDigrAAAAEzIHAABYETQkh41//QfjJ3NAcAAAgBUJVFYgOAAAwBKbwYEIDvrN+PwP/jNdiKc/RwBAFHymC5L+9ncHIiPmgoOzZ89Kkg7orSiPBAAQL86ePSu32z2wF6GsED0ZGRlqaWlRcnKyHI6LW1G1t7crKytLLS0tcrlcUR5h/3EfseNquAfp6riPq+EeJO4jWgzD0NmzZ5WRkTHwFwsaspXSZkJi/w0ZMkSZmZk9fudyueLif6xXwn3EjqvhHqSr4z6uhnuQuI9oGPCMQQKKueAAAICYZAQvNjv94wTBAQAAViTQnIO42CHR6XRq/fr1cjqd0R6KLdxH7Lga7kG6Ou7jargHifvA1cVhsP4DAIBetbe3y+12q+DG+3TNkP4HTZ8Fu/T2n7coEAiENZ+joqJCGzZskN/vV15enp577jnNmDGjx3MrKyu1cuVK0zGn06nOzs6wxhoXmQMAAKLuUlnBTgvTq6++qrKyMq1fv17vvvuu8vLyVFhYqI8//rjXPi6XS62traH24Ycfhn1dggMAAAZRe3u7qXV1dfV67i9/+UutXr1aK1eu1KRJk7RlyxaNHDlSL774Yq99HA6HPB5PqKWlpYU9RoIDAACsMGQzc3DxZ7KysuR2u0PN5/P1eLnz58+rvr5eBQUFoWNDhgxRQUGB6urqeh3muXPnNG7cOGVlZWnRokU6fvx42LfKagUAAKyI0GqFL28w1dvkz7/85S/q7u6+7F/+aWlpev/993vsk5OToxdffFG5ubkKBAJ6+umnNWvWLB0/frzXPYR6QnAAAIAVwaAkG3sVBC/2HcgNprxer7xeb+jzrFmzNHHiRD3//PN68sknLf9OXJQVKioq9JWvfEXDhw/XzJkz9Z//+Z/RHlJYHnvsMTkcDlObMGFCtIfVp/3792vhwoXKyMiQw+HQzp07Td8bhqFHH31U6enpGjFihAoKCvTBBx9EZ7B9uNJ9rFix4rJns2DBgugMthc+n0/Tp09XcnKyUlNTtXjxYjU2NprO6ezsVElJia6//nqNGjVKS5YsUVtbW5RG3DMr95Gfn3/Z87jvvvuiNOLLbd68Wbm5uaH/5+71evW73/0u9H08PAfpyvcR688hUYwZM0ZDhw697H9DbW1t8ng8ln5j2LBh+trXvqYTJ06Ede2YDw76M1MzFt16662m2aMHDhyI9pD61NHRoby8PFVUVPT4/VNPPaVf/epX2rJliw4fPqxrr71WhYWFYS+XGWhXug9JWrBggenZvPLKK4M4wiurra1VSUmJDh06pL179+rChQuaP3++Ojo6QuesXbtWv/3tb7V9+3bV1tbq1KlTuuuuu6I46stZuQ9JWr16tel5PPXUU1Ea8eUyMzP185//XPX19Tpy5IjuuOMOU003Hp6DdOX7kGL7OUTNIK9WSEpK0rRp01RdXR06FgwGVV1dbcoO9KW7u1vvvfee0tPTw7q2jBg3Y8YMo6SkJPS5u7vbyMjIMHw+XxRHFZ7169cbeXl50R5Gv0kyduzYEfocDAYNj8djbNiwIXTszJkzhtPpNF555ZUojNCaL9+HYRhGcXGxsWjRoqiMp78+/vhjQ5JRW1trGMbFP/thw4YZ27dvD53zP//zP4Yko66uLlrDvKIv34dhGMa3vvUt48EHH4zeoPrhuuuuM1544YW4fQ6XXLoPw4jP5zCQAoGAIckoGPNDY0Hqff1uBWN+aEgyAoGA5Wtv27bNcDqdRmVlpfHHP/7RuPfee43Ro0cbfr/fMAzD+MEPfmD84z/+Y+j8xx9/3NizZ4/R1NRk1NfXG/fcc48xfPhw4/jx42Hdc0xnDvo7UzMWffDBB8rIyNBNN92k73//+2pubo72kPrt5MmT8vv9pufidrs1c+bMuHsuklRTU6PU1FTl5OTo/vvv1+nTp6M9pD4FAgFJUkpKiiSpvr5eFy5cMD2PCRMmaOzYsTH9PL58H5e8/PLLGjNmjCZPnqzy8nJ98skn0RjeFXV3d2vbtm3q6OiQ1+uN2+fw5fu4JF6ew9Vu6dKlevrpp/Xoo49q6tSpamho0O7du0OTFJubm9Xa2ho6/69//atWr16tiRMn6s4771R7e7sOHjyoSZMmhXXdmJ6Q2J+ZmrFo5syZqqysVE5OjlpbW/X444/rm9/8po4dO6bk5ORoDy9sfr9fknp8Lpe+ixcLFizQXXfdpezsbDU1Nemhhx5SUVGR6urqNHTo0GgP7zLBYFBr1qzR7NmzNXnyZEkXn0dSUpJGjx5tOjeWn0dP9yFJ3/ve9zRu3DhlZGTo6NGj+ulPf6rGxka98cYbURyt2XvvvSev16vOzk6NGjVKO3bs0KRJk9TQ0BBXz6G3+5Di4zlERZRe2VxaWqrS0tIev6upqTF93rhxozZu3Niv63xRTAcHV4uioqLQf+fm5mrmzJkaN26cXnvtNa1atSqKI8M999wT+u8pU6YoNzdXN998s2pqajRv3rwojqxnJSUlOnbsWMzPWbmS3u7j3nvvDf33lClTlJ6ernnz5qmpqUk333zzYA+zRzk5OWpoaFAgENDrr7+u4uJi1dbWRntYYevtPiZNmhQXzyEaDCMow8abFe30HWwxXVaIxEzNWDR69Gh99atfDXv2aKy49Gd/tT0XSbrppps0ZsyYmHw2paWl2rVrl9555x3TemWPx6Pz58/rzJkzpvNj9Xn0dh89mTlzpiTF1PNISkrS+PHjNW3aNPl8PuXl5enZZ5+Nu+fQ2330JBafAwZWTAcHkZipGYvOnTunpqam8GePxojs7Gx5PB7Tc2lvb9fhw4fj+rlI0kcffaTTp0/H1LMxDEOlpaXasWOH9u3bp+zsbNP306ZN07Bhw0zPo7GxUc3NzTH1PK50Hz1paGiQpJh6Hl8WDAbV1dUVN8+hN5fuoyfx8BwGhWFcLA30t8XRew5jvqxQVlam4uJi3XbbbZoxY4Y2bdqkjo6Oy946Fct+/OMfa+HChRo3bpxOnTql9evXa+jQoVq2bFm0h9arc+fOmf6VcPLkSTU0NCglJUVjx47VmjVr9LOf/Uy33HKLsrOz9cgjjygjI0OLFy+O3qB70Nd9pKSk6PHHH9eSJUvk8XjU1NSkdevWafz48SosLIziqM1KSkpUVVWlN998U8nJyaH6tdvt1ogRI+R2u7Vq1SqVlZUpJSVFLpdLDzzwgLxer26//fYoj/5vrnQfTU1Nqqqq0p133qnrr79eR48e1dq1azVnzhzl5uZGefQXlZeXq6ioSGPHjtXZs2dVVVWlmpoa7dmzJ26eg9T3fcTDc4gaw+acgzgKDmJ+KaNhGMZzzz1njB071khKSjJmzJhhHDp0KNpDCsvSpUuN9PR0IykpybjxxhuNpUuXGidOnIj2sPr0zjvvXPq/AlMrLi42DOPicsZHHnnESEtLM5xOpzFv3jyjsbExuoPuQV/38cknnxjz5883brjhBmPYsGHGuHHjjNWrV4eWCMWKnsYvydi6dWvonE8//dT4+7//e+O6664zRo4caXz3u981WltbozfoHlzpPpqbm405c+YYKSkphtPpNMaPH2/85Cc/CWvZ10D74Q9/aIwbN85ISkoybrjhBmPevHnG73//+9D38fAcDKPv+4iH5zDYLi1lnOf+gVE4elW/2zz3D8JeyhgtDsOIp1AGAIDB1d7eLrfbrXnJ39c1jqR+/85nxnlVn31ZgUBgwLZPjpSYLysAABATEqisQHAAAIAFRjAow8FSRgAAkIDIHAAAYAVlBQAAYBI0JEdiBAeUFQAAgAmZAwAArDAMSTYmFcZR5oDgAAAAC4ygIcNGWSGethWirAAAAEzIHAAAYIURlL2yQvzsc0BwAACABZQVAABAwiJzAACABZ8ZXbZKA5/pQgRHM7AIDgAA6ENSUpI8Ho8O+N+y/Vsej0dJSf1/s+Ng4ZXNAABcQWdnp86fP2/7d5KSkjR8+PAIjGhgERwAAAATJiQCAAATggMAAGBCcAAAAEwIDgAAgAnBAQAAMCE4AAAAJgQHAADA5P8D7zF1hhYN5g8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = train_dataset[128][0].reshape(NUMBER_OF_MASKS, 30, 40).cpu()\n",
    "\n",
    "plt.imshow(imgs[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ReadoutLayer(number_of_devices*NUMBER_OF_MASKS).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "val_accuracy, val_precision, val_recall, val_fscore = [], [], [], []\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=len(labels)).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=len(labels), average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=len(labels), average='macro').to(device)\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=len(labels), average='macro').to(device)\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=len(labels)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 1.502853 Validation - Accuracy: 0.5540 Precision: 0.3845  Recall: 0.4649 F1 Score: 0.4142\n",
      "Epoch [20/1000], Loss: 1.482811 Validation - Accuracy: 0.5699 Precision: 0.3962  Recall: 0.4798 F1 Score: 0.4260\n",
      "Epoch [30/1000], Loss: 1.473927 Validation - Accuracy: 0.5742 Precision: 0.3972  Recall: 0.4823 F1 Score: 0.4293\n",
      "Epoch [40/1000], Loss: 1.468438 Validation - Accuracy: 0.5753 Precision: 0.3990  Recall: 0.4842 F1 Score: 0.4299\n",
      "Epoch [50/1000], Loss: 1.464424 Validation - Accuracy: 0.5798 Precision: 0.4035  Recall: 0.4880 F1 Score: 0.4337\n",
      "Epoch [60/1000], Loss: 1.461683 Validation - Accuracy: 0.5822 Precision: 0.4052  Recall: 0.4905 F1 Score: 0.4352\n",
      "Epoch [70/1000], Loss: 1.459356 Validation - Accuracy: 0.5819 Precision: 0.4039  Recall: 0.4897 F1 Score: 0.4351\n",
      "Epoch [80/1000], Loss: 1.457292 Validation - Accuracy: 0.5830 Precision: 0.4042  Recall: 0.4907 F1 Score: 0.4358\n",
      "Epoch [90/1000], Loss: 1.455189 Validation - Accuracy: 0.5817 Precision: 0.4046  Recall: 0.4902 F1 Score: 0.4345\n",
      "Epoch [100/1000], Loss: 1.454301 Validation - Accuracy: 0.5826 Precision: 0.4040  Recall: 0.4902 F1 Score: 0.4355\n",
      "Epoch [110/1000], Loss: 1.452975 Validation - Accuracy: 0.5815 Precision: 0.4029  Recall: 0.4894 F1 Score: 0.4346\n",
      "Epoch [120/1000], Loss: 1.451393 Validation - Accuracy: 0.5844 Precision: 0.4072  Recall: 0.4923 F1 Score: 0.4369\n",
      "Epoch [130/1000], Loss: 1.450271 Validation - Accuracy: 0.5850 Precision: 0.4058  Recall: 0.4922 F1 Score: 0.4373\n",
      "Epoch [140/1000], Loss: 1.449732 Validation - Accuracy: 0.5835 Precision: 0.4064  Recall: 0.4912 F1 Score: 0.4365\n",
      "Epoch [150/1000], Loss: 1.448358 Validation - Accuracy: 0.5834 Precision: 0.4047  Recall: 0.4913 F1 Score: 0.4359\n",
      "Epoch [160/1000], Loss: 1.447553 Validation - Accuracy: 0.5847 Precision: 0.4073  Recall: 0.4919 F1 Score: 0.4376\n",
      "Epoch [170/1000], Loss: 1.446312 Validation - Accuracy: 0.5860 Precision: 0.4067  Recall: 0.4932 F1 Score: 0.4381\n",
      "Epoch [180/1000], Loss: 1.445479 Validation - Accuracy: 0.5851 Precision: 0.4070  Recall: 0.4925 F1 Score: 0.4376\n",
      "Epoch [190/1000], Loss: 1.445030 Validation - Accuracy: 0.5859 Precision: 0.4064  Recall: 0.4925 F1 Score: 0.4382\n",
      "Epoch [200/1000], Loss: 1.444575 Validation - Accuracy: 0.5863 Precision: 0.4063  Recall: 0.4932 F1 Score: 0.4383\n",
      "Epoch [210/1000], Loss: 1.443530 Validation - Accuracy: 0.5873 Precision: 0.4072  Recall: 0.4939 F1 Score: 0.4393\n",
      "Epoch [220/1000], Loss: 1.443240 Validation - Accuracy: 0.5868 Precision: 0.4071  Recall: 0.4934 F1 Score: 0.4390\n",
      "Epoch [230/1000], Loss: 1.442556 Validation - Accuracy: 0.5877 Precision: 0.4075  Recall: 0.4941 F1 Score: 0.4396\n",
      "Epoch [240/1000], Loss: 1.442019 Validation - Accuracy: 0.5846 Precision: 0.4058  Recall: 0.4926 F1 Score: 0.4367\n",
      "Epoch [250/1000], Loss: 1.440972 Validation - Accuracy: 0.5862 Precision: 0.4060  Recall: 0.4930 F1 Score: 0.4383\n",
      "Epoch [260/1000], Loss: 1.441542 Validation - Accuracy: 0.5851 Precision: 0.4054  Recall: 0.4929 F1 Score: 0.4370\n",
      "Epoch [270/1000], Loss: 1.440087 Validation - Accuracy: 0.5871 Precision: 0.4065  Recall: 0.4931 F1 Score: 0.4390\n",
      "Epoch [280/1000], Loss: 1.440180 Validation - Accuracy: 0.5859 Precision: 0.4079  Recall: 0.4936 F1 Score: 0.4378\n",
      "Epoch [290/1000], Loss: 1.439444 Validation - Accuracy: 0.5877 Precision: 0.4086  Recall: 0.4947 F1 Score: 0.4395\n",
      "Epoch [300/1000], Loss: 1.438583 Validation - Accuracy: 0.5873 Precision: 0.4076  Recall: 0.4934 F1 Score: 0.4394\n",
      "Epoch [310/1000], Loss: 1.438135 Validation - Accuracy: 0.5888 Precision: 0.4078  Recall: 0.4950 F1 Score: 0.4403\n",
      "Epoch [320/1000], Loss: 1.438476 Validation - Accuracy: 0.5877 Precision: 0.4086  Recall: 0.4941 F1 Score: 0.4400\n",
      "Epoch [330/1000], Loss: 1.438528 Validation - Accuracy: 0.5887 Precision: 0.4074  Recall: 0.4953 F1 Score: 0.4400\n",
      "Epoch [340/1000], Loss: 1.436759 Validation - Accuracy: 0.5880 Precision: 0.4081  Recall: 0.4951 F1 Score: 0.4395\n",
      "Epoch [350/1000], Loss: 1.436746 Validation - Accuracy: 0.5881 Precision: 0.4075  Recall: 0.4937 F1 Score: 0.4402\n",
      "Epoch [360/1000], Loss: 1.436124 Validation - Accuracy: 0.5889 Precision: 0.4090  Recall: 0.4945 F1 Score: 0.4409\n",
      "Epoch [370/1000], Loss: 1.435859 Validation - Accuracy: 0.5884 Precision: 0.4080  Recall: 0.4950 F1 Score: 0.4400\n",
      "Epoch [380/1000], Loss: 1.435443 Validation - Accuracy: 0.5892 Precision: 0.4083  Recall: 0.4956 F1 Score: 0.4406\n",
      "Epoch [390/1000], Loss: 1.435301 Validation - Accuracy: 0.5898 Precision: 0.4105  Recall: 0.4960 F1 Score: 0.4416\n",
      "Epoch [400/1000], Loss: 1.434929 Validation - Accuracy: 0.5879 Precision: 0.4091  Recall: 0.4954 F1 Score: 0.4393\n",
      "Epoch [410/1000], Loss: 1.435035 Validation - Accuracy: 0.5897 Precision: 0.4094  Recall: 0.4959 F1 Score: 0.4412\n",
      "Epoch [420/1000], Loss: 1.434474 Validation - Accuracy: 0.5884 Precision: 0.4079  Recall: 0.4955 F1 Score: 0.4396\n",
      "Epoch [430/1000], Loss: 1.434447 Validation - Accuracy: 0.5893 Precision: 0.4082  Recall: 0.4959 F1 Score: 0.4406\n",
      "Epoch [440/1000], Loss: 1.433598 Validation - Accuracy: 0.5893 Precision: 0.4082  Recall: 0.4950 F1 Score: 0.4409\n",
      "Epoch [450/1000], Loss: 1.433432 Validation - Accuracy: 0.5891 Precision: 0.4091  Recall: 0.4953 F1 Score: 0.4408\n",
      "Epoch [460/1000], Loss: 1.433324 Validation - Accuracy: 0.5906 Precision: 0.4098  Recall: 0.4967 F1 Score: 0.4418\n",
      "Epoch [470/1000], Loss: 1.432708 Validation - Accuracy: 0.5901 Precision: 0.4096  Recall: 0.4969 F1 Score: 0.4412\n",
      "Epoch [480/1000], Loss: 1.432916 Validation - Accuracy: 0.5904 Precision: 0.4099  Recall: 0.4964 F1 Score: 0.4418\n",
      "Epoch [490/1000], Loss: 1.432328 Validation - Accuracy: 0.5914 Precision: 0.4107  Recall: 0.4972 F1 Score: 0.4426\n",
      "Epoch [500/1000], Loss: 1.432454 Validation - Accuracy: 0.5917 Precision: 0.4108  Recall: 0.4980 F1 Score: 0.4425\n",
      "Epoch [510/1000], Loss: 1.431695 Validation - Accuracy: 0.5914 Precision: 0.4101  Recall: 0.4974 F1 Score: 0.4424\n",
      "Epoch [520/1000], Loss: 1.431638 Validation - Accuracy: 0.5926 Precision: 0.4108  Recall: 0.4979 F1 Score: 0.4435\n",
      "Epoch [530/1000], Loss: 1.431605 Validation - Accuracy: 0.5925 Precision: 0.4107  Recall: 0.4978 F1 Score: 0.4434\n",
      "Epoch [540/1000], Loss: 1.431252 Validation - Accuracy: 0.5918 Precision: 0.4104  Recall: 0.4976 F1 Score: 0.4428\n",
      "Epoch [550/1000], Loss: 1.431387 Validation - Accuracy: 0.5920 Precision: 0.4102  Recall: 0.4976 F1 Score: 0.4428\n",
      "Epoch [560/1000], Loss: 1.430881 Validation - Accuracy: 0.5921 Precision: 0.4108  Recall: 0.4979 F1 Score: 0.4430\n",
      "Epoch [570/1000], Loss: 1.430880 Validation - Accuracy: 0.5922 Precision: 0.4105  Recall: 0.4984 F1 Score: 0.4428\n",
      "Epoch [580/1000], Loss: 1.430396 Validation - Accuracy: 0.5921 Precision: 0.4115  Recall: 0.4970 F1 Score: 0.4435\n",
      "Epoch [590/1000], Loss: 1.430110 Validation - Accuracy: 0.5931 Precision: 0.4116  Recall: 0.4991 F1 Score: 0.4437\n",
      "Epoch [600/1000], Loss: 1.429664 Validation - Accuracy: 0.5925 Precision: 0.4116  Recall: 0.4985 F1 Score: 0.4433\n",
      "Epoch [610/1000], Loss: 1.429734 Validation - Accuracy: 0.5929 Precision: 0.4111  Recall: 0.4984 F1 Score: 0.4436\n",
      "Epoch [620/1000], Loss: 1.429306 Validation - Accuracy: 0.5937 Precision: 0.4114  Recall: 0.4989 F1 Score: 0.4442\n",
      "Epoch [630/1000], Loss: 1.429102 Validation - Accuracy: 0.5937 Precision: 0.4123  Recall: 0.4988 F1 Score: 0.4445\n",
      "Epoch [640/1000], Loss: 1.429228 Validation - Accuracy: 0.5942 Precision: 0.4121  Recall: 0.4995 F1 Score: 0.4447\n",
      "Epoch [650/1000], Loss: 1.428834 Validation - Accuracy: 0.5933 Precision: 0.4125  Recall: 0.4989 F1 Score: 0.4441\n",
      "Epoch [660/1000], Loss: 1.428569 Validation - Accuracy: 0.5927 Precision: 0.4108  Recall: 0.4979 F1 Score: 0.4436\n",
      "Epoch [670/1000], Loss: 1.428806 Validation - Accuracy: 0.5933 Precision: 0.4116  Recall: 0.4994 F1 Score: 0.4437\n",
      "Epoch [680/1000], Loss: 1.428195 Validation - Accuracy: 0.5942 Precision: 0.4123  Recall: 0.4996 F1 Score: 0.4447\n",
      "Epoch [690/1000], Loss: 1.428574 Validation - Accuracy: 0.5941 Precision: 0.4120  Recall: 0.4988 F1 Score: 0.4448\n",
      "Epoch [700/1000], Loss: 1.428015 Validation - Accuracy: 0.5949 Precision: 0.4127  Recall: 0.5004 F1 Score: 0.4451\n",
      "Epoch [710/1000], Loss: 1.427982 Validation - Accuracy: 0.5939 Precision: 0.4123  Recall: 0.4987 F1 Score: 0.4448\n",
      "Epoch [720/1000], Loss: 1.427681 Validation - Accuracy: 0.5954 Precision: 0.4129  Recall: 0.5006 F1 Score: 0.4456\n",
      "Epoch [730/1000], Loss: 1.427206 Validation - Accuracy: 0.5947 Precision: 0.4127  Recall: 0.5003 F1 Score: 0.4450\n",
      "Epoch [740/1000], Loss: 1.427047 Validation - Accuracy: 0.5951 Precision: 0.4132  Recall: 0.4999 F1 Score: 0.4456\n",
      "Epoch [750/1000], Loss: 1.426585 Validation - Accuracy: 0.5954 Precision: 0.4137  Recall: 0.5005 F1 Score: 0.4458\n",
      "Epoch [760/1000], Loss: 1.426865 Validation - Accuracy: 0.5943 Precision: 0.4123  Recall: 0.5004 F1 Score: 0.4444\n",
      "Epoch [770/1000], Loss: 1.426596 Validation - Accuracy: 0.5962 Precision: 0.4141  Recall: 0.5011 F1 Score: 0.4464\n",
      "Epoch [780/1000], Loss: 1.426382 Validation - Accuracy: 0.5960 Precision: 0.4139  Recall: 0.5007 F1 Score: 0.4464\n",
      "Epoch [790/1000], Loss: 1.426176 Validation - Accuracy: 0.5964 Precision: 0.4138  Recall: 0.5015 F1 Score: 0.4465\n",
      "Epoch [800/1000], Loss: 1.426128 Validation - Accuracy: 0.5966 Precision: 0.4147  Recall: 0.5022 F1 Score: 0.4465\n",
      "Epoch [810/1000], Loss: 1.425664 Validation - Accuracy: 0.5943 Precision: 0.4132  Recall: 0.5007 F1 Score: 0.4446\n",
      "Epoch [820/1000], Loss: 1.425470 Validation - Accuracy: 0.5959 Precision: 0.4134  Recall: 0.5004 F1 Score: 0.4463\n",
      "Epoch [830/1000], Loss: 1.425550 Validation - Accuracy: 0.5964 Precision: 0.4136  Recall: 0.5014 F1 Score: 0.4465\n",
      "Epoch [840/1000], Loss: 1.425419 Validation - Accuracy: 0.5970 Precision: 0.4142  Recall: 0.5019 F1 Score: 0.4470\n",
      "Epoch [850/1000], Loss: 1.425065 Validation - Accuracy: 0.5982 Precision: 0.4157  Recall: 0.5028 F1 Score: 0.4480\n",
      "Epoch [860/1000], Loss: 1.425964 Validation - Accuracy: 0.5972 Precision: 0.4153  Recall: 0.5023 F1 Score: 0.4472\n",
      "Epoch [870/1000], Loss: 1.424986 Validation - Accuracy: 0.5980 Precision: 0.4157  Recall: 0.5024 F1 Score: 0.4481\n",
      "Epoch [880/1000], Loss: 1.424910 Validation - Accuracy: 0.5979 Precision: 0.4154  Recall: 0.5021 F1 Score: 0.4479\n",
      "Epoch [890/1000], Loss: 1.424676 Validation - Accuracy: 0.5982 Precision: 0.4153  Recall: 0.5028 F1 Score: 0.4480\n",
      "Epoch [900/1000], Loss: 1.424650 Validation - Accuracy: 0.5983 Precision: 0.4155  Recall: 0.5031 F1 Score: 0.4480\n",
      "Epoch [910/1000], Loss: 1.424178 Validation - Accuracy: 0.5983 Precision: 0.4156  Recall: 0.5030 F1 Score: 0.4481\n",
      "Epoch [920/1000], Loss: 1.424110 Validation - Accuracy: 0.5993 Precision: 0.4161  Recall: 0.5037 F1 Score: 0.4489\n",
      "Epoch [930/1000], Loss: 1.423984 Validation - Accuracy: 0.5988 Precision: 0.4162  Recall: 0.5039 F1 Score: 0.4484\n",
      "Epoch [940/1000], Loss: 1.423702 Validation - Accuracy: 0.5978 Precision: 0.4153  Recall: 0.5029 F1 Score: 0.4476\n",
      "Epoch [950/1000], Loss: 1.423755 Validation - Accuracy: 0.6000 Precision: 0.4175  Recall: 0.5044 F1 Score: 0.4495\n",
      "Epoch [960/1000], Loss: 1.423553 Validation - Accuracy: 0.6000 Precision: 0.4167  Recall: 0.5042 F1 Score: 0.4495\n",
      "Epoch [970/1000], Loss: 1.423507 Validation - Accuracy: 0.6009 Precision: 0.4174  Recall: 0.5046 F1 Score: 0.4503\n",
      "Epoch [980/1000], Loss: 1.422863 Validation - Accuracy: 0.6012 Precision: 0.4179  Recall: 0.5052 F1 Score: 0.4505\n",
      "Epoch [990/1000], Loss: 1.422848 Validation - Accuracy: 0.5999 Precision: 0.4164  Recall: 0.5039 F1 Score: 0.4495\n",
      "Epoch [1000/1000], Loss: 1.422791 Validation - Accuracy: 0.6011 Precision: 0.4176  Recall: 0.5051 F1 Score: 0.4504\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, batch_count = 0.0, 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to device\n",
    "        outputs = model(images.float())  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Loss calculation\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "    \n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images, labels\n",
    "            outputs = model(images.float())\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            labels = labels.argmax(dim=1)\n",
    "            # Update metrics\n",
    "            # print(preds.shape, labels.shape)\n",
    "            accuracy.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            f1_score.update(preds, labels)\n",
    "\n",
    "        # Print validation metrics\n",
    "\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/batch_count:.6f}', end=\" \")\n",
    "            print(f'Validation - Accuracy: {accuracy.compute().max().item():.4f} Precision: {precision.compute().max().item():.4f} ', end=\" \")\n",
    "            print(f'Recall: {recall.compute().max().item():.4f} F1 Score: {f1_score.compute().max().item():.4f}')\n",
    "\n",
    "        # Updating the list to save current metrics\n",
    "        val_accuracy.append(accuracy.compute().item())\n",
    "        val_precision.append(precision.compute().item())\n",
    "        val_recall.append(recall.compute().item())\n",
    "        val_fscore.append(f1_score.compute().item())\n",
    "\n",
    "        # Reset metrics for the next epoch\n",
    "        accuracy.reset()\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        f1_score.reset()\n",
    "        confusion_matrix.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_46404\\227308190.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 62.81%\n",
      "Test Precision: 44.0218%\n",
      "Test Recall: 53.1435%\n",
      "Test F1 Score: 0.4725\n",
      "Confusion Matrix:\n",
      "tensor([[8996,  658,  844,    0,    0,  373],\n",
      "        [ 842, 8591,  910,    0,    0,  178],\n",
      "        [1379, 2284, 8382,    0,    0,  822],\n",
      "        [ 611,   98,  335,    0,    0, 5745],\n",
      "        [ 406,   79,  270,    0,    0, 4152],\n",
      "        [ 661,  128,  380,    0,    0, 9766]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(torch.tensor(images, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and labels for metric calculations\n",
    "        all_preds.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "\n",
    "all_preds = torch.cat(all_preds).to(device)\n",
    "all_labels = torch.cat(all_labels).to(device)\n",
    "all_labels = all_labels.argmax(dim=1)\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy(all_preds, all_labels)\n",
    "test_precision = precision(all_preds, all_labels)\n",
    "test_recall = recall(all_preds, all_labels)\n",
    "test_f1 = f1_score(all_preds, all_labels)\n",
    "test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_confusion_matrix)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
