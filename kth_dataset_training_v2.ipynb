{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from torchmetrics.classification import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item for item in os.listdir(\"data/kth_dataset\") if os.path.isdir(os.path.join(\"data/kth_dataset\", item))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape: (75854, 30, 40)\n",
      "Combined labels shape: (75854, 6)\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(\"data\\kth_dataset\\processed_data.npz\")\n",
    "combined_data = []\n",
    "combined_labels = []\n",
    "\n",
    "# Loop through the dictionary to combine data and labels\n",
    "for label, data_array in data_dict.items():\n",
    "    # Append the data array entries to all_data\n",
    "    combined_data.append(data_array)  # Keeps the (num_entries, 4, width, height) shape\n",
    "    \n",
    "    # Create a list of labels for each entry in this data_array and extend all_labels\n",
    "    combined_labels.extend([label] * data_array.shape[0])\n",
    "\n",
    "del(data_array)\n",
    "# Concatenate all data along the first axis to create a single numpy array\n",
    "combined_data = np.concatenate(combined_data, axis=0)  # Shape: (total_entries, 4, width, height)\n",
    "combined_labels = np.array(combined_labels)             # Shape: (total_entries,)\n",
    "\n",
    "\n",
    "# Convert each label in combined_labels to its corresponding index\n",
    "label_indices = [labels.index(label) for label in combined_labels]\n",
    "\n",
    "# Create a one-hot encoded array using np.eye\n",
    "num_classes = len(labels)\n",
    "one_hot_labels = np.eye(num_classes)[label_indices]  # Shape: (total_entries, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indices = np.random.permutation(combined_data.shape[0])\n",
    "shuffled_data = combined_data[indices]\n",
    "shuffled_labels = one_hot_labels[indices]\n",
    "del(combined_data, combined_labels, one_hot_labels, data_dict, label_indices, indices)\n",
    "\n",
    "print(\"Combined data shape:\", shuffled_data.shape)\n",
    "print(\"Combined labels shape:\", shuffled_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e+00, 1.000e+01, 1.100e+01, 1.000e+02, 1.010e+02,\n",
       "       1.100e+02, 1.110e+02, 1.000e+03, 1.001e+03, 1.010e+03, 1.011e+03,\n",
       "       1.100e+03, 1.101e+03, 1.110e+03, 1.111e+03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(shuffled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x284568fac50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = shuffled_data[99]\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (56890, 30, 40)\n",
      "Train labels shape: (56890, 6)\n",
      "Validation data shape: (7585, 30, 40)\n",
      "Validation labels shape: (7585, 6)\n",
      "Test data shape: (11379, 30, 40)\n",
      "Test labels shape: (11379, 6)\n"
     ]
    }
   ],
   "source": [
    "# Define the split ratios\n",
    "train_ratio = 0.75\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Total number of entries\n",
    "total_entries = shuffled_data.shape[0]\n",
    "\n",
    "# Calculate split indices\n",
    "train_end = int(total_entries * train_ratio)\n",
    "val_end = train_end + int(total_entries * val_ratio)\n",
    "\n",
    "# Split the data and labels\n",
    "train_data = shuffled_data[:train_end]\n",
    "train_labels = shuffled_labels[:train_end]\n",
    "\n",
    "val_data = shuffled_data[train_end:val_end]\n",
    "val_labels = shuffled_labels[train_end:val_end]\n",
    "\n",
    "test_data = shuffled_data[val_end:]\n",
    "test_labels = shuffled_labels[val_end:]\n",
    "\n",
    "del(shuffled_data, shuffled_labels)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all the rows of each mask-set in every file \n",
    "json_data = {\n",
    "    \"365nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(10, 15),\n",
    "        \"I3\":range(18, 23),\n",
    "        \"I4\":range(25, 30)\n",
    "    },\n",
    "    \"455nm\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(7, 12),\n",
    "        \"I3\":range(14, 19),\n",
    "        \"I4\":range(21, 26)\n",
    "    },\n",
    "    \"White\":{\n",
    "        \"I1\":range(0, 5),\n",
    "        \"I2\":range(9, 14),\n",
    "        \"I3\":range(16, 21),\n",
    "        \"I4\":range(24, 29)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tables = []\n",
    "for filename in [\"White\", \"365nm\", \"455nm\"]:\n",
    "    path = \"data/\"+filename+\".xlsx\" \n",
    "    df = pd.read_excel(path, usecols='B:Q') # Read the excel sheet\n",
    "    tables = [df.iloc[json_data[filename][key]].copy().reset_index(drop=True) for key in list(json_data[filename].keys())]\n",
    "    combined_table = pd.concat(tables, axis=0)\n",
    "    combined_tables.append(combined_table)\n",
    "    del(df, tables, combined_table)\n",
    "\n",
    "combined_tables[1] = combined_tables[1].reindex(columns=combined_tables[0].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_MASKS = 4\n",
    "optical_range = np.array([0, 1, 2])  # Optical masks: 0, 1, 2\n",
    "electrical_range = np.array([0, 1, 2, 3])  # Electrical masks: 0, 1, 2, 3\n",
    "\n",
    "# Generate a meshgrid of all combinations, so that we don't sample same pair twice\n",
    "optical_masks, electrical_masks = np.meshgrid(optical_range, electrical_range, indexing='ij')\n",
    "all_pairs = np.column_stack((optical_masks.ravel(), electrical_masks.ravel()))\n",
    "\n",
    "unique_indices = np.random.choice(all_pairs.shape[0], size=NUMBER_OF_MASKS, replace=False)\n",
    "\n",
    "selected_pairs = all_pairs[unique_indices]\n",
    "optical_masks = selected_pairs[:, 0]\n",
    "electrical_masks = selected_pairs[:, 1]\n",
    "\n",
    "\n",
    "# Use this to override previous values,  if you want a specific set of masks\n",
    "# optical_masks = np.array([0, 1, 2])\n",
    "# electrical_masks = np.array([0, 1, 2])\n",
    "\n",
    "# Device masks\n",
    "\n",
    "number_of_devices = np.multiply(*train_data.shape[-2:])\n",
    "\n",
    "# device_mask = np.random.randint(0, 5, (NUMBER_OF_MASKS, number_of_devices))\n",
    "\n",
    "device_mask = np.ones((NUMBER_OF_MASKS, number_of_devices))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] [3] (1, 1200)\n"
     ]
    }
   ],
   "source": [
    "print(optical_masks, electrical_masks, device_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56890/56890 [00:22<00:00, 2529.74it/s]\n",
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_12796\\3357411927.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  self.processed_data = torch.tensor(self.processed_data).to(device=device)\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset:np.array, \n",
    "                 labels:np.array, \n",
    "                 combined_tables:np.array, \n",
    "                 optical_masks:np.array, \n",
    "                 electrical_masks:np.array, \n",
    "                 device_mask:np.array):\n",
    "        self.processed_data = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx in tqdm(range(len(dataset))):\n",
    "            image, label = dataset[idx], labels[idx]\n",
    "            # image = (\n",
    "            #     images[0]*1000+\n",
    "            #     images[1]*100+\n",
    "            #     images[2]*10+\n",
    "            #     images[3]\n",
    "            # )\n",
    "            image = image.flatten()\n",
    "            \n",
    "            column_indices = combined_tables[0].columns.get_indexer(image.tolist())\n",
    "            x = []\n",
    "            for j, (optical_mask, electrical_mask) in enumerate(zip(optical_masks, electrical_masks)):\n",
    "                required_table = combined_tables[optical_mask].iloc[electrical_mask*5:(electrical_mask+1)*5].iloc[device_mask[j]]\n",
    "                # print(required_table.shape)\n",
    "\n",
    "                # to_add = required_table.values[np.arange(device_mask.shape[-1]), column_indices]*1e9\n",
    "\n",
    "                # plt.imshow(to_add.reshape(43, 54))\n",
    "\n",
    "                # print(y)\n",
    "\n",
    "                x.append(required_table.values[np.arange(device_mask.shape[-1]), column_indices]*1e9)\n",
    "            \n",
    "            x = np.concatenate(x, axis=0)\n",
    "\n",
    "            # print(y)\n",
    "            x = x.reshape(1, 30*NUMBER_OF_MASKS, 40)\n",
    "            self.processed_data.append(x)\n",
    "            self.labels.append(label)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.processed_data = torch.tensor(self.processed_data).to(device=device)\n",
    "        \n",
    "        self.labels = torch.tensor(self.labels).to(device=device)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.processed_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx], self.labels[idx]\n",
    "    \n",
    "train_dataset = CustomDataset(train_data, train_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56890, 1, 30, 40])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1000,  100,   10,    1, 1100,  110, 1010, 1001,  101,   11, 1110, 1101,\n",
       "       1011,  111, 1111,    0],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tables[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 2048\n",
    "# class ReadoutLayer(nn.Module):\n",
    "#     def __init__(self, input_size:int):\n",
    "#         super(ReadoutLayer, self).__init__()\n",
    "#         self.fc = nn.Linear(input_size, len(labels))\n",
    "#         self.activation = nn.functional.relu\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.activation(self.fc(x))\n",
    "#         x = self.softmax(x)\n",
    "#         # x = x.reshape(BATCH_SIZE, 1, NUMBER_OF_MASKS*144, 180)\n",
    "        \n",
    "#         # x = self.fc(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "class ReadoutLayer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ReadoutLayer, self).__init__()\n",
    "        \n",
    "        # First convolutional layer with BatchNorm\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Second convolutional layer with BatchNorm\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Third convolutional layer with BatchNorm\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 3 * 5, 64)  # Adjust the flattened size based on your input\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with BatchNorm, ReLU, and pooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# class ReadoutLayer(nn.Module):\n",
    "#     def __init__(self, input_channels:int):\n",
    "#         super(ReadoutLayer, self).__init__()\n",
    "        \n",
    "#         # Define convolutional layers for feature extraction\n",
    "#         self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, stride=1, padding=1)  # First convolutional layer\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Second convolutional layer\n",
    "        \n",
    "#         # Fully connected layer for classification (after flattening the output from conv layers)\n",
    "#         self.fc = nn.Linear(64 * 36 * 45, 10)  # Adjust this depending on the dimensions after convolution\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Reshape the input to (BATCH_SIZE, input_channels, height, width)\n",
    "#         x = x.reshape(BATCH_SIZE, 1, NUMBER_OF_MASKS * 144, 180)\n",
    "        \n",
    "#         # Apply the first convolutional layer with ReLU activation\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.max_pool2d(x, 2)  # Apply max pooling to downsample\n",
    "        \n",
    "#         # Apply the second convolutional layer with ReLU activation\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = F.max_pool2d(x, 2)  # Apply max pooling to downsample\n",
    "        \n",
    "#         # Flatten the output to feed into the fully connected layer\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "#         # Pass through the fully connected layer for classification\n",
    "#         x = self.fc(x)\n",
    "        \n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56890/56890 [00:23<00:00, 2412.36it/s]\n",
      "100%|██████████| 7585/7585 [00:03<00:00, 2330.76it/s]\n",
      "100%|██████████| 11379/11379 [00:04<00:00, 2486.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_data, train_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "validation_dataset = CustomDataset(val_data, val_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "test_dataset = CustomDataset(test_data, test_labels, combined_tables, optical_masks, electrical_masks, device_mask)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 40])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 40])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2845858b650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = train_dataset[128][0].cpu()\n",
    "print(imgs.shape)\n",
    "plt.imshow(imgs[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = ReadoutLayer(num_classes).to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "val_accuracy, val_precision, val_recall, val_fscore = [], [], [], []\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=6).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=6, average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=6, average='macro').to(device)\n",
    "f1_score = F1Score(task=\"multiclass\", num_classes=6, average='macro').to(device)\n",
    "\n",
    "confusion_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.554468 Validation - Accuracy: 0.7423 Precision: 0.6920  Recall: 0.6551 F1 Score: 0.6474\n",
      "Epoch [20/100], Loss: 0.432825 Validation - Accuracy: 0.7582 Precision: 0.7055  Recall: 0.6716 F1 Score: 0.6648\n",
      "Epoch [30/100], Loss: 0.361016 Validation - Accuracy: 0.7433 Precision: 0.6896  Recall: 0.6727 F1 Score: 0.6750\n",
      "Epoch [40/100], Loss: 0.316250 Validation - Accuracy: 0.7577 Precision: 0.7017  Recall: 0.6775 F1 Score: 0.6772\n",
      "Epoch [50/100], Loss: 0.274027 Validation - Accuracy: 0.7449 Precision: 0.6898  Recall: 0.6662 F1 Score: 0.6673\n",
      "Epoch [60/100], Loss: 0.246874 Validation - Accuracy: 0.7437 Precision: 0.6827  Recall: 0.6702 F1 Score: 0.6694\n",
      "Epoch [70/100], Loss: 0.223838 Validation - Accuracy: 0.7462 Precision: 0.6851  Recall: 0.6708 F1 Score: 0.6702\n",
      "Epoch [80/100], Loss: 0.207705 Validation - Accuracy: 0.7387 Precision: 0.6769  Recall: 0.6658 F1 Score: 0.6677\n",
      "Epoch [90/100], Loss: 0.270874 Validation - Accuracy: 0.7517 Precision: 0.6893  Recall: 0.6780 F1 Score: 0.6784\n",
      "Epoch [100/100], Loss: 0.193555 Validation - Accuracy: 0.7511 Precision: 0.6917  Recall: 0.6751 F1 Score: 0.6760\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, batch_count = 0.0, 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to device\n",
    "        outputs = model(images.float())  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Loss calculation\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "    \n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images, labels\n",
    "            outputs = model(images.float())\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            labels = labels.argmax(dim=1)\n",
    "            # Update metrics\n",
    "            # print(preds.shape, labels.shape)\n",
    "            accuracy.update(preds, labels)\n",
    "            precision.update(preds, labels)\n",
    "            recall.update(preds, labels)\n",
    "            f1_score.update(preds, labels)\n",
    "\n",
    "        # Print validation metrics\n",
    "\n",
    "        if (epoch+1)%10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/batch_count:.6f}', end=\" \")\n",
    "            print(f'Validation - Accuracy: {accuracy.compute().max().item():.4f} Precision: {precision.compute().max().item():.4f} ', end=\" \")\n",
    "            print(f'Recall: {recall.compute().max().item():.4f} F1 Score: {f1_score.compute().max().item():.4f}')\n",
    "\n",
    "        # Updating the list to save current metrics\n",
    "        val_accuracy.append(accuracy.compute().item())\n",
    "        val_precision.append(precision.compute().item())\n",
    "        val_recall.append(recall.compute().item())\n",
    "        val_fscore.append(f1_score.compute().item())\n",
    "\n",
    "        # Reset metrics for the next epoch\n",
    "        accuracy.reset()\n",
    "        precision.reset()\n",
    "        recall.reset()\n",
    "        f1_score.reset()\n",
    "        confusion_matrix.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adith\\AppData\\Local\\Temp\\ipykernel_13132\\227308190.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(images, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.69%\n",
      "Test Precision: 68.1397%\n",
      "Test Recall: 72.0819%\n",
      "Test F1 Score: 0.6939\n",
      "Confusion Matrix:\n",
      "tensor([[10573,   103,    38,    28,     0,   185],\n",
      "        [   85,  9996,   243,    11,     0,    61],\n",
      "        [   74,   617, 11864,    16,     0,   354],\n",
      "        [   43,    32,    33,  3542,     0,  3175],\n",
      "        [   89,    22,    52,  1854,     0,  2850],\n",
      "        [   61,    44,    69,   276,     0, 10500]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        # Move images and labels to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(torch.tensor(images, dtype=torch.float32))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Append predictions and labels for metric calculations\n",
    "        all_preds.append(predicted)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "\n",
    "all_preds = torch.cat(all_preds).to(device)\n",
    "all_labels = torch.cat(all_labels).to(device)\n",
    "all_labels = all_labels.argmax(dim=1)\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy(all_preds, all_labels)\n",
    "test_precision = precision(all_preds, all_labels)\n",
    "test_recall = recall(all_preds, all_labels)\n",
    "test_f1 = f1_score(all_preds, all_labels)\n",
    "test_confusion_matrix = confusion_matrix(all_preds, all_labels)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision*100:.4f}%')\n",
    "print(f'Test Recall: {test_recall*100:.4f}%')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_confusion_matrix)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
